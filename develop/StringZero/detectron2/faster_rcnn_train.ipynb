{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only on the first execution\n",
    "# !python setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_train', {}, '../../../dataset/train.json', '../../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '../../../dataset/test.json', '../../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 0\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml')\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.002\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (8000,12000)\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 3000\n",
    "\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 12\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "import detectron2.data.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        # T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        # T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "        # T.RandomBrightness(0.8, 1.5),\n",
    "        # T.RandomContrast(0.6, 1.3),\n",
    "        T.Resize(1024)\n",
    "        # A.Resize(1024, 1024),\n",
    "        # ToTensorV2(p=0.1)\n",
    "\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/09 09:53:30 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=13, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=48, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/09 09:53:30 d2.data.datasets.coco]: \u001b[0mLoaded 4883 images in COCO format from ../../../dataset/train.json\n",
      "\u001b[32m[01/09 09:53:30 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4883 images left.\n",
      "\u001b[32m[01/09 09:53:30 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/09 09:53:30 d2.data.common]: \u001b[0mSerializing 4883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/09 09:53:31 d2.data.common]: \u001b[0mSerialized dataset takes 2.20 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (13, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (48, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (48,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/09 09:53:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/09 09:54:13 d2.utils.events]: \u001b[0m eta: 7:46:23  iter: 19  total_loss: 3.437  loss_cls: 2.653  loss_box_reg: 0.6597  loss_rpn_cls: 0.07801  loss_rpn_loc: 0.03325  time: 1.8738  data_time: 0.2068  lr: 3.9962e-05  max_mem: 25340M\n",
      "\u001b[32m[01/09 09:54:51 d2.utils.events]: \u001b[0m eta: 7:44:32  iter: 39  total_loss: 2.634  loss_cls: 1.775  loss_box_reg: 0.7122  loss_rpn_cls: 0.09029  loss_rpn_loc: 0.04541  time: 1.8702  data_time: 0.1887  lr: 7.9922e-05  max_mem: 25340M\n",
      "\u001b[32m[01/09 09:55:28 d2.utils.events]: \u001b[0m eta: 7:44:24  iter: 59  total_loss: 1.678  loss_cls: 0.8596  loss_box_reg: 0.6646  loss_rpn_cls: 0.07687  loss_rpn_loc: 0.04063  time: 1.8710  data_time: 0.1902  lr: 0.00011988  max_mem: 25340M\n",
      "\u001b[32m[01/09 09:56:06 d2.utils.events]: \u001b[0m eta: 7:44:22  iter: 79  total_loss: 1.621  loss_cls: 0.775  loss_box_reg: 0.7109  loss_rpn_cls: 0.06151  loss_rpn_loc: 0.04428  time: 1.8735  data_time: 0.1985  lr: 0.00015984  max_mem: 25340M\n",
      "\u001b[32m[01/09 09:56:43 d2.utils.events]: \u001b[0m eta: 7:43:43  iter: 99  total_loss: 1.54  loss_cls: 0.743  loss_box_reg: 0.7266  loss_rpn_cls: 0.04448  loss_rpn_loc: 0.03438  time: 1.8730  data_time: 0.1896  lr: 0.0001998  max_mem: 25340M\n",
      "\u001b[32m[01/09 09:57:21 d2.utils.events]: \u001b[0m eta: 7:43:22  iter: 119  total_loss: 1.525  loss_cls: 0.7118  loss_box_reg: 0.7156  loss_rpn_cls: 0.03763  loss_rpn_loc: 0.0353  time: 1.8743  data_time: 0.1995  lr: 0.00023976  max_mem: 25340M\n",
      "\u001b[32m[01/09 09:57:58 d2.utils.events]: \u001b[0m eta: 7:42:45  iter: 139  total_loss: 1.498  loss_cls: 0.6988  loss_box_reg: 0.7086  loss_rpn_cls: 0.05276  loss_rpn_loc: 0.03382  time: 1.8742  data_time: 0.1919  lr: 0.00027972  max_mem: 25340M\n",
      "\u001b[32m[01/09 09:58:36 d2.utils.events]: \u001b[0m eta: 7:42:07  iter: 159  total_loss: 1.408  loss_cls: 0.6327  loss_box_reg: 0.6802  loss_rpn_cls: 0.03658  loss_rpn_loc: 0.0293  time: 1.8733  data_time: 0.1850  lr: 0.00031968  max_mem: 25340M\n",
      "\u001b[32m[01/09 09:59:13 d2.utils.events]: \u001b[0m eta: 7:41:33  iter: 179  total_loss: 1.39  loss_cls: 0.629  loss_box_reg: 0.6711  loss_rpn_cls: 0.03399  loss_rpn_loc: 0.03986  time: 1.8742  data_time: 0.1922  lr: 0.00035964  max_mem: 25340M\n",
      "\u001b[32m[01/09 09:59:51 d2.utils.events]: \u001b[0m eta: 7:41:05  iter: 199  total_loss: 1.276  loss_cls: 0.5691  loss_box_reg: 0.6447  loss_rpn_cls: 0.02744  loss_rpn_loc: 0.03106  time: 1.8744  data_time: 0.1961  lr: 0.0003996  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:00:28 d2.utils.events]: \u001b[0m eta: 7:40:28  iter: 219  total_loss: 1.231  loss_cls: 0.5803  loss_box_reg: 0.6082  loss_rpn_cls: 0.02435  loss_rpn_loc: 0.0435  time: 1.8744  data_time: 0.1895  lr: 0.00043956  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:01:06 d2.utils.events]: \u001b[0m eta: 7:39:55  iter: 239  total_loss: 1.172  loss_cls: 0.5447  loss_box_reg: 0.5631  loss_rpn_cls: 0.03207  loss_rpn_loc: 0.03081  time: 1.8745  data_time: 0.1916  lr: 0.00047952  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:01:44 d2.utils.events]: \u001b[0m eta: 7:39:18  iter: 259  total_loss: 1.111  loss_cls: 0.5464  loss_box_reg: 0.5151  loss_rpn_cls: 0.0357  loss_rpn_loc: 0.04642  time: 1.8750  data_time: 0.1974  lr: 0.00051948  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:02:21 d2.utils.events]: \u001b[0m eta: 7:38:43  iter: 279  total_loss: 1.015  loss_cls: 0.5297  loss_box_reg: 0.4257  loss_rpn_cls: 0.03176  loss_rpn_loc: 0.04232  time: 1.8753  data_time: 0.1951  lr: 0.00055944  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:02:59 d2.utils.events]: \u001b[0m eta: 7:38:13  iter: 299  total_loss: 1.042  loss_cls: 0.5236  loss_box_reg: 0.4391  loss_rpn_cls: 0.03492  loss_rpn_loc: 0.04195  time: 1.8759  data_time: 0.1971  lr: 0.0005994  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:03:37 d2.utils.events]: \u001b[0m eta: 7:37:37  iter: 319  total_loss: 0.9624  loss_cls: 0.5132  loss_box_reg: 0.38  loss_rpn_cls: 0.02555  loss_rpn_loc: 0.03585  time: 1.8760  data_time: 0.1951  lr: 0.00063936  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:04:14 d2.utils.events]: \u001b[0m eta: 7:36:57  iter: 339  total_loss: 0.8275  loss_cls: 0.4422  loss_box_reg: 0.3281  loss_rpn_cls: 0.02353  loss_rpn_loc: 0.02566  time: 1.8756  data_time: 0.1908  lr: 0.00067932  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:04:51 d2.utils.events]: \u001b[0m eta: 7:36:19  iter: 359  total_loss: 0.8886  loss_cls: 0.4623  loss_box_reg: 0.3535  loss_rpn_cls: 0.0311  loss_rpn_loc: 0.04281  time: 1.8755  data_time: 0.1937  lr: 0.00071928  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:05:29 d2.utils.events]: \u001b[0m eta: 7:35:42  iter: 379  total_loss: 0.8664  loss_cls: 0.4585  loss_box_reg: 0.3269  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.03223  time: 1.8753  data_time: 0.1923  lr: 0.00075924  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:06:06 d2.utils.events]: \u001b[0m eta: 7:35:06  iter: 399  total_loss: 0.8734  loss_cls: 0.4696  loss_box_reg: 0.3398  loss_rpn_cls: 0.02738  loss_rpn_loc: 0.0395  time: 1.8753  data_time: 0.1963  lr: 0.0007992  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:06:44 d2.utils.events]: \u001b[0m eta: 7:34:27  iter: 419  total_loss: 0.8374  loss_cls: 0.4505  loss_box_reg: 0.3187  loss_rpn_cls: 0.02992  loss_rpn_loc: 0.03779  time: 1.8752  data_time: 0.1912  lr: 0.00083916  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:07:21 d2.utils.events]: \u001b[0m eta: 7:33:50  iter: 439  total_loss: 0.8731  loss_cls: 0.4722  loss_box_reg: 0.3364  loss_rpn_cls: 0.03031  loss_rpn_loc: 0.03473  time: 1.8752  data_time: 0.1888  lr: 0.00087912  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:07:59 d2.utils.events]: \u001b[0m eta: 7:33:14  iter: 459  total_loss: 0.7947  loss_cls: 0.4331  loss_box_reg: 0.3031  loss_rpn_cls: 0.02578  loss_rpn_loc: 0.03183  time: 1.8754  data_time: 0.1965  lr: 0.00091908  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:08:37 d2.utils.events]: \u001b[0m eta: 7:32:36  iter: 479  total_loss: 0.8028  loss_cls: 0.43  loss_box_reg: 0.2881  loss_rpn_cls: 0.02841  loss_rpn_loc: 0.02843  time: 1.8754  data_time: 0.1947  lr: 0.00095904  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:09:14 d2.utils.events]: \u001b[0m eta: 7:32:01  iter: 499  total_loss: 0.7988  loss_cls: 0.4508  loss_box_reg: 0.314  loss_rpn_cls: 0.02838  loss_rpn_loc: 0.03395  time: 1.8755  data_time: 0.1958  lr: 0.000999  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:09:52 d2.utils.events]: \u001b[0m eta: 7:31:23  iter: 519  total_loss: 0.8362  loss_cls: 0.4539  loss_box_reg: 0.3094  loss_rpn_cls: 0.02744  loss_rpn_loc: 0.03754  time: 1.8753  data_time: 0.1883  lr: 0.001039  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:10:29 d2.utils.events]: \u001b[0m eta: 7:30:46  iter: 539  total_loss: 0.8293  loss_cls: 0.4663  loss_box_reg: 0.2929  loss_rpn_cls: 0.02717  loss_rpn_loc: 0.02935  time: 1.8754  data_time: 0.1932  lr: 0.0010789  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:11:07 d2.utils.events]: \u001b[0m eta: 7:30:12  iter: 559  total_loss: 0.8465  loss_cls: 0.4462  loss_box_reg: 0.3193  loss_rpn_cls: 0.02801  loss_rpn_loc: 0.04644  time: 1.8757  data_time: 0.1977  lr: 0.0011189  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:11:44 d2.utils.events]: \u001b[0m eta: 7:29:34  iter: 579  total_loss: 0.788  loss_cls: 0.4443  loss_box_reg: 0.3095  loss_rpn_cls: 0.02454  loss_rpn_loc: 0.03427  time: 1.8757  data_time: 0.1981  lr: 0.0011588  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:12:22 d2.utils.events]: \u001b[0m eta: 7:28:59  iter: 599  total_loss: 0.8073  loss_cls: 0.4282  loss_box_reg: 0.2943  loss_rpn_cls: 0.03477  loss_rpn_loc: 0.04246  time: 1.8760  data_time: 0.2017  lr: 0.0011988  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:13:00 d2.utils.events]: \u001b[0m eta: 7:28:22  iter: 619  total_loss: 0.7721  loss_cls: 0.3926  loss_box_reg: 0.2897  loss_rpn_cls: 0.02688  loss_rpn_loc: 0.03515  time: 1.8759  data_time: 0.1916  lr: 0.0012388  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:13:37 d2.utils.events]: \u001b[0m eta: 7:27:44  iter: 639  total_loss: 0.7192  loss_cls: 0.3722  loss_box_reg: 0.2759  loss_rpn_cls: 0.02077  loss_rpn_loc: 0.03209  time: 1.8759  data_time: 0.1917  lr: 0.0012787  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:14:15 d2.utils.events]: \u001b[0m eta: 7:27:08  iter: 659  total_loss: 0.8096  loss_cls: 0.4238  loss_box_reg: 0.3112  loss_rpn_cls: 0.02619  loss_rpn_loc: 0.03496  time: 1.8759  data_time: 0.1933  lr: 0.0013187  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:14:52 d2.utils.events]: \u001b[0m eta: 7:26:33  iter: 679  total_loss: 0.7645  loss_cls: 0.4132  loss_box_reg: 0.2671  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.03425  time: 1.8761  data_time: 0.1934  lr: 0.0013586  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:15:30 d2.utils.events]: \u001b[0m eta: 7:25:55  iter: 699  total_loss: 0.6797  loss_cls: 0.396  loss_box_reg: 0.2495  loss_rpn_cls: 0.01902  loss_rpn_loc: 0.02811  time: 1.8759  data_time: 0.1915  lr: 0.0013986  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:16:07 d2.utils.events]: \u001b[0m eta: 7:25:19  iter: 719  total_loss: 0.6838  loss_cls: 0.3671  loss_box_reg: 0.2647  loss_rpn_cls: 0.0222  loss_rpn_loc: 0.03117  time: 1.8759  data_time: 0.1914  lr: 0.0014386  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:16:45 d2.utils.events]: \u001b[0m eta: 7:24:41  iter: 739  total_loss: 0.68  loss_cls: 0.3706  loss_box_reg: 0.2546  loss_rpn_cls: 0.01924  loss_rpn_loc: 0.02876  time: 1.8759  data_time: 0.1944  lr: 0.0014785  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:17:23 d2.utils.events]: \u001b[0m eta: 7:24:08  iter: 759  total_loss: 0.7417  loss_cls: 0.3873  loss_box_reg: 0.2674  loss_rpn_cls: 0.02348  loss_rpn_loc: 0.03027  time: 1.8762  data_time: 0.1972  lr: 0.0015185  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:18:00 d2.utils.events]: \u001b[0m eta: 7:23:30  iter: 779  total_loss: 0.7328  loss_cls: 0.4013  loss_box_reg: 0.2787  loss_rpn_cls: 0.02277  loss_rpn_loc: 0.02855  time: 1.8762  data_time: 0.1945  lr: 0.0015584  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:18:38 d2.utils.events]: \u001b[0m eta: 7:22:55  iter: 799  total_loss: 0.7771  loss_cls: 0.4072  loss_box_reg: 0.2978  loss_rpn_cls: 0.02403  loss_rpn_loc: 0.03249  time: 1.8764  data_time: 0.1959  lr: 0.0015984  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:19:15 d2.utils.events]: \u001b[0m eta: 7:22:18  iter: 819  total_loss: 0.7503  loss_cls: 0.4262  loss_box_reg: 0.2758  loss_rpn_cls: 0.02347  loss_rpn_loc: 0.02339  time: 1.8763  data_time: 0.1886  lr: 0.0016384  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:19:53 d2.utils.events]: \u001b[0m eta: 7:21:40  iter: 839  total_loss: 0.7479  loss_cls: 0.4244  loss_box_reg: 0.281  loss_rpn_cls: 0.02082  loss_rpn_loc: 0.03652  time: 1.8763  data_time: 0.1945  lr: 0.0016783  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:20:30 d2.utils.events]: \u001b[0m eta: 7:21:03  iter: 859  total_loss: 0.7994  loss_cls: 0.4224  loss_box_reg: 0.2863  loss_rpn_cls: 0.02503  loss_rpn_loc: 0.04185  time: 1.8763  data_time: 0.1951  lr: 0.0017183  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:21:08 d2.utils.events]: \u001b[0m eta: 7:20:26  iter: 879  total_loss: 0.7065  loss_cls: 0.379  loss_box_reg: 0.261  loss_rpn_cls: 0.0224  loss_rpn_loc: 0.02985  time: 1.8763  data_time: 0.1965  lr: 0.0017582  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:21:46 d2.utils.events]: \u001b[0m eta: 7:19:50  iter: 899  total_loss: 0.6983  loss_cls: 0.3712  loss_box_reg: 0.2652  loss_rpn_cls: 0.02022  loss_rpn_loc: 0.03083  time: 1.8766  data_time: 0.2031  lr: 0.0017982  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:22:23 d2.utils.events]: \u001b[0m eta: 7:19:15  iter: 919  total_loss: 0.6911  loss_cls: 0.3801  loss_box_reg: 0.2502  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.03218  time: 1.8767  data_time: 0.1962  lr: 0.0018382  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:23:01 d2.utils.events]: \u001b[0m eta: 7:18:37  iter: 939  total_loss: 0.6587  loss_cls: 0.3514  loss_box_reg: 0.249  loss_rpn_cls: 0.0185  loss_rpn_loc: 0.03441  time: 1.8766  data_time: 0.1924  lr: 0.0018781  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:23:38 d2.utils.events]: \u001b[0m eta: 7:18:00  iter: 959  total_loss: 0.6781  loss_cls: 0.3749  loss_box_reg: 0.2388  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.02689  time: 1.8766  data_time: 0.1955  lr: 0.0019181  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:24:16 d2.utils.events]: \u001b[0m eta: 7:17:23  iter: 979  total_loss: 0.6756  loss_cls: 0.3477  loss_box_reg: 0.2704  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.0301  time: 1.8767  data_time: 0.1990  lr: 0.001958  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:24:53 d2.utils.events]: \u001b[0m eta: 7:16:46  iter: 999  total_loss: 0.631  loss_cls: 0.3522  loss_box_reg: 0.232  loss_rpn_cls: 0.01759  loss_rpn_loc: 0.02743  time: 1.8766  data_time: 0.1924  lr: 0.001998  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:25:31 d2.utils.events]: \u001b[0m eta: 7:16:07  iter: 1019  total_loss: 0.6655  loss_cls: 0.3703  loss_box_reg: 0.2453  loss_rpn_cls: 0.01845  loss_rpn_loc: 0.02798  time: 1.8766  data_time: 0.1921  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:26:08 d2.utils.events]: \u001b[0m eta: 7:15:31  iter: 1039  total_loss: 0.6544  loss_cls: 0.3488  loss_box_reg: 0.2557  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.03493  time: 1.8765  data_time: 0.1901  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:26:46 d2.utils.events]: \u001b[0m eta: 7:14:54  iter: 1059  total_loss: 0.6445  loss_cls: 0.3428  loss_box_reg: 0.2521  loss_rpn_cls: 0.02052  loss_rpn_loc: 0.03084  time: 1.8766  data_time: 0.1916  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:27:24 d2.utils.events]: \u001b[0m eta: 7:14:15  iter: 1079  total_loss: 0.6427  loss_cls: 0.3352  loss_box_reg: 0.2604  loss_rpn_cls: 0.01825  loss_rpn_loc: 0.0325  time: 1.8766  data_time: 0.1920  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:28:01 d2.utils.events]: \u001b[0m eta: 7:13:40  iter: 1099  total_loss: 0.6244  loss_cls: 0.3432  loss_box_reg: 0.2369  loss_rpn_cls: 0.01979  loss_rpn_loc: 0.02659  time: 1.8768  data_time: 0.2023  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:28:39 d2.utils.events]: \u001b[0m eta: 7:13:01  iter: 1119  total_loss: 0.6726  loss_cls: 0.3607  loss_box_reg: 0.2414  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.02183  time: 1.8767  data_time: 0.1921  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:29:16 d2.utils.events]: \u001b[0m eta: 7:12:25  iter: 1139  total_loss: 0.6577  loss_cls: 0.3502  loss_box_reg: 0.2574  loss_rpn_cls: 0.01824  loss_rpn_loc: 0.02929  time: 1.8767  data_time: 0.1949  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:29:54 d2.utils.events]: \u001b[0m eta: 7:11:55  iter: 1159  total_loss: 0.6877  loss_cls: 0.3746  loss_box_reg: 0.2593  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.03266  time: 1.8767  data_time: 0.1973  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:30:32 d2.utils.events]: \u001b[0m eta: 7:11:17  iter: 1179  total_loss: 0.654  loss_cls: 0.3584  loss_box_reg: 0.265  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.02805  time: 1.8770  data_time: 0.2054  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:31:09 d2.utils.events]: \u001b[0m eta: 7:10:40  iter: 1199  total_loss: 0.7038  loss_cls: 0.3717  loss_box_reg: 0.2575  loss_rpn_cls: 0.02195  loss_rpn_loc: 0.03461  time: 1.8771  data_time: 0.1982  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:31:47 d2.utils.events]: \u001b[0m eta: 7:10:05  iter: 1219  total_loss: 0.6739  loss_cls: 0.3622  loss_box_reg: 0.2521  loss_rpn_cls: 0.0213  loss_rpn_loc: 0.03304  time: 1.8771  data_time: 0.1967  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:32:25 d2.utils.events]: \u001b[0m eta: 7:09:25  iter: 1239  total_loss: 0.5583  loss_cls: 0.2913  loss_box_reg: 0.2243  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.02604  time: 1.8770  data_time: 0.1900  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:33:02 d2.utils.events]: \u001b[0m eta: 7:08:50  iter: 1259  total_loss: 0.5907  loss_cls: 0.3066  loss_box_reg: 0.2366  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.03466  time: 1.8771  data_time: 0.1975  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:33:40 d2.utils.events]: \u001b[0m eta: 7:08:08  iter: 1279  total_loss: 0.6073  loss_cls: 0.3187  loss_box_reg: 0.2392  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.02899  time: 1.8770  data_time: 0.1913  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:34:17 d2.utils.events]: \u001b[0m eta: 7:07:28  iter: 1299  total_loss: 0.5246  loss_cls: 0.2717  loss_box_reg: 0.2117  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.02792  time: 1.8771  data_time: 0.1978  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:34:55 d2.utils.events]: \u001b[0m eta: 7:06:48  iter: 1319  total_loss: 0.5755  loss_cls: 0.3067  loss_box_reg: 0.2252  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.02826  time: 1.8771  data_time: 0.1935  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:35:33 d2.utils.events]: \u001b[0m eta: 7:06:16  iter: 1339  total_loss: 0.6109  loss_cls: 0.3315  loss_box_reg: 0.2276  loss_rpn_cls: 0.01531  loss_rpn_loc: 0.02678  time: 1.8772  data_time: 0.1969  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:36:10 d2.utils.events]: \u001b[0m eta: 7:05:39  iter: 1359  total_loss: 0.5913  loss_cls: 0.3015  loss_box_reg: 0.223  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.03431  time: 1.8772  data_time: 0.1926  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:36:48 d2.utils.events]: \u001b[0m eta: 7:05:01  iter: 1379  total_loss: 0.5869  loss_cls: 0.3017  loss_box_reg: 0.2205  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.02434  time: 1.8771  data_time: 0.1930  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:37:25 d2.utils.events]: \u001b[0m eta: 7:04:27  iter: 1399  total_loss: 0.6034  loss_cls: 0.3209  loss_box_reg: 0.2349  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.02589  time: 1.8772  data_time: 0.1976  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:38:03 d2.utils.events]: \u001b[0m eta: 7:03:50  iter: 1419  total_loss: 0.6147  loss_cls: 0.315  loss_box_reg: 0.241  loss_rpn_cls: 0.01656  loss_rpn_loc: 0.03075  time: 1.8772  data_time: 0.1935  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:38:40 d2.utils.events]: \u001b[0m eta: 7:03:08  iter: 1439  total_loss: 0.5696  loss_cls: 0.3068  loss_box_reg: 0.22  loss_rpn_cls: 0.01517  loss_rpn_loc: 0.02832  time: 1.8771  data_time: 0.1913  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:39:18 d2.utils.events]: \u001b[0m eta: 7:02:29  iter: 1459  total_loss: 0.6093  loss_cls: 0.3296  loss_box_reg: 0.2278  loss_rpn_cls: 0.01576  loss_rpn_loc: 0.03424  time: 1.8771  data_time: 0.1891  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:39:55 d2.utils.events]: \u001b[0m eta: 7:01:56  iter: 1479  total_loss: 0.6292  loss_cls: 0.3176  loss_box_reg: 0.2439  loss_rpn_cls: 0.01536  loss_rpn_loc: 0.03585  time: 1.8771  data_time: 0.1941  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:40:33 d2.utils.events]: \u001b[0m eta: 7:01:16  iter: 1499  total_loss: 0.5804  loss_cls: 0.3251  loss_box_reg: 0.2186  loss_rpn_cls: 0.01446  loss_rpn_loc: 0.02558  time: 1.8771  data_time: 0.1914  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:41:10 d2.utils.events]: \u001b[0m eta: 7:00:42  iter: 1519  total_loss: 0.5952  loss_cls: 0.3264  loss_box_reg: 0.2263  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.03908  time: 1.8771  data_time: 0.1956  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:41:48 d2.utils.events]: \u001b[0m eta: 7:00:07  iter: 1539  total_loss: 0.5994  loss_cls: 0.3118  loss_box_reg: 0.2289  loss_rpn_cls: 0.01686  loss_rpn_loc: 0.03085  time: 1.8771  data_time: 0.1960  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:42:26 d2.utils.events]: \u001b[0m eta: 6:59:29  iter: 1559  total_loss: 0.5038  loss_cls: 0.2746  loss_box_reg: 0.1925  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.02419  time: 1.8772  data_time: 0.1976  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:43:03 d2.utils.events]: \u001b[0m eta: 6:58:54  iter: 1579  total_loss: 0.5536  loss_cls: 0.2848  loss_box_reg: 0.2018  loss_rpn_cls: 0.01477  loss_rpn_loc: 0.0303  time: 1.8773  data_time: 0.1964  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:43:41 d2.utils.events]: \u001b[0m eta: 6:58:16  iter: 1599  total_loss: 0.5644  loss_cls: 0.3001  loss_box_reg: 0.2149  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.03279  time: 1.8772  data_time: 0.1938  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:44:18 d2.utils.events]: \u001b[0m eta: 6:57:37  iter: 1619  total_loss: 0.5658  loss_cls: 0.2799  loss_box_reg: 0.2168  loss_rpn_cls: 0.01688  loss_rpn_loc: 0.0287  time: 1.8773  data_time: 0.1936  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:44:56 d2.utils.events]: \u001b[0m eta: 6:57:01  iter: 1639  total_loss: 0.5398  loss_cls: 0.2709  loss_box_reg: 0.2175  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.02953  time: 1.8773  data_time: 0.1931  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:45:34 d2.utils.events]: \u001b[0m eta: 6:56:24  iter: 1659  total_loss: 0.5494  loss_cls: 0.275  loss_box_reg: 0.2184  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.03148  time: 1.8774  data_time: 0.2000  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:46:11 d2.utils.events]: \u001b[0m eta: 6:55:43  iter: 1679  total_loss: 0.5102  loss_cls: 0.2708  loss_box_reg: 0.2001  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.02597  time: 1.8773  data_time: 0.1904  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:46:49 d2.utils.events]: \u001b[0m eta: 6:55:07  iter: 1699  total_loss: 0.539  loss_cls: 0.2865  loss_box_reg: 0.2137  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.0288  time: 1.8773  data_time: 0.1998  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:47:27 d2.utils.events]: \u001b[0m eta: 6:54:28  iter: 1719  total_loss: 0.5315  loss_cls: 0.2866  loss_box_reg: 0.2165  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.03281  time: 1.8774  data_time: 0.1920  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:48:04 d2.utils.events]: \u001b[0m eta: 6:53:53  iter: 1739  total_loss: 0.4978  loss_cls: 0.2423  loss_box_reg: 0.1941  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.02813  time: 1.8774  data_time: 0.1948  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:48:42 d2.utils.events]: \u001b[0m eta: 6:53:16  iter: 1759  total_loss: 0.5429  loss_cls: 0.2849  loss_box_reg: 0.2094  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.03169  time: 1.8775  data_time: 0.1997  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:49:20 d2.utils.events]: \u001b[0m eta: 6:52:42  iter: 1779  total_loss: 0.5437  loss_cls: 0.2875  loss_box_reg: 0.2178  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.02685  time: 1.8775  data_time: 0.1945  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:49:57 d2.utils.events]: \u001b[0m eta: 6:52:02  iter: 1799  total_loss: 0.5124  loss_cls: 0.271  loss_box_reg: 0.208  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.03454  time: 1.8776  data_time: 0.1960  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:50:35 d2.utils.events]: \u001b[0m eta: 6:51:27  iter: 1819  total_loss: 0.547  loss_cls: 0.2997  loss_box_reg: 0.2122  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.02809  time: 1.8776  data_time: 0.1954  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:51:12 d2.utils.events]: \u001b[0m eta: 6:50:49  iter: 1839  total_loss: 0.5154  loss_cls: 0.2629  loss_box_reg: 0.2088  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.02996  time: 1.8776  data_time: 0.1933  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:51:50 d2.utils.events]: \u001b[0m eta: 6:50:14  iter: 1859  total_loss: 0.5243  loss_cls: 0.2568  loss_box_reg: 0.2089  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.02764  time: 1.8776  data_time: 0.1945  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:52:28 d2.utils.events]: \u001b[0m eta: 6:49:39  iter: 1879  total_loss: 0.4938  loss_cls: 0.2475  loss_box_reg: 0.1823  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.02161  time: 1.8778  data_time: 0.2042  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:53:05 d2.utils.events]: \u001b[0m eta: 6:49:00  iter: 1899  total_loss: 0.4605  loss_cls: 0.2235  loss_box_reg: 0.195  loss_rpn_cls: 0.009533  loss_rpn_loc: 0.02737  time: 1.8778  data_time: 0.1974  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:53:43 d2.utils.events]: \u001b[0m eta: 6:48:21  iter: 1919  total_loss: 0.4807  loss_cls: 0.2313  loss_box_reg: 0.1912  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.02728  time: 1.8777  data_time: 0.1914  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:54:20 d2.utils.events]: \u001b[0m eta: 6:47:40  iter: 1939  total_loss: 0.5038  loss_cls: 0.2299  loss_box_reg: 0.2028  loss_rpn_cls: 0.009832  loss_rpn_loc: 0.02285  time: 1.8777  data_time: 0.1882  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:54:58 d2.utils.events]: \u001b[0m eta: 6:47:02  iter: 1959  total_loss: 0.4863  loss_cls: 0.2428  loss_box_reg: 0.2059  loss_rpn_cls: 0.009312  loss_rpn_loc: 0.02643  time: 1.8777  data_time: 0.1954  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:55:36 d2.utils.events]: \u001b[0m eta: 6:46:24  iter: 1979  total_loss: 0.4844  loss_cls: 0.2524  loss_box_reg: 0.1889  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.02191  time: 1.8778  data_time: 0.1943  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:56:13 d2.utils.events]: \u001b[0m eta: 6:45:46  iter: 1999  total_loss: 0.4522  loss_cls: 0.2313  loss_box_reg: 0.2085  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.02806  time: 1.8778  data_time: 0.1936  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:56:51 d2.utils.events]: \u001b[0m eta: 6:45:10  iter: 2019  total_loss: 0.5361  loss_cls: 0.2762  loss_box_reg: 0.2135  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.02222  time: 1.8778  data_time: 0.1950  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:57:28 d2.utils.events]: \u001b[0m eta: 6:44:32  iter: 2039  total_loss: 0.4892  loss_cls: 0.2436  loss_box_reg: 0.2029  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.02148  time: 1.8778  data_time: 0.1955  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:58:06 d2.utils.events]: \u001b[0m eta: 6:43:59  iter: 2059  total_loss: 0.4583  loss_cls: 0.2269  loss_box_reg: 0.1889  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.02629  time: 1.8779  data_time: 0.1933  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:58:44 d2.utils.events]: \u001b[0m eta: 6:43:23  iter: 2079  total_loss: 0.4625  loss_cls: 0.2406  loss_box_reg: 0.1839  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.02488  time: 1.8779  data_time: 0.1930  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:59:21 d2.utils.events]: \u001b[0m eta: 6:42:44  iter: 2099  total_loss: 0.5079  loss_cls: 0.258  loss_box_reg: 0.2095  loss_rpn_cls: 0.0105  loss_rpn_loc: 0.03033  time: 1.8778  data_time: 0.1889  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 10:59:59 d2.utils.events]: \u001b[0m eta: 6:42:05  iter: 2119  total_loss: 0.4503  loss_cls: 0.2578  loss_box_reg: 0.1817  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.02169  time: 1.8778  data_time: 0.1917  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:00:36 d2.utils.events]: \u001b[0m eta: 6:41:28  iter: 2139  total_loss: 0.5352  loss_cls: 0.281  loss_box_reg: 0.2095  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.03147  time: 1.8778  data_time: 0.1975  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:01:14 d2.utils.events]: \u001b[0m eta: 6:40:52  iter: 2159  total_loss: 0.4088  loss_cls: 0.2035  loss_box_reg: 0.1788  loss_rpn_cls: 0.009775  loss_rpn_loc: 0.0271  time: 1.8779  data_time: 0.1976  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:01:52 d2.utils.events]: \u001b[0m eta: 6:40:13  iter: 2179  total_loss: 0.4603  loss_cls: 0.22  loss_box_reg: 0.1851  loss_rpn_cls: 0.008325  loss_rpn_loc: 0.02465  time: 1.8779  data_time: 0.1917  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:02:29 d2.utils.events]: \u001b[0m eta: 6:39:36  iter: 2199  total_loss: 0.4614  loss_cls: 0.2334  loss_box_reg: 0.1937  loss_rpn_cls: 0.009601  loss_rpn_loc: 0.02632  time: 1.8779  data_time: 0.1901  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:03:07 d2.utils.events]: \u001b[0m eta: 6:38:58  iter: 2219  total_loss: 0.4416  loss_cls: 0.2309  loss_box_reg: 0.1865  loss_rpn_cls: 0.009314  loss_rpn_loc: 0.02362  time: 1.8779  data_time: 0.1930  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:03:44 d2.utils.events]: \u001b[0m eta: 6:38:23  iter: 2239  total_loss: 0.4629  loss_cls: 0.2328  loss_box_reg: 0.1951  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.02019  time: 1.8779  data_time: 0.1966  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:04:22 d2.utils.events]: \u001b[0m eta: 6:37:47  iter: 2259  total_loss: 0.4732  loss_cls: 0.2353  loss_box_reg: 0.195  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.03431  time: 1.8780  data_time: 0.1961  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:05:00 d2.utils.events]: \u001b[0m eta: 6:37:11  iter: 2279  total_loss: 0.4054  loss_cls: 0.1994  loss_box_reg: 0.1735  loss_rpn_cls: 0.008845  loss_rpn_loc: 0.02071  time: 1.8780  data_time: 0.1922  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:05:37 d2.utils.events]: \u001b[0m eta: 6:36:34  iter: 2299  total_loss: 0.4177  loss_cls: 0.2028  loss_box_reg: 0.1831  loss_rpn_cls: 0.009283  loss_rpn_loc: 0.02035  time: 1.8780  data_time: 0.1930  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:06:15 d2.utils.events]: \u001b[0m eta: 6:35:57  iter: 2319  total_loss: 0.4631  loss_cls: 0.204  loss_box_reg: 0.2011  loss_rpn_cls: 0.009447  loss_rpn_loc: 0.02559  time: 1.8780  data_time: 0.1951  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:06:52 d2.utils.events]: \u001b[0m eta: 6:35:19  iter: 2339  total_loss: 0.4599  loss_cls: 0.2247  loss_box_reg: 0.1849  loss_rpn_cls: 0.00944  loss_rpn_loc: 0.02905  time: 1.8780  data_time: 0.1916  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:07:30 d2.utils.events]: \u001b[0m eta: 6:34:44  iter: 2359  total_loss: 0.5171  loss_cls: 0.2522  loss_box_reg: 0.2203  loss_rpn_cls: 0.01015  loss_rpn_loc: 0.03105  time: 1.8780  data_time: 0.1958  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:08:08 d2.utils.events]: \u001b[0m eta: 6:34:09  iter: 2379  total_loss: 0.4551  loss_cls: 0.2317  loss_box_reg: 0.1881  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.02625  time: 1.8780  data_time: 0.1935  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:08:45 d2.utils.events]: \u001b[0m eta: 6:33:35  iter: 2399  total_loss: 0.5173  loss_cls: 0.2423  loss_box_reg: 0.2194  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.03189  time: 1.8780  data_time: 0.1908  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:09:23 d2.utils.events]: \u001b[0m eta: 6:32:56  iter: 2419  total_loss: 0.4799  loss_cls: 0.2156  loss_box_reg: 0.2034  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.03022  time: 1.8780  data_time: 0.1902  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:10:00 d2.utils.events]: \u001b[0m eta: 6:32:23  iter: 2439  total_loss: 0.4492  loss_cls: 0.2495  loss_box_reg: 0.18  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.02711  time: 1.8780  data_time: 0.1899  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:10:38 d2.utils.events]: \u001b[0m eta: 6:31:46  iter: 2459  total_loss: 0.4193  loss_cls: 0.198  loss_box_reg: 0.1783  loss_rpn_cls: 0.009124  loss_rpn_loc: 0.02612  time: 1.8780  data_time: 0.1943  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:11:15 d2.utils.events]: \u001b[0m eta: 6:31:07  iter: 2479  total_loss: 0.4178  loss_cls: 0.1915  loss_box_reg: 0.1762  loss_rpn_cls: 0.008483  loss_rpn_loc: 0.02592  time: 1.8780  data_time: 0.1931  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:11:53 d2.utils.events]: \u001b[0m eta: 6:30:29  iter: 2499  total_loss: 0.3933  loss_cls: 0.1876  loss_box_reg: 0.1762  loss_rpn_cls: 0.00976  loss_rpn_loc: 0.02188  time: 1.8780  data_time: 0.1971  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:12:31 d2.utils.events]: \u001b[0m eta: 6:29:51  iter: 2519  total_loss: 0.4187  loss_cls: 0.2051  loss_box_reg: 0.1987  loss_rpn_cls: 0.009078  loss_rpn_loc: 0.02938  time: 1.8780  data_time: 0.1903  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:13:08 d2.utils.events]: \u001b[0m eta: 6:29:16  iter: 2539  total_loss: 0.4221  loss_cls: 0.1946  loss_box_reg: 0.1913  loss_rpn_cls: 0.007896  loss_rpn_loc: 0.02482  time: 1.8780  data_time: 0.1896  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:13:46 d2.utils.events]: \u001b[0m eta: 6:28:36  iter: 2559  total_loss: 0.4205  loss_cls: 0.1863  loss_box_reg: 0.1904  loss_rpn_cls: 0.009196  loss_rpn_loc: 0.02317  time: 1.8780  data_time: 0.1905  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:14:23 d2.utils.events]: \u001b[0m eta: 6:27:58  iter: 2579  total_loss: 0.4074  loss_cls: 0.1852  loss_box_reg: 0.169  loss_rpn_cls: 0.008857  loss_rpn_loc: 0.02389  time: 1.8780  data_time: 0.1903  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:15:01 d2.utils.events]: \u001b[0m eta: 6:27:23  iter: 2599  total_loss: 0.4258  loss_cls: 0.1902  loss_box_reg: 0.1907  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.02859  time: 1.8781  data_time: 0.1991  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:15:39 d2.utils.events]: \u001b[0m eta: 6:26:46  iter: 2619  total_loss: 0.4339  loss_cls: 0.2015  loss_box_reg: 0.1884  loss_rpn_cls: 0.01057  loss_rpn_loc: 0.03145  time: 1.8781  data_time: 0.1928  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:16:16 d2.utils.events]: \u001b[0m eta: 6:26:10  iter: 2639  total_loss: 0.3958  loss_cls: 0.192  loss_box_reg: 0.1682  loss_rpn_cls: 0.007794  loss_rpn_loc: 0.02561  time: 1.8781  data_time: 0.1955  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:16:54 d2.utils.events]: \u001b[0m eta: 6:25:31  iter: 2659  total_loss: 0.3962  loss_cls: 0.1773  loss_box_reg: 0.1712  loss_rpn_cls: 0.008549  loss_rpn_loc: 0.03413  time: 1.8781  data_time: 0.1954  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:17:32 d2.utils.events]: \u001b[0m eta: 6:24:55  iter: 2679  total_loss: 0.4127  loss_cls: 0.198  loss_box_reg: 0.1656  loss_rpn_cls: 0.008598  loss_rpn_loc: 0.03184  time: 1.8781  data_time: 0.1904  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:18:09 d2.utils.events]: \u001b[0m eta: 6:24:20  iter: 2699  total_loss: 0.414  loss_cls: 0.197  loss_box_reg: 0.186  loss_rpn_cls: 0.007519  loss_rpn_loc: 0.02411  time: 1.8782  data_time: 0.1969  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:18:47 d2.utils.events]: \u001b[0m eta: 6:23:42  iter: 2719  total_loss: 0.431  loss_cls: 0.2122  loss_box_reg: 0.1761  loss_rpn_cls: 0.008864  loss_rpn_loc: 0.02462  time: 1.8782  data_time: 0.1910  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:19:25 d2.utils.events]: \u001b[0m eta: 6:23:05  iter: 2739  total_loss: 0.454  loss_cls: 0.2218  loss_box_reg: 0.1712  loss_rpn_cls: 0.007009  loss_rpn_loc: 0.0257  time: 1.8782  data_time: 0.1926  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:20:02 d2.utils.events]: \u001b[0m eta: 6:22:25  iter: 2759  total_loss: 0.4367  loss_cls: 0.2054  loss_box_reg: 0.1984  loss_rpn_cls: 0.008259  loss_rpn_loc: 0.02484  time: 1.8782  data_time: 0.1990  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:20:40 d2.utils.events]: \u001b[0m eta: 6:21:46  iter: 2779  total_loss: 0.4283  loss_cls: 0.1827  loss_box_reg: 0.178  loss_rpn_cls: 0.007539  loss_rpn_loc: 0.02785  time: 1.8782  data_time: 0.1926  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:21:17 d2.utils.events]: \u001b[0m eta: 6:21:11  iter: 2799  total_loss: 0.3999  loss_cls: 0.1667  loss_box_reg: 0.1866  loss_rpn_cls: 0.008101  loss_rpn_loc: 0.02805  time: 1.8782  data_time: 0.1898  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:21:55 d2.utils.events]: \u001b[0m eta: 6:20:31  iter: 2819  total_loss: 0.3356  loss_cls: 0.1502  loss_box_reg: 0.1573  loss_rpn_cls: 0.006239  loss_rpn_loc: 0.02151  time: 1.8782  data_time: 0.1993  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:22:33 d2.utils.events]: \u001b[0m eta: 6:19:55  iter: 2839  total_loss: 0.4059  loss_cls: 0.1823  loss_box_reg: 0.1804  loss_rpn_cls: 0.007116  loss_rpn_loc: 0.02422  time: 1.8783  data_time: 0.1997  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:23:10 d2.utils.events]: \u001b[0m eta: 6:19:16  iter: 2859  total_loss: 0.3654  loss_cls: 0.1681  loss_box_reg: 0.1634  loss_rpn_cls: 0.005917  loss_rpn_loc: 0.02133  time: 1.8784  data_time: 0.1968  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:23:48 d2.utils.events]: \u001b[0m eta: 6:18:37  iter: 2879  total_loss: 0.4192  loss_cls: 0.1869  loss_box_reg: 0.1955  loss_rpn_cls: 0.007509  loss_rpn_loc: 0.02408  time: 1.8784  data_time: 0.1946  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:24:26 d2.utils.events]: \u001b[0m eta: 6:18:00  iter: 2899  total_loss: 0.3625  loss_cls: 0.1718  loss_box_reg: 0.1554  loss_rpn_cls: 0.007294  loss_rpn_loc: 0.02566  time: 1.8783  data_time: 0.1897  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:25:03 d2.utils.events]: \u001b[0m eta: 6:17:24  iter: 2919  total_loss: 0.3704  loss_cls: 0.1571  loss_box_reg: 0.159  loss_rpn_cls: 0.008321  loss_rpn_loc: 0.03072  time: 1.8783  data_time: 0.1932  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:25:41 d2.utils.events]: \u001b[0m eta: 6:16:50  iter: 2939  total_loss: 0.4087  loss_cls: 0.187  loss_box_reg: 0.1778  loss_rpn_cls: 0.01077  loss_rpn_loc: 0.02962  time: 1.8784  data_time: 0.2015  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:26:19 d2.utils.events]: \u001b[0m eta: 6:16:13  iter: 2959  total_loss: 0.3914  loss_cls: 0.1789  loss_box_reg: 0.1754  loss_rpn_cls: 0.008227  loss_rpn_loc: 0.02512  time: 1.8785  data_time: 0.1963  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:26:56 d2.utils.events]: \u001b[0m eta: 6:15:35  iter: 2979  total_loss: 0.3902  loss_cls: 0.1845  loss_box_reg: 0.1775  loss_rpn_cls: 0.007821  loss_rpn_loc: 0.02018  time: 1.8785  data_time: 0.1947  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:27:36 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../../../dataset/test.json\n",
      "\u001b[32m[01/09 11:27:36 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 0            |    Paper    | 0            | Paper pack | 0            |\n",
      "|     Metal     | 0            |    Glass    | 0            |  Plastic   | 0            |\n",
      "|   Styrofoam   | 0            | Plastic bag | 0            |  Battery   | 0            |\n",
      "|   Clothing    | 0            |             |              |            |              |\n",
      "|     total     | 0            |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[01/09 11:27:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/09 11:27:36 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/09 11:27:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.53 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/09 11:27:36 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/09 11:27:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[01/09 11:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0012 s/iter. Inference: 0.0457 s/iter. Eval: 0.0002 s/iter. Total: 0.0472 s/iter. ETA=0:03:49\n",
      "\u001b[32m[01/09 11:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 121/4871. Dataloading: 0.0015 s/iter. Inference: 0.0440 s/iter. Eval: 0.0002 s/iter. Total: 0.0458 s/iter. ETA=0:03:37\n",
      "\u001b[32m[01/09 11:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 227/4871. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0002 s/iter. Total: 0.0465 s/iter. ETA=0:03:36\n",
      "\u001b[32m[01/09 11:27:52 d2.evaluation.evaluator]: \u001b[0mInference done 333/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0468 s/iter. ETA=0:03:32\n",
      "\u001b[32m[01/09 11:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 440/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0468 s/iter. ETA=0:03:27\n",
      "\u001b[32m[01/09 11:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 546/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0469 s/iter. ETA=0:03:22\n",
      "\u001b[32m[01/09 11:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 654/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0469 s/iter. ETA=0:03:17\n",
      "\u001b[32m[01/09 11:28:12 d2.evaluation.evaluator]: \u001b[0mInference done 766/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0002 s/iter. Total: 0.0466 s/iter. ETA=0:03:11\n",
      "\u001b[32m[01/09 11:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 876/4871. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0002 s/iter. Total: 0.0465 s/iter. ETA=0:03:05\n",
      "\u001b[32m[01/09 11:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 987/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:59\n",
      "\u001b[32m[01/09 11:28:27 d2.evaluation.evaluator]: \u001b[0mInference done 1094/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:02:55\n",
      "\u001b[32m[01/09 11:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 1201/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:02:50\n",
      "\u001b[32m[01/09 11:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 1312/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:44\n",
      "\u001b[32m[01/09 11:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 1416/4871. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0002 s/iter. Total: 0.0465 s/iter. ETA=0:02:40\n",
      "\u001b[32m[01/09 11:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 1522/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0002 s/iter. Total: 0.0465 s/iter. ETA=0:02:35\n",
      "\u001b[32m[01/09 11:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 1634/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:02:30\n",
      "\u001b[32m[01/09 11:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 1745/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:24\n",
      "\u001b[32m[01/09 11:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 1854/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:19\n",
      "\u001b[32m[01/09 11:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 1962/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:02:14\n",
      "\u001b[32m[01/09 11:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 2076/4871. Dataloading: 0.0015 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:02:09\n",
      "\u001b[32m[01/09 11:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 2182/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:04\n",
      "\u001b[32m[01/09 11:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 2295/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:58\n",
      "\u001b[32m[01/09 11:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 2403/4871. Dataloading: 0.0015 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:54\n",
      "\u001b[32m[01/09 11:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 2513/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:48\n",
      "\u001b[32m[01/09 11:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 2622/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:43\n",
      "\u001b[32m[01/09 11:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 2731/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:38\n",
      "\u001b[32m[01/09 11:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 2841/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:33\n",
      "\u001b[32m[01/09 11:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 2951/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:28\n",
      "\u001b[32m[01/09 11:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 3060/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:23\n",
      "\u001b[32m[01/09 11:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 3171/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:18\n",
      "\u001b[32m[01/09 11:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 3281/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:13\n",
      "\u001b[32m[01/09 11:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 3390/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:08\n",
      "\u001b[32m[01/09 11:30:17 d2.evaluation.evaluator]: \u001b[0mInference done 3496/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:03\n",
      "\u001b[32m[01/09 11:30:22 d2.evaluation.evaluator]: \u001b[0mInference done 3607/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:00:58\n",
      "\u001b[32m[01/09 11:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 3721/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:52\n",
      "\u001b[32m[01/09 11:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 3833/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:47\n",
      "\u001b[32m[01/09 11:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 3943/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:42\n",
      "\u001b[32m[01/09 11:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 4051/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:37\n",
      "\u001b[32m[01/09 11:30:48 d2.evaluation.evaluator]: \u001b[0mInference done 4162/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:32\n",
      "\u001b[32m[01/09 11:30:53 d2.evaluation.evaluator]: \u001b[0mInference done 4276/4871. Dataloading: 0.0015 s/iter. Inference: 0.0441 s/iter. Eval: 0.0002 s/iter. Total: 0.0459 s/iter. ETA=0:00:27\n",
      "\u001b[32m[01/09 11:30:58 d2.evaluation.evaluator]: \u001b[0mInference done 4386/4871. Dataloading: 0.0015 s/iter. Inference: 0.0441 s/iter. Eval: 0.0002 s/iter. Total: 0.0459 s/iter. ETA=0:00:22\n",
      "\u001b[32m[01/09 11:31:03 d2.evaluation.evaluator]: \u001b[0mInference done 4495/4871. Dataloading: 0.0015 s/iter. Inference: 0.0441 s/iter. Eval: 0.0002 s/iter. Total: 0.0459 s/iter. ETA=0:00:17\n",
      "\u001b[32m[01/09 11:31:08 d2.evaluation.evaluator]: \u001b[0mInference done 4604/4871. Dataloading: 0.0015 s/iter. Inference: 0.0441 s/iter. Eval: 0.0002 s/iter. Total: 0.0459 s/iter. ETA=0:00:12\n",
      "\u001b[32m[01/09 11:31:13 d2.evaluation.evaluator]: \u001b[0mInference done 4712/4871. Dataloading: 0.0015 s/iter. Inference: 0.0441 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:07\n",
      "\u001b[32m[01/09 11:31:18 d2.evaluation.evaluator]: \u001b[0mInference done 4819/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:02\n",
      "\u001b[32m[01/09 11:31:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:43.729667 (0.045978 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/09 11:31:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:34 (0.044134 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/09 11:31:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/09 11:31:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[01/09 11:31:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.40s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/09 11:31:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/09 11:31:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.70 seconds.\n",
      "\u001b[32m[01/09 11:31:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/09 11:31:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.21 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/09 11:31:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[01/09 11:31:24 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/09 11:31:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[01/09 11:31:24 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[01/09 11:31:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/09 11:31:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/09 11:31:24 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[01/09 11:31:24 d2.utils.events]: \u001b[0m eta: 6:14:58  iter: 2999  total_loss: 0.3717  loss_cls: 0.1535  loss_box_reg: 0.1623  loss_rpn_cls: 0.007349  loss_rpn_loc: 0.01992  time: 1.8785  data_time: 0.1961  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:32:02 d2.utils.events]: \u001b[0m eta: 6:14:21  iter: 3019  total_loss: 0.3616  loss_cls: 0.1781  loss_box_reg: 0.1606  loss_rpn_cls: 0.006407  loss_rpn_loc: 0.01898  time: 1.8785  data_time: 0.2023  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:32:39 d2.utils.events]: \u001b[0m eta: 6:13:45  iter: 3039  total_loss: 0.4258  loss_cls: 0.2055  loss_box_reg: 0.1844  loss_rpn_cls: 0.008935  loss_rpn_loc: 0.02917  time: 1.8786  data_time: 0.1994  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:33:17 d2.utils.events]: \u001b[0m eta: 6:13:07  iter: 3059  total_loss: 0.3636  loss_cls: 0.1688  loss_box_reg: 0.167  loss_rpn_cls: 0.00707  loss_rpn_loc: 0.01997  time: 1.8786  data_time: 0.1946  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:33:55 d2.utils.events]: \u001b[0m eta: 6:12:31  iter: 3079  total_loss: 0.337  loss_cls: 0.1548  loss_box_reg: 0.1606  loss_rpn_cls: 0.005785  loss_rpn_loc: 0.01986  time: 1.8786  data_time: 0.1974  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:34:32 d2.utils.events]: \u001b[0m eta: 6:11:56  iter: 3099  total_loss: 0.389  loss_cls: 0.1753  loss_box_reg: 0.1827  loss_rpn_cls: 0.006804  loss_rpn_loc: 0.01985  time: 1.8786  data_time: 0.1901  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:35:10 d2.utils.events]: \u001b[0m eta: 6:11:24  iter: 3119  total_loss: 0.3175  loss_cls: 0.1521  loss_box_reg: 0.1566  loss_rpn_cls: 0.007522  loss_rpn_loc: 0.02231  time: 1.8787  data_time: 0.2043  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:35:48 d2.utils.events]: \u001b[0m eta: 6:10:49  iter: 3139  total_loss: 0.3973  loss_cls: 0.1781  loss_box_reg: 0.1837  loss_rpn_cls: 0.006312  loss_rpn_loc: 0.02396  time: 1.8787  data_time: 0.1955  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:36:25 d2.utils.events]: \u001b[0m eta: 6:10:12  iter: 3159  total_loss: 0.3067  loss_cls: 0.1373  loss_box_reg: 0.1433  loss_rpn_cls: 0.005198  loss_rpn_loc: 0.01702  time: 1.8787  data_time: 0.1941  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:37:03 d2.utils.events]: \u001b[0m eta: 6:09:35  iter: 3179  total_loss: 0.3513  loss_cls: 0.1528  loss_box_reg: 0.1619  loss_rpn_cls: 0.006794  loss_rpn_loc: 0.02248  time: 1.8787  data_time: 0.1955  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:37:41 d2.utils.events]: \u001b[0m eta: 6:08:56  iter: 3199  total_loss: 0.3552  loss_cls: 0.1697  loss_box_reg: 0.1528  loss_rpn_cls: 0.007228  loss_rpn_loc: 0.02624  time: 1.8788  data_time: 0.1974  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:38:18 d2.utils.events]: \u001b[0m eta: 6:08:21  iter: 3219  total_loss: 0.3764  loss_cls: 0.1644  loss_box_reg: 0.163  loss_rpn_cls: 0.00696  loss_rpn_loc: 0.03408  time: 1.8788  data_time: 0.1956  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:38:56 d2.utils.events]: \u001b[0m eta: 6:07:43  iter: 3239  total_loss: 0.3964  loss_cls: 0.1864  loss_box_reg: 0.1804  loss_rpn_cls: 0.007581  loss_rpn_loc: 0.03286  time: 1.8789  data_time: 0.1992  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:39:34 d2.utils.events]: \u001b[0m eta: 6:07:06  iter: 3259  total_loss: 0.3569  loss_cls: 0.1542  loss_box_reg: 0.1566  loss_rpn_cls: 0.006773  loss_rpn_loc: 0.02192  time: 1.8789  data_time: 0.1955  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:40:11 d2.utils.events]: \u001b[0m eta: 6:06:27  iter: 3279  total_loss: 0.3654  loss_cls: 0.1645  loss_box_reg: 0.1531  loss_rpn_cls: 0.006958  loss_rpn_loc: 0.02609  time: 1.8789  data_time: 0.1930  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:40:49 d2.utils.events]: \u001b[0m eta: 6:05:51  iter: 3299  total_loss: 0.3769  loss_cls: 0.1835  loss_box_reg: 0.1745  loss_rpn_cls: 0.007102  loss_rpn_loc: 0.02434  time: 1.8789  data_time: 0.2008  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:41:27 d2.utils.events]: \u001b[0m eta: 6:05:14  iter: 3319  total_loss: 0.3289  loss_cls: 0.1393  loss_box_reg: 0.159  loss_rpn_cls: 0.007137  loss_rpn_loc: 0.02205  time: 1.8790  data_time: 0.1977  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:42:05 d2.utils.events]: \u001b[0m eta: 6:04:37  iter: 3339  total_loss: 0.3797  loss_cls: 0.1591  loss_box_reg: 0.1754  loss_rpn_cls: 0.006658  loss_rpn_loc: 0.02162  time: 1.8790  data_time: 0.1964  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:42:42 d2.utils.events]: \u001b[0m eta: 6:04:00  iter: 3359  total_loss: 0.3697  loss_cls: 0.1566  loss_box_reg: 0.1785  loss_rpn_cls: 0.006245  loss_rpn_loc: 0.01979  time: 1.8790  data_time: 0.1971  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:43:20 d2.utils.events]: \u001b[0m eta: 6:03:24  iter: 3379  total_loss: 0.2999  loss_cls: 0.1271  loss_box_reg: 0.1564  loss_rpn_cls: 0.006206  loss_rpn_loc: 0.02077  time: 1.8791  data_time: 0.1978  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:43:58 d2.utils.events]: \u001b[0m eta: 6:02:47  iter: 3399  total_loss: 0.3237  loss_cls: 0.1299  loss_box_reg: 0.1613  loss_rpn_cls: 0.005205  loss_rpn_loc: 0.02473  time: 1.8791  data_time: 0.1991  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:44:36 d2.utils.events]: \u001b[0m eta: 6:02:14  iter: 3419  total_loss: 0.3102  loss_cls: 0.1204  loss_box_reg: 0.1571  loss_rpn_cls: 0.005254  loss_rpn_loc: 0.02171  time: 1.8792  data_time: 0.2023  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:45:13 d2.utils.events]: \u001b[0m eta: 6:01:38  iter: 3439  total_loss: 0.3748  loss_cls: 0.1587  loss_box_reg: 0.1781  loss_rpn_cls: 0.005734  loss_rpn_loc: 0.02515  time: 1.8792  data_time: 0.1926  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:45:51 d2.utils.events]: \u001b[0m eta: 6:01:02  iter: 3459  total_loss: 0.3497  loss_cls: 0.1412  loss_box_reg: 0.1537  loss_rpn_cls: 0.005715  loss_rpn_loc: 0.02484  time: 1.8792  data_time: 0.1930  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:46:29 d2.utils.events]: \u001b[0m eta: 6:00:26  iter: 3479  total_loss: 0.336  loss_cls: 0.1362  loss_box_reg: 0.1634  loss_rpn_cls: 0.006444  loss_rpn_loc: 0.02313  time: 1.8792  data_time: 0.1958  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:47:06 d2.utils.events]: \u001b[0m eta: 5:59:50  iter: 3499  total_loss: 0.3654  loss_cls: 0.1531  loss_box_reg: 0.1683  loss_rpn_cls: 0.006667  loss_rpn_loc: 0.02463  time: 1.8793  data_time: 0.1986  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:47:44 d2.utils.events]: \u001b[0m eta: 5:59:14  iter: 3519  total_loss: 0.3282  loss_cls: 0.157  loss_box_reg: 0.1547  loss_rpn_cls: 0.005493  loss_rpn_loc: 0.02186  time: 1.8793  data_time: 0.1942  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:48:22 d2.utils.events]: \u001b[0m eta: 5:58:36  iter: 3539  total_loss: 0.3375  loss_cls: 0.1459  loss_box_reg: 0.1571  loss_rpn_cls: 0.005138  loss_rpn_loc: 0.02317  time: 1.8793  data_time: 0.1954  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:48:59 d2.utils.events]: \u001b[0m eta: 5:57:59  iter: 3559  total_loss: 0.3364  loss_cls: 0.1552  loss_box_reg: 0.1624  loss_rpn_cls: 0.006139  loss_rpn_loc: 0.02323  time: 1.8793  data_time: 0.1943  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:49:37 d2.utils.events]: \u001b[0m eta: 5:57:22  iter: 3579  total_loss: 0.3223  loss_cls: 0.1368  loss_box_reg: 0.1605  loss_rpn_cls: 0.006538  loss_rpn_loc: 0.0211  time: 1.8794  data_time: 0.2020  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:50:15 d2.utils.events]: \u001b[0m eta: 5:56:44  iter: 3599  total_loss: 0.3415  loss_cls: 0.1443  loss_box_reg: 0.1555  loss_rpn_cls: 0.006841  loss_rpn_loc: 0.02291  time: 1.8794  data_time: 0.1987  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:50:53 d2.utils.events]: \u001b[0m eta: 5:56:07  iter: 3619  total_loss: 0.3682  loss_cls: 0.1599  loss_box_reg: 0.165  loss_rpn_cls: 0.006171  loss_rpn_loc: 0.02294  time: 1.8794  data_time: 0.1939  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:51:30 d2.utils.events]: \u001b[0m eta: 5:55:29  iter: 3639  total_loss: 0.364  loss_cls: 0.1386  loss_box_reg: 0.1593  loss_rpn_cls: 0.006278  loss_rpn_loc: 0.01925  time: 1.8794  data_time: 0.1930  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:52:08 d2.utils.events]: \u001b[0m eta: 5:54:51  iter: 3659  total_loss: 0.3288  loss_cls: 0.1417  loss_box_reg: 0.1574  loss_rpn_cls: 0.007234  loss_rpn_loc: 0.02513  time: 1.8794  data_time: 0.1912  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:52:45 d2.utils.events]: \u001b[0m eta: 5:54:15  iter: 3679  total_loss: 0.3063  loss_cls: 0.1365  loss_box_reg: 0.1447  loss_rpn_cls: 0.004297  loss_rpn_loc: 0.02043  time: 1.8794  data_time: 0.1987  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:53:23 d2.utils.events]: \u001b[0m eta: 5:53:36  iter: 3699  total_loss: 0.3005  loss_cls: 0.1172  loss_box_reg: 0.1563  loss_rpn_cls: 0.004671  loss_rpn_loc: 0.02037  time: 1.8795  data_time: 0.1969  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:54:01 d2.utils.events]: \u001b[0m eta: 5:53:01  iter: 3719  total_loss: 0.3001  loss_cls: 0.1206  loss_box_reg: 0.1539  loss_rpn_cls: 0.004103  loss_rpn_loc: 0.02082  time: 1.8795  data_time: 0.1953  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:54:39 d2.utils.events]: \u001b[0m eta: 5:52:25  iter: 3739  total_loss: 0.2994  loss_cls: 0.1224  loss_box_reg: 0.1428  loss_rpn_cls: 0.004825  loss_rpn_loc: 0.02274  time: 1.8796  data_time: 0.1962  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:55:16 d2.utils.events]: \u001b[0m eta: 5:51:49  iter: 3759  total_loss: 0.3167  loss_cls: 0.1365  loss_box_reg: 0.1628  loss_rpn_cls: 0.005629  loss_rpn_loc: 0.02205  time: 1.8796  data_time: 0.1978  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:55:54 d2.utils.events]: \u001b[0m eta: 5:51:12  iter: 3779  total_loss: 0.3153  loss_cls: 0.1254  loss_box_reg: 0.1581  loss_rpn_cls: 0.00489  loss_rpn_loc: 0.01967  time: 1.8796  data_time: 0.1937  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:56:32 d2.utils.events]: \u001b[0m eta: 5:50:34  iter: 3799  total_loss: 0.2772  loss_cls: 0.1159  loss_box_reg: 0.1534  loss_rpn_cls: 0.00397  loss_rpn_loc: 0.01583  time: 1.8796  data_time: 0.1924  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:57:09 d2.utils.events]: \u001b[0m eta: 5:49:57  iter: 3819  total_loss: 0.2969  loss_cls: 0.1238  loss_box_reg: 0.1441  loss_rpn_cls: 0.004583  loss_rpn_loc: 0.01828  time: 1.8796  data_time: 0.1942  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:57:47 d2.utils.events]: \u001b[0m eta: 5:49:19  iter: 3839  total_loss: 0.3394  loss_cls: 0.137  loss_box_reg: 0.1619  loss_rpn_cls: 0.005182  loss_rpn_loc: 0.02223  time: 1.8796  data_time: 0.1960  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:58:25 d2.utils.events]: \u001b[0m eta: 5:48:40  iter: 3859  total_loss: 0.3191  loss_cls: 0.1441  loss_box_reg: 0.155  loss_rpn_cls: 0.00492  loss_rpn_loc: 0.02865  time: 1.8796  data_time: 0.1943  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:59:02 d2.utils.events]: \u001b[0m eta: 5:48:04  iter: 3879  total_loss: 0.3326  loss_cls: 0.1383  loss_box_reg: 0.1505  loss_rpn_cls: 0.005139  loss_rpn_loc: 0.02959  time: 1.8797  data_time: 0.2013  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 11:59:40 d2.utils.events]: \u001b[0m eta: 5:47:30  iter: 3899  total_loss: 0.3193  loss_cls: 0.1351  loss_box_reg: 0.1576  loss_rpn_cls: 0.006055  loss_rpn_loc: 0.02256  time: 1.8797  data_time: 0.1952  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:00:18 d2.utils.events]: \u001b[0m eta: 5:46:55  iter: 3919  total_loss: 0.3592  loss_cls: 0.1465  loss_box_reg: 0.1682  loss_rpn_cls: 0.006982  loss_rpn_loc: 0.02364  time: 1.8798  data_time: 0.2042  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:00:56 d2.utils.events]: \u001b[0m eta: 5:46:17  iter: 3939  total_loss: 0.3226  loss_cls: 0.1223  loss_box_reg: 0.1556  loss_rpn_cls: 0.004903  loss_rpn_loc: 0.02723  time: 1.8798  data_time: 0.1960  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:01:33 d2.utils.events]: \u001b[0m eta: 5:45:39  iter: 3959  total_loss: 0.2685  loss_cls: 0.1218  loss_box_reg: 0.1385  loss_rpn_cls: 0.003828  loss_rpn_loc: 0.01558  time: 1.8798  data_time: 0.1930  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:02:11 d2.utils.events]: \u001b[0m eta: 5:45:01  iter: 3979  total_loss: 0.2974  loss_cls: 0.1191  loss_box_reg: 0.1578  loss_rpn_cls: 0.003522  loss_rpn_loc: 0.01961  time: 1.8798  data_time: 0.1909  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:02:49 d2.utils.events]: \u001b[0m eta: 5:44:22  iter: 3999  total_loss: 0.2862  loss_cls: 0.1082  loss_box_reg: 0.1464  loss_rpn_cls: 0.004233  loss_rpn_loc: 0.02104  time: 1.8798  data_time: 0.1923  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:03:26 d2.utils.events]: \u001b[0m eta: 5:43:46  iter: 4019  total_loss: 0.2618  loss_cls: 0.09992  loss_box_reg: 0.1477  loss_rpn_cls: 0.00353  loss_rpn_loc: 0.022  time: 1.8799  data_time: 0.2017  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:04:04 d2.utils.events]: \u001b[0m eta: 5:43:10  iter: 4039  total_loss: 0.3032  loss_cls: 0.1179  loss_box_reg: 0.1497  loss_rpn_cls: 0.004788  loss_rpn_loc: 0.02435  time: 1.8799  data_time: 0.1994  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:04:42 d2.utils.events]: \u001b[0m eta: 5:42:33  iter: 4059  total_loss: 0.2937  loss_cls: 0.1196  loss_box_reg: 0.1464  loss_rpn_cls: 0.004257  loss_rpn_loc: 0.02196  time: 1.8799  data_time: 0.1952  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:05:19 d2.utils.events]: \u001b[0m eta: 5:41:54  iter: 4079  total_loss: 0.2861  loss_cls: 0.1163  loss_box_reg: 0.1478  loss_rpn_cls: 0.004041  loss_rpn_loc: 0.02077  time: 1.8799  data_time: 0.1951  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:05:57 d2.utils.events]: \u001b[0m eta: 5:41:19  iter: 4099  total_loss: 0.2979  loss_cls: 0.1085  loss_box_reg: 0.1562  loss_rpn_cls: 0.004322  loss_rpn_loc: 0.024  time: 1.8799  data_time: 0.1942  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:06:35 d2.utils.events]: \u001b[0m eta: 5:40:38  iter: 4119  total_loss: 0.3024  loss_cls: 0.1194  loss_box_reg: 0.1543  loss_rpn_cls: 0.004339  loss_rpn_loc: 0.02284  time: 1.8799  data_time: 0.1938  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:07:12 d2.utils.events]: \u001b[0m eta: 5:39:58  iter: 4139  total_loss: 0.25  loss_cls: 0.1031  loss_box_reg: 0.1325  loss_rpn_cls: 0.003873  loss_rpn_loc: 0.014  time: 1.8799  data_time: 0.1904  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:07:50 d2.utils.events]: \u001b[0m eta: 5:39:21  iter: 4159  total_loss: 0.3157  loss_cls: 0.1209  loss_box_reg: 0.1547  loss_rpn_cls: 0.004138  loss_rpn_loc: 0.01852  time: 1.8799  data_time: 0.1967  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:08:28 d2.utils.events]: \u001b[0m eta: 5:38:43  iter: 4179  total_loss: 0.287  loss_cls: 0.1096  loss_box_reg: 0.1447  loss_rpn_cls: 0.004681  loss_rpn_loc: 0.02088  time: 1.8800  data_time: 0.1959  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:09:05 d2.utils.events]: \u001b[0m eta: 5:38:07  iter: 4199  total_loss: 0.296  loss_cls: 0.1224  loss_box_reg: 0.1548  loss_rpn_cls: 0.005112  loss_rpn_loc: 0.02239  time: 1.8800  data_time: 0.2003  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:09:43 d2.utils.events]: \u001b[0m eta: 5:37:28  iter: 4219  total_loss: 0.2871  loss_cls: 0.1164  loss_box_reg: 0.146  loss_rpn_cls: 0.005047  loss_rpn_loc: 0.02676  time: 1.8800  data_time: 0.1997  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:10:21 d2.utils.events]: \u001b[0m eta: 5:36:53  iter: 4239  total_loss: 0.2952  loss_cls: 0.11  loss_box_reg: 0.1491  loss_rpn_cls: 0.004504  loss_rpn_loc: 0.02369  time: 1.8800  data_time: 0.1946  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:10:59 d2.utils.events]: \u001b[0m eta: 5:36:14  iter: 4259  total_loss: 0.2958  loss_cls: 0.1196  loss_box_reg: 0.1494  loss_rpn_cls: 0.004328  loss_rpn_loc: 0.01792  time: 1.8801  data_time: 0.1968  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:11:36 d2.utils.events]: \u001b[0m eta: 5:35:37  iter: 4279  total_loss: 0.2981  loss_cls: 0.1197  loss_box_reg: 0.1493  loss_rpn_cls: 0.004059  loss_rpn_loc: 0.0225  time: 1.8801  data_time: 0.1936  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:12:14 d2.utils.events]: \u001b[0m eta: 5:34:57  iter: 4299  total_loss: 0.292  loss_cls: 0.1002  loss_box_reg: 0.1425  loss_rpn_cls: 0.004226  loss_rpn_loc: 0.02136  time: 1.8801  data_time: 0.1936  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:12:52 d2.utils.events]: \u001b[0m eta: 5:34:18  iter: 4319  total_loss: 0.2923  loss_cls: 0.1108  loss_box_reg: 0.1505  loss_rpn_cls: 0.00527  loss_rpn_loc: 0.0267  time: 1.8801  data_time: 0.1967  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:13:29 d2.utils.events]: \u001b[0m eta: 5:33:42  iter: 4339  total_loss: 0.2861  loss_cls: 0.09787  loss_box_reg: 0.1536  loss_rpn_cls: 0.003424  loss_rpn_loc: 0.01883  time: 1.8801  data_time: 0.1941  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:14:07 d2.utils.events]: \u001b[0m eta: 5:33:05  iter: 4359  total_loss: 0.2711  loss_cls: 0.1055  loss_box_reg: 0.1433  loss_rpn_cls: 0.004088  loss_rpn_loc: 0.01863  time: 1.8801  data_time: 0.2007  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:14:45 d2.utils.events]: \u001b[0m eta: 5:32:29  iter: 4379  total_loss: 0.2578  loss_cls: 0.09332  loss_box_reg: 0.1378  loss_rpn_cls: 0.003868  loss_rpn_loc: 0.02148  time: 1.8802  data_time: 0.2027  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:15:23 d2.utils.events]: \u001b[0m eta: 5:31:49  iter: 4399  total_loss: 0.2834  loss_cls: 0.1124  loss_box_reg: 0.1424  loss_rpn_cls: 0.003735  loss_rpn_loc: 0.02373  time: 1.8802  data_time: 0.2005  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:16:00 d2.utils.events]: \u001b[0m eta: 5:31:11  iter: 4419  total_loss: 0.2797  loss_cls: 0.1089  loss_box_reg: 0.1529  loss_rpn_cls: 0.004014  loss_rpn_loc: 0.01965  time: 1.8802  data_time: 0.1957  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:16:38 d2.utils.events]: \u001b[0m eta: 5:30:34  iter: 4439  total_loss: 0.2797  loss_cls: 0.1028  loss_box_reg: 0.1463  loss_rpn_cls: 0.003946  loss_rpn_loc: 0.01991  time: 1.8803  data_time: 0.1941  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:17:16 d2.utils.events]: \u001b[0m eta: 5:29:57  iter: 4459  total_loss: 0.2739  loss_cls: 0.101  loss_box_reg: 0.1468  loss_rpn_cls: 0.004065  loss_rpn_loc: 0.02104  time: 1.8803  data_time: 0.1910  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:17:53 d2.utils.events]: \u001b[0m eta: 5:29:19  iter: 4479  total_loss: 0.2947  loss_cls: 0.1246  loss_box_reg: 0.1436  loss_rpn_cls: 0.004696  loss_rpn_loc: 0.02334  time: 1.8803  data_time: 0.1956  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:18:31 d2.utils.events]: \u001b[0m eta: 5:28:40  iter: 4499  total_loss: 0.2922  loss_cls: 0.1161  loss_box_reg: 0.1513  loss_rpn_cls: 0.00426  loss_rpn_loc: 0.02289  time: 1.8803  data_time: 0.1949  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:19:09 d2.utils.events]: \u001b[0m eta: 5:28:03  iter: 4519  total_loss: 0.321  loss_cls: 0.1264  loss_box_reg: 0.1552  loss_rpn_cls: 0.004014  loss_rpn_loc: 0.0276  time: 1.8803  data_time: 0.1975  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:19:47 d2.utils.events]: \u001b[0m eta: 5:27:27  iter: 4539  total_loss: 0.2676  loss_cls: 0.1043  loss_box_reg: 0.1372  loss_rpn_cls: 0.003705  loss_rpn_loc: 0.01833  time: 1.8803  data_time: 0.1971  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:20:24 d2.utils.events]: \u001b[0m eta: 5:26:52  iter: 4559  total_loss: 0.3031  loss_cls: 0.1201  loss_box_reg: 0.1546  loss_rpn_cls: 0.004732  loss_rpn_loc: 0.02241  time: 1.8803  data_time: 0.1933  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:21:02 d2.utils.events]: \u001b[0m eta: 5:26:13  iter: 4579  total_loss: 0.264  loss_cls: 0.09495  loss_box_reg: 0.1329  loss_rpn_cls: 0.004063  loss_rpn_loc: 0.01811  time: 1.8804  data_time: 0.1948  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:21:40 d2.utils.events]: \u001b[0m eta: 5:25:34  iter: 4599  total_loss: 0.2702  loss_cls: 0.09583  loss_box_reg: 0.1437  loss_rpn_cls: 0.003811  loss_rpn_loc: 0.02174  time: 1.8804  data_time: 0.1953  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:22:17 d2.utils.events]: \u001b[0m eta: 5:24:57  iter: 4619  total_loss: 0.2685  loss_cls: 0.09909  loss_box_reg: 0.1463  loss_rpn_cls: 0.003712  loss_rpn_loc: 0.02284  time: 1.8804  data_time: 0.1950  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:22:55 d2.utils.events]: \u001b[0m eta: 5:24:22  iter: 4639  total_loss: 0.2975  loss_cls: 0.1134  loss_box_reg: 0.1478  loss_rpn_cls: 0.004178  loss_rpn_loc: 0.02596  time: 1.8804  data_time: 0.1981  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:23:33 d2.utils.events]: \u001b[0m eta: 5:23:48  iter: 4659  total_loss: 0.2481  loss_cls: 0.09384  loss_box_reg: 0.1281  loss_rpn_cls: 0.003753  loss_rpn_loc: 0.01789  time: 1.8804  data_time: 0.1999  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:24:10 d2.utils.events]: \u001b[0m eta: 5:23:12  iter: 4679  total_loss: 0.2632  loss_cls: 0.1021  loss_box_reg: 0.1388  loss_rpn_cls: 0.003333  loss_rpn_loc: 0.02268  time: 1.8804  data_time: 0.1929  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:24:48 d2.utils.events]: \u001b[0m eta: 5:22:34  iter: 4699  total_loss: 0.2565  loss_cls: 0.09311  loss_box_reg: 0.1403  loss_rpn_cls: 0.004268  loss_rpn_loc: 0.02392  time: 1.8805  data_time: 0.1937  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:25:26 d2.utils.events]: \u001b[0m eta: 5:21:55  iter: 4719  total_loss: 0.2737  loss_cls: 0.08724  loss_box_reg: 0.1386  loss_rpn_cls: 0.003063  loss_rpn_loc: 0.01995  time: 1.8805  data_time: 0.1958  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:26:04 d2.utils.events]: \u001b[0m eta: 5:21:17  iter: 4739  total_loss: 0.2478  loss_cls: 0.08866  loss_box_reg: 0.1396  loss_rpn_cls: 0.00365  loss_rpn_loc: 0.01807  time: 1.8805  data_time: 0.1993  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:26:41 d2.utils.events]: \u001b[0m eta: 5:20:39  iter: 4759  total_loss: 0.2628  loss_cls: 0.09703  loss_box_reg: 0.1458  loss_rpn_cls: 0.003861  loss_rpn_loc: 0.02252  time: 1.8805  data_time: 0.1976  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:27:19 d2.utils.events]: \u001b[0m eta: 5:20:02  iter: 4779  total_loss: 0.2687  loss_cls: 0.09742  loss_box_reg: 0.143  loss_rpn_cls: 0.003247  loss_rpn_loc: 0.01861  time: 1.8805  data_time: 0.1944  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:27:57 d2.utils.events]: \u001b[0m eta: 5:19:25  iter: 4799  total_loss: 0.2777  loss_cls: 0.09819  loss_box_reg: 0.1437  loss_rpn_cls: 0.003685  loss_rpn_loc: 0.02225  time: 1.8806  data_time: 0.1995  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:28:34 d2.utils.events]: \u001b[0m eta: 5:18:47  iter: 4819  total_loss: 0.2542  loss_cls: 0.09839  loss_box_reg: 0.1331  loss_rpn_cls: 0.003591  loss_rpn_loc: 0.0201  time: 1.8806  data_time: 0.1911  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:29:12 d2.utils.events]: \u001b[0m eta: 5:18:11  iter: 4839  total_loss: 0.2637  loss_cls: 0.1012  loss_box_reg: 0.1428  loss_rpn_cls: 0.002938  loss_rpn_loc: 0.01602  time: 1.8806  data_time: 0.1986  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:29:50 d2.utils.events]: \u001b[0m eta: 5:17:32  iter: 4859  total_loss: 0.2585  loss_cls: 0.09154  loss_box_reg: 0.1399  loss_rpn_cls: 0.003421  loss_rpn_loc: 0.0193  time: 1.8806  data_time: 0.1951  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:30:28 d2.utils.events]: \u001b[0m eta: 5:16:56  iter: 4879  total_loss: 0.2493  loss_cls: 0.09222  loss_box_reg: 0.1258  loss_rpn_cls: 0.002323  loss_rpn_loc: 0.02112  time: 1.8806  data_time: 0.1970  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:31:05 d2.utils.events]: \u001b[0m eta: 5:16:17  iter: 4899  total_loss: 0.2235  loss_cls: 0.07715  loss_box_reg: 0.1223  loss_rpn_cls: 0.003209  loss_rpn_loc: 0.01963  time: 1.8806  data_time: 0.1917  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:31:43 d2.utils.events]: \u001b[0m eta: 5:15:39  iter: 4919  total_loss: 0.2518  loss_cls: 0.09976  loss_box_reg: 0.1321  loss_rpn_cls: 0.003589  loss_rpn_loc: 0.01744  time: 1.8807  data_time: 0.1996  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:32:21 d2.utils.events]: \u001b[0m eta: 5:15:03  iter: 4939  total_loss: 0.2712  loss_cls: 0.1016  loss_box_reg: 0.1449  loss_rpn_cls: 0.002876  loss_rpn_loc: 0.02166  time: 1.8807  data_time: 0.2005  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:32:59 d2.utils.events]: \u001b[0m eta: 5:14:27  iter: 4959  total_loss: 0.2668  loss_cls: 0.09899  loss_box_reg: 0.1421  loss_rpn_cls: 0.003364  loss_rpn_loc: 0.02007  time: 1.8807  data_time: 0.1920  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:33:36 d2.utils.events]: \u001b[0m eta: 5:13:50  iter: 4979  total_loss: 0.2518  loss_cls: 0.08608  loss_box_reg: 0.135  loss_rpn_cls: 0.00343  loss_rpn_loc: 0.02491  time: 1.8808  data_time: 0.1949  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:34:14 d2.utils.events]: \u001b[0m eta: 5:13:17  iter: 4999  total_loss: 0.2366  loss_cls: 0.08442  loss_box_reg: 0.1289  loss_rpn_cls: 0.003399  loss_rpn_loc: 0.02345  time: 1.8808  data_time: 0.2018  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:34:52 d2.utils.events]: \u001b[0m eta: 5:12:38  iter: 5019  total_loss: 0.2799  loss_cls: 0.1079  loss_box_reg: 0.146  loss_rpn_cls: 0.003172  loss_rpn_loc: 0.02213  time: 1.8808  data_time: 0.1943  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:35:30 d2.utils.events]: \u001b[0m eta: 5:12:00  iter: 5039  total_loss: 0.245  loss_cls: 0.09032  loss_box_reg: 0.1261  loss_rpn_cls: 0.003018  loss_rpn_loc: 0.01802  time: 1.8809  data_time: 0.2048  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:36:08 d2.utils.events]: \u001b[0m eta: 5:11:23  iter: 5059  total_loss: 0.2592  loss_cls: 0.09535  loss_box_reg: 0.1382  loss_rpn_cls: 0.00341  loss_rpn_loc: 0.02115  time: 1.8809  data_time: 0.1967  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:36:46 d2.utils.events]: \u001b[0m eta: 5:10:47  iter: 5079  total_loss: 0.231  loss_cls: 0.08618  loss_box_reg: 0.124  loss_rpn_cls: 0.002564  loss_rpn_loc: 0.01672  time: 1.8810  data_time: 0.2032  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:37:23 d2.utils.events]: \u001b[0m eta: 5:10:09  iter: 5099  total_loss: 0.2277  loss_cls: 0.07859  loss_box_reg: 0.1283  loss_rpn_cls: 0.003563  loss_rpn_loc: 0.01864  time: 1.8810  data_time: 0.2000  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:38:01 d2.utils.events]: \u001b[0m eta: 5:09:31  iter: 5119  total_loss: 0.2606  loss_cls: 0.08666  loss_box_reg: 0.1378  loss_rpn_cls: 0.003035  loss_rpn_loc: 0.02047  time: 1.8810  data_time: 0.1963  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:38:39 d2.utils.events]: \u001b[0m eta: 5:08:54  iter: 5139  total_loss: 0.2399  loss_cls: 0.08451  loss_box_reg: 0.1306  loss_rpn_cls: 0.002602  loss_rpn_loc: 0.01587  time: 1.8810  data_time: 0.1897  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:39:16 d2.utils.events]: \u001b[0m eta: 5:08:18  iter: 5159  total_loss: 0.2442  loss_cls: 0.09874  loss_box_reg: 0.1303  loss_rpn_cls: 0.003035  loss_rpn_loc: 0.01808  time: 1.8810  data_time: 0.1964  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:39:54 d2.utils.events]: \u001b[0m eta: 5:07:44  iter: 5179  total_loss: 0.296  loss_cls: 0.1095  loss_box_reg: 0.1434  loss_rpn_cls: 0.003877  loss_rpn_loc: 0.02634  time: 1.8810  data_time: 0.1991  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:40:32 d2.utils.events]: \u001b[0m eta: 5:07:08  iter: 5199  total_loss: 0.2363  loss_cls: 0.09076  loss_box_reg: 0.128  loss_rpn_cls: 0.003212  loss_rpn_loc: 0.01608  time: 1.8811  data_time: 0.2029  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:41:10 d2.utils.events]: \u001b[0m eta: 5:06:29  iter: 5219  total_loss: 0.2182  loss_cls: 0.07888  loss_box_reg: 0.1208  loss_rpn_cls: 0.002374  loss_rpn_loc: 0.01828  time: 1.8811  data_time: 0.2010  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:41:48 d2.utils.events]: \u001b[0m eta: 5:05:50  iter: 5239  total_loss: 0.256  loss_cls: 0.09325  loss_box_reg: 0.134  loss_rpn_cls: 0.003241  loss_rpn_loc: 0.0239  time: 1.8812  data_time: 0.1998  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:42:26 d2.utils.events]: \u001b[0m eta: 5:05:15  iter: 5259  total_loss: 0.2275  loss_cls: 0.07789  loss_box_reg: 0.1243  loss_rpn_cls: 0.002644  loss_rpn_loc: 0.02165  time: 1.8812  data_time: 0.2017  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:43:03 d2.utils.events]: \u001b[0m eta: 5:04:40  iter: 5279  total_loss: 0.2246  loss_cls: 0.08622  loss_box_reg: 0.1223  loss_rpn_cls: 0.002655  loss_rpn_loc: 0.01905  time: 1.8812  data_time: 0.1969  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:43:41 d2.utils.events]: \u001b[0m eta: 5:04:00  iter: 5299  total_loss: 0.2391  loss_cls: 0.08088  loss_box_reg: 0.1321  loss_rpn_cls: 0.003255  loss_rpn_loc: 0.02629  time: 1.8812  data_time: 0.1900  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:44:19 d2.utils.events]: \u001b[0m eta: 5:03:23  iter: 5319  total_loss: 0.2568  loss_cls: 0.08476  loss_box_reg: 0.1338  loss_rpn_cls: 0.003453  loss_rpn_loc: 0.02273  time: 1.8812  data_time: 0.1956  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:44:56 d2.utils.events]: \u001b[0m eta: 5:02:44  iter: 5339  total_loss: 0.2353  loss_cls: 0.07464  loss_box_reg: 0.1347  loss_rpn_cls: 0.002519  loss_rpn_loc: 0.01837  time: 1.8812  data_time: 0.1916  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:45:34 d2.utils.events]: \u001b[0m eta: 5:02:05  iter: 5359  total_loss: 0.2459  loss_cls: 0.08103  loss_box_reg: 0.1288  loss_rpn_cls: 0.00351  loss_rpn_loc: 0.02301  time: 1.8812  data_time: 0.1983  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:46:12 d2.utils.events]: \u001b[0m eta: 5:01:26  iter: 5379  total_loss: 0.2441  loss_cls: 0.09062  loss_box_reg: 0.1263  loss_rpn_cls: 0.003781  loss_rpn_loc: 0.0222  time: 1.8813  data_time: 0.1990  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:46:49 d2.utils.events]: \u001b[0m eta: 5:00:48  iter: 5399  total_loss: 0.2392  loss_cls: 0.07614  loss_box_reg: 0.1267  loss_rpn_cls: 0.002959  loss_rpn_loc: 0.01985  time: 1.8813  data_time: 0.2001  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:47:28 d2.utils.events]: \u001b[0m eta: 5:00:14  iter: 5419  total_loss: 0.2613  loss_cls: 0.08878  loss_box_reg: 0.1371  loss_rpn_cls: 0.00257  loss_rpn_loc: 0.02321  time: 1.8814  data_time: 0.2122  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:48:05 d2.utils.events]: \u001b[0m eta: 4:59:38  iter: 5439  total_loss: 0.2486  loss_cls: 0.09411  loss_box_reg: 0.1317  loss_rpn_cls: 0.003139  loss_rpn_loc: 0.02266  time: 1.8814  data_time: 0.2006  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:48:43 d2.utils.events]: \u001b[0m eta: 4:59:02  iter: 5459  total_loss: 0.2382  loss_cls: 0.0794  loss_box_reg: 0.1303  loss_rpn_cls: 0.00257  loss_rpn_loc: 0.02099  time: 1.8815  data_time: 0.2052  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:49:21 d2.utils.events]: \u001b[0m eta: 4:58:27  iter: 5479  total_loss: 0.2638  loss_cls: 0.09388  loss_box_reg: 0.1391  loss_rpn_cls: 0.003742  loss_rpn_loc: 0.02041  time: 1.8815  data_time: 0.1961  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:49:59 d2.utils.events]: \u001b[0m eta: 4:57:50  iter: 5499  total_loss: 0.2151  loss_cls: 0.07755  loss_box_reg: 0.1253  loss_rpn_cls: 0.003379  loss_rpn_loc: 0.01963  time: 1.8815  data_time: 0.1960  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:50:36 d2.utils.events]: \u001b[0m eta: 4:57:13  iter: 5519  total_loss: 0.233  loss_cls: 0.07498  loss_box_reg: 0.1312  loss_rpn_cls: 0.002571  loss_rpn_loc: 0.01945  time: 1.8815  data_time: 0.1950  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:51:14 d2.utils.events]: \u001b[0m eta: 4:56:37  iter: 5539  total_loss: 0.2367  loss_cls: 0.07983  loss_box_reg: 0.1342  loss_rpn_cls: 0.00264  loss_rpn_loc: 0.01822  time: 1.8815  data_time: 0.1972  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:51:52 d2.utils.events]: \u001b[0m eta: 4:55:59  iter: 5559  total_loss: 0.2332  loss_cls: 0.07426  loss_box_reg: 0.129  loss_rpn_cls: 0.00291  loss_rpn_loc: 0.01909  time: 1.8816  data_time: 0.1964  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:52:30 d2.utils.events]: \u001b[0m eta: 4:55:20  iter: 5579  total_loss: 0.2316  loss_cls: 0.08196  loss_box_reg: 0.1264  loss_rpn_cls: 0.002579  loss_rpn_loc: 0.02456  time: 1.8816  data_time: 0.1915  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:53:08 d2.utils.events]: \u001b[0m eta: 4:54:44  iter: 5599  total_loss: 0.2363  loss_cls: 0.08047  loss_box_reg: 0.1299  loss_rpn_cls: 0.00279  loss_rpn_loc: 0.02077  time: 1.8816  data_time: 0.2022  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:53:45 d2.utils.events]: \u001b[0m eta: 4:54:06  iter: 5619  total_loss: 0.2034  loss_cls: 0.06617  loss_box_reg: 0.1117  loss_rpn_cls: 0.002117  loss_rpn_loc: 0.01556  time: 1.8816  data_time: 0.1913  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:54:23 d2.utils.events]: \u001b[0m eta: 4:53:28  iter: 5639  total_loss: 0.2152  loss_cls: 0.07086  loss_box_reg: 0.1262  loss_rpn_cls: 0.002972  loss_rpn_loc: 0.0176  time: 1.8816  data_time: 0.1933  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:55:01 d2.utils.events]: \u001b[0m eta: 4:52:50  iter: 5659  total_loss: 0.2268  loss_cls: 0.07595  loss_box_reg: 0.1277  loss_rpn_cls: 0.002453  loss_rpn_loc: 0.01821  time: 1.8816  data_time: 0.1938  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:55:38 d2.utils.events]: \u001b[0m eta: 4:52:12  iter: 5679  total_loss: 0.2104  loss_cls: 0.0742  loss_box_reg: 0.1184  loss_rpn_cls: 0.002237  loss_rpn_loc: 0.01763  time: 1.8816  data_time: 0.1906  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:56:16 d2.utils.events]: \u001b[0m eta: 4:51:34  iter: 5699  total_loss: 0.2505  loss_cls: 0.07871  loss_box_reg: 0.1345  loss_rpn_cls: 0.002373  loss_rpn_loc: 0.01806  time: 1.8816  data_time: 0.1923  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:56:53 d2.utils.events]: \u001b[0m eta: 4:50:55  iter: 5719  total_loss: 0.2139  loss_cls: 0.07502  loss_box_reg: 0.1196  loss_rpn_cls: 0.002745  loss_rpn_loc: 0.02256  time: 1.8816  data_time: 0.1879  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:57:31 d2.utils.events]: \u001b[0m eta: 4:50:19  iter: 5739  total_loss: 0.2291  loss_cls: 0.07966  loss_box_reg: 0.1279  loss_rpn_cls: 0.002476  loss_rpn_loc: 0.02292  time: 1.8816  data_time: 0.2003  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:58:09 d2.utils.events]: \u001b[0m eta: 4:49:42  iter: 5759  total_loss: 0.2292  loss_cls: 0.07967  loss_box_reg: 0.1245  loss_rpn_cls: 0.002706  loss_rpn_loc: 0.01506  time: 1.8816  data_time: 0.1993  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:58:47 d2.utils.events]: \u001b[0m eta: 4:49:04  iter: 5779  total_loss: 0.2585  loss_cls: 0.08129  loss_box_reg: 0.143  loss_rpn_cls: 0.002652  loss_rpn_loc: 0.01917  time: 1.8817  data_time: 0.1922  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 12:59:25 d2.utils.events]: \u001b[0m eta: 4:48:26  iter: 5799  total_loss: 0.2419  loss_cls: 0.0799  loss_box_reg: 0.12  loss_rpn_cls: 0.00353  loss_rpn_loc: 0.0197  time: 1.8817  data_time: 0.1938  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:00:02 d2.utils.events]: \u001b[0m eta: 4:47:49  iter: 5819  total_loss: 0.2414  loss_cls: 0.07465  loss_box_reg: 0.1325  loss_rpn_cls: 0.002351  loss_rpn_loc: 0.02328  time: 1.8817  data_time: 0.1943  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:00:40 d2.utils.events]: \u001b[0m eta: 4:47:10  iter: 5839  total_loss: 0.2082  loss_cls: 0.06682  loss_box_reg: 0.1179  loss_rpn_cls: 0.002221  loss_rpn_loc: 0.02107  time: 1.8817  data_time: 0.1939  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:01:18 d2.utils.events]: \u001b[0m eta: 4:46:33  iter: 5859  total_loss: 0.2109  loss_cls: 0.07102  loss_box_reg: 0.1154  loss_rpn_cls: 0.002477  loss_rpn_loc: 0.02155  time: 1.8817  data_time: 0.1928  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:01:55 d2.utils.events]: \u001b[0m eta: 4:45:53  iter: 5879  total_loss: 0.2059  loss_cls: 0.06232  loss_box_reg: 0.1158  loss_rpn_cls: 0.001885  loss_rpn_loc: 0.01729  time: 1.8817  data_time: 0.1944  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:02:33 d2.utils.events]: \u001b[0m eta: 4:45:14  iter: 5899  total_loss: 0.213  loss_cls: 0.07397  loss_box_reg: 0.1242  loss_rpn_cls: 0.002639  loss_rpn_loc: 0.01792  time: 1.8817  data_time: 0.1974  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:03:11 d2.utils.events]: \u001b[0m eta: 4:44:35  iter: 5919  total_loss: 0.2274  loss_cls: 0.07564  loss_box_reg: 0.1312  loss_rpn_cls: 0.002633  loss_rpn_loc: 0.02201  time: 1.8817  data_time: 0.1941  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:03:48 d2.utils.events]: \u001b[0m eta: 4:43:57  iter: 5939  total_loss: 0.2045  loss_cls: 0.07273  loss_box_reg: 0.1181  loss_rpn_cls: 0.002305  loss_rpn_loc: 0.01731  time: 1.8817  data_time: 0.1963  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:04:26 d2.utils.events]: \u001b[0m eta: 4:43:20  iter: 5959  total_loss: 0.202  loss_cls: 0.07151  loss_box_reg: 0.1146  loss_rpn_cls: 0.002553  loss_rpn_loc: 0.01756  time: 1.8817  data_time: 0.1963  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:05:04 d2.utils.events]: \u001b[0m eta: 4:42:42  iter: 5979  total_loss: 0.2479  loss_cls: 0.08318  loss_box_reg: 0.1327  loss_rpn_cls: 0.002932  loss_rpn_loc: 0.01858  time: 1.8817  data_time: 0.1951  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:05:43 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../../../dataset/test.json\n",
      "\u001b[32m[01/09 13:05:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/09 13:05:43 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/09 13:05:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.53 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/09 13:05:43 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/09 13:05:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[01/09 13:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0017 s/iter. Inference: 0.0448 s/iter. Eval: 0.0002 s/iter. Total: 0.0467 s/iter. ETA=0:03:47\n",
      "\u001b[32m[01/09 13:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 119/4871. Dataloading: 0.0015 s/iter. Inference: 0.0448 s/iter. Eval: 0.0002 s/iter. Total: 0.0466 s/iter. ETA=0:03:41\n",
      "\u001b[32m[01/09 13:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 225/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0469 s/iter. ETA=0:03:37\n",
      "\u001b[32m[01/09 13:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 330/4871. Dataloading: 0.0016 s/iter. Inference: 0.0454 s/iter. Eval: 0.0002 s/iter. Total: 0.0472 s/iter. ETA=0:03:34\n",
      "\u001b[32m[01/09 13:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 438/4871. Dataloading: 0.0016 s/iter. Inference: 0.0452 s/iter. Eval: 0.0002 s/iter. Total: 0.0471 s/iter. ETA=0:03:28\n",
      "\u001b[32m[01/09 13:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 545/4871. Dataloading: 0.0015 s/iter. Inference: 0.0452 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:03:23\n",
      "\u001b[32m[01/09 13:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 655/4871. Dataloading: 0.0015 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0468 s/iter. ETA=0:03:17\n",
      "\u001b[32m[01/09 13:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 767/4871. Dataloading: 0.0015 s/iter. Inference: 0.0447 s/iter. Eval: 0.0002 s/iter. Total: 0.0465 s/iter. ETA=0:03:10\n",
      "\u001b[32m[01/09 13:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 879/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:03:04\n",
      "\u001b[32m[01/09 13:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 989/4871. Dataloading: 0.0015 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:02:59\n",
      "\u001b[32m[01/09 13:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 1095/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:54\n",
      "\u001b[32m[01/09 13:06:39 d2.evaluation.evaluator]: \u001b[0mInference done 1202/4871. Dataloading: 0.0015 s/iter. Inference: 0.0446 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:02:50\n",
      "\u001b[32m[01/09 13:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 1307/4871. Dataloading: 0.0015 s/iter. Inference: 0.0447 s/iter. Eval: 0.0002 s/iter. Total: 0.0465 s/iter. ETA=0:02:45\n",
      "\u001b[32m[01/09 13:06:49 d2.evaluation.evaluator]: \u001b[0mInference done 1420/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:39\n",
      "\u001b[32m[01/09 13:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 1530/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:34\n",
      "\u001b[32m[01/09 13:06:59 d2.evaluation.evaluator]: \u001b[0mInference done 1635/4871. Dataloading: 0.0015 s/iter. Inference: 0.0446 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:02:30\n",
      "\u001b[32m[01/09 13:07:04 d2.evaluation.evaluator]: \u001b[0mInference done 1745/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:24\n",
      "\u001b[32m[01/09 13:07:09 d2.evaluation.evaluator]: \u001b[0mInference done 1856/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:19\n",
      "\u001b[32m[01/09 13:07:14 d2.evaluation.evaluator]: \u001b[0mInference done 1969/4871. Dataloading: 0.0015 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:02:14\n",
      "\u001b[32m[01/09 13:07:20 d2.evaluation.evaluator]: \u001b[0mInference done 2073/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:09\n",
      "\u001b[32m[01/09 13:07:25 d2.evaluation.evaluator]: \u001b[0mInference done 2179/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:02:04\n",
      "\u001b[32m[01/09 13:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 2287/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:01:59\n",
      "\u001b[32m[01/09 13:07:35 d2.evaluation.evaluator]: \u001b[0mInference done 2393/4871. Dataloading: 0.0015 s/iter. Inference: 0.0446 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:01:54\n",
      "\u001b[32m[01/09 13:07:40 d2.evaluation.evaluator]: \u001b[0mInference done 2501/4871. Dataloading: 0.0015 s/iter. Inference: 0.0446 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:01:49\n",
      "\u001b[32m[01/09 13:07:45 d2.evaluation.evaluator]: \u001b[0mInference done 2609/4871. Dataloading: 0.0015 s/iter. Inference: 0.0446 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:01:44\n",
      "\u001b[32m[01/09 13:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 2720/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:01:39\n",
      "\u001b[32m[01/09 13:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 2829/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:01:34\n",
      "\u001b[32m[01/09 13:08:00 d2.evaluation.evaluator]: \u001b[0mInference done 2939/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:01:29\n",
      "\u001b[32m[01/09 13:08:05 d2.evaluation.evaluator]: \u001b[0mInference done 3048/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:01:24\n",
      "\u001b[32m[01/09 13:08:10 d2.evaluation.evaluator]: \u001b[0mInference done 3161/4871. Dataloading: 0.0015 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:19\n",
      "\u001b[32m[01/09 13:08:15 d2.evaluation.evaluator]: \u001b[0mInference done 3272/4871. Dataloading: 0.0015 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:13\n",
      "\u001b[32m[01/09 13:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 3384/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:08\n",
      "\u001b[32m[01/09 13:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 3493/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:03\n",
      "\u001b[32m[01/09 13:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 3603/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:00:58\n",
      "\u001b[32m[01/09 13:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 3713/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:00:53\n",
      "\u001b[32m[01/09 13:08:40 d2.evaluation.evaluator]: \u001b[0mInference done 3824/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:00:48\n",
      "\u001b[32m[01/09 13:08:45 d2.evaluation.evaluator]: \u001b[0mInference done 3936/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:43\n",
      "\u001b[32m[01/09 13:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 4047/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:37\n",
      "\u001b[32m[01/09 13:08:55 d2.evaluation.evaluator]: \u001b[0mInference done 4156/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:32\n",
      "\u001b[32m[01/09 13:09:00 d2.evaluation.evaluator]: \u001b[0mInference done 4264/4871. Dataloading: 0.0015 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:00:27\n",
      "\u001b[32m[01/09 13:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 4364/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:00:23\n",
      "\u001b[32m[01/09 13:09:10 d2.evaluation.evaluator]: \u001b[0mInference done 4473/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:00:18\n",
      "\u001b[32m[01/09 13:09:15 d2.evaluation.evaluator]: \u001b[0mInference done 4580/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:00:13\n",
      "\u001b[32m[01/09 13:09:20 d2.evaluation.evaluator]: \u001b[0mInference done 4688/4871. Dataloading: 0.0015 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/09 13:09:25 d2.evaluation.evaluator]: \u001b[0mInference done 4795/4871. Dataloading: 0.0015 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:00:03\n",
      "\u001b[32m[01/09 13:09:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:44.771205 (0.046192 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/09 13:09:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:35 (0.044366 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/09 13:09:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/09 13:09:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[01/09 13:09:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/09 13:09:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/09 13:09:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.79 seconds.\n",
      "\u001b[32m[01/09 13:09:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/09 13:09:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.18 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/09 13:09:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[01/09 13:09:32 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/09 13:09:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[01/09 13:09:32 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[01/09 13:09:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/09 13:09:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/09 13:09:32 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[01/09 13:09:32 d2.utils.events]: \u001b[0m eta: 4:42:03  iter: 5999  total_loss: 0.2216  loss_cls: 0.06995  loss_box_reg: 0.1229  loss_rpn_cls: 0.002157  loss_rpn_loc: 0.01577  time: 1.8817  data_time: 0.1921  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:10:10 d2.utils.events]: \u001b[0m eta: 4:41:26  iter: 6019  total_loss: 0.2521  loss_cls: 0.08444  loss_box_reg: 0.1387  loss_rpn_cls: 0.002622  loss_rpn_loc: 0.01968  time: 1.8818  data_time: 0.1998  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:10:48 d2.utils.events]: \u001b[0m eta: 4:40:49  iter: 6039  total_loss: 0.2265  loss_cls: 0.07996  loss_box_reg: 0.1229  loss_rpn_cls: 0.002649  loss_rpn_loc: 0.01852  time: 1.8818  data_time: 0.2036  lr: 0.002  max_mem: 25340M\n",
      "\u001b[32m[01/09 13:10:52 d2.engine.hooks]: \u001b[0mOverall training speed: 6040 iterations in 3:09:27 (1.8820 s / it)\n",
      "\u001b[32m[01/09 13:10:52 d2.engine.hooks]: \u001b[0mTotal training time: 3:17:12 (0:07:45 on hooks)\n",
      "\u001b[32m[01/09 13:10:52 d2.utils.events]: \u001b[0m eta: 4:40:44  iter: 6042  total_loss: 0.2265  loss_cls: 0.07996  loss_box_reg: 0.1229  loss_rpn_cls: 0.002649  loss_rpn_loc: 0.01738  time: 1.8818  data_time: 0.2021  lr: 0.002  max_mem: 25340M\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/engine/defaults.py:489\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m    Run training.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m        OrderedDict of results, if evaluation is enabled. Otherwise None.\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mTEST\u001b[38;5;241m.\u001b[39mEXPECTED_RESULTS) \u001b[38;5;129;01mand\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mis_main_process():\n\u001b[1;32m    491\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    492\u001b[0m             \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_last_eval_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    493\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo evaluation results obtained during training!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/engine/train_loop.py:149\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iter, max_iter):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_step()\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/engine/defaults.py:499\u001b[0m, in \u001b[0;36mDefaultTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/engine/train_loop.py:273\u001b[0m, in \u001b[0;36mSimpleTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m data_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03mIf you want to do something with the losses, you can wrap the model.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_dict, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    275\u001b[0m     losses \u001b[38;5;241m=\u001b[39m loss_dict\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/modeling/meta_arch/rcnn.py:157\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(images\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproposal_generator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     proposals, proposal_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproposal_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_instances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batched_inputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/modeling/proposal_generator/rpn.py:471\u001b[0m, in \u001b[0;36mRPN.forward\u001b[0;34m(self, images, features, gt_instances)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m gt_instances \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPN requires gt_instances in training!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 471\u001b[0m     gt_labels, gt_boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_and_sample_anchors\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_instances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses(\n\u001b[1;32m    473\u001b[0m         anchors, pred_objectness_logits, gt_labels, pred_anchor_deltas, gt_boxes\n\u001b[1;32m    474\u001b[0m     )\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/modeling/proposal_generator/rpn.py:340\u001b[0m, in \u001b[0;36mRPN.label_and_sample_anchors\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03mimage_size_i: (h, w) for the i-th image\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mgt_boxes_i: ground-truth boxes for i-th image\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m match_quality_matrix \u001b[38;5;241m=\u001b[39m retry_if_cuda_oom(pairwise_iou)(gt_boxes_i, anchors)\n\u001b[0;32m--> 340\u001b[0m matched_idxs, gt_labels_i \u001b[38;5;241m=\u001b[39m \u001b[43mretry_if_cuda_oom\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manchor_matcher\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch_quality_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Matching is memory-expensive and may result in CPU tensors. But the result is small\u001b[39;00m\n\u001b[1;32m    342\u001b[0m gt_labels_i \u001b[38;5;241m=\u001b[39m gt_labels_i\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mgt_boxes_i\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/utils/memory.py:70\u001b[0m, in \u001b[0;36mretry_if_cuda_oom.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _ignore_torch_cuda_oom():\n\u001b[0;32m---> 70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Clear cache and retry\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/modeling/matcher.py:88\u001b[0m, in \u001b[0;36mMatcher.__call__\u001b[0;34m(self, match_quality_matrix)\u001b[0m\n\u001b[1;32m     83\u001b[0m     default_match_labels \u001b[38;5;241m=\u001b[39m match_quality_matrix\u001b[38;5;241m.\u001b[39mnew_full(\n\u001b[1;32m     84\u001b[0m         (match_quality_matrix\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m),), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint8\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_matches, default_match_labels\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(match_quality_matrix \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# match_quality_matrix is M (gt) x N (predicted)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Max over gt elements (dim 0) to find best gt candidate for each prediction\u001b[39;00m\n\u001b[1;32m     92\u001b[0m matched_vals, matches \u001b[38;5;241m=\u001b[39m match_quality_matrix\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
