{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only on the first execution\n",
    "# !python setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_train', {}, '../../../dataset/train.json', '../../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '../../../dataset/test.json', '../../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 0\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml')\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (8000,12000)\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 3000\n",
    "\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 12\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "import detectron2.data.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "        T.RandomBrightness(0.8, 1.5),\n",
    "        # T.RandomContrast(0.6, 1.3),\n",
    "        T.Resize(1024)\n",
    "        # A.Resize(1024, 1024),\n",
    "        # ToTensorV2(p=0.1)\n",
    "\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/08 15:45:34 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=13, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=48, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/08 15:45:34 d2.data.datasets.coco]: \u001b[0mLoaded 4883 images in COCO format from ../../../dataset/train.json\n",
      "\u001b[32m[01/08 15:45:34 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4883 images left.\n",
      "\u001b[32m[01/08 15:45:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/08 15:45:34 d2.data.common]: \u001b[0mSerializing 4883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/08 15:45:34 d2.data.common]: \u001b[0mSerialized dataset takes 2.20 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (13, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (48, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (48,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/08 15:45:35 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/image_list.py:99: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/08 15:46:14 d2.utils.events]: \u001b[0m eta: 7:49:05  iter: 19  total_loss: 3.394  loss_cls: 2.553  loss_box_reg: 0.6921  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.03723  time: 1.8812  data_time: 0.2131  lr: 1.9981e-05  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:46:52 d2.utils.events]: \u001b[0m eta: 7:48:14  iter: 39  total_loss: 3.014  loss_cls: 2.102  loss_box_reg: 0.6915  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.04886  time: 1.8811  data_time: 0.2006  lr: 3.9961e-05  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:47:30 d2.utils.events]: \u001b[0m eta: 7:47:30  iter: 59  total_loss: 2.15  loss_cls: 1.28  loss_box_reg: 0.6844  loss_rpn_cls: 0.08379  loss_rpn_loc: 0.03134  time: 1.8796  data_time: 0.1960  lr: 5.9941e-05  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:48:07 d2.utils.events]: \u001b[0m eta: 7:46:40  iter: 79  total_loss: 1.682  loss_cls: 0.8397  loss_box_reg: 0.6914  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.03811  time: 1.8796  data_time: 0.1971  lr: 7.9921e-05  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:48:45 d2.utils.events]: \u001b[0m eta: 7:46:05  iter: 99  total_loss: 1.557  loss_cls: 0.7595  loss_box_reg: 0.6968  loss_rpn_cls: 0.06614  loss_rpn_loc: 0.03549  time: 1.8815  data_time: 0.2077  lr: 9.9901e-05  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:49:23 d2.utils.events]: \u001b[0m eta: 7:45:31  iter: 119  total_loss: 1.644  loss_cls: 0.7756  loss_box_reg: 0.7462  loss_rpn_cls: 0.05621  loss_rpn_loc: 0.04286  time: 1.8822  data_time: 0.2015  lr: 0.00011988  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:50:00 d2.utils.events]: \u001b[0m eta: 7:44:51  iter: 139  total_loss: 1.531  loss_cls: 0.7343  loss_box_reg: 0.714  loss_rpn_cls: 0.04742  loss_rpn_loc: 0.02931  time: 1.8819  data_time: 0.2002  lr: 0.00013986  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:50:38 d2.utils.events]: \u001b[0m eta: 7:44:28  iter: 159  total_loss: 1.48  loss_cls: 0.6868  loss_box_reg: 0.6848  loss_rpn_cls: 0.04994  loss_rpn_loc: 0.03735  time: 1.8824  data_time: 0.2023  lr: 0.00015984  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:51:16 d2.utils.events]: \u001b[0m eta: 7:43:46  iter: 179  total_loss: 1.421  loss_cls: 0.6632  loss_box_reg: 0.6905  loss_rpn_cls: 0.03166  loss_rpn_loc: 0.03512  time: 1.8820  data_time: 0.1954  lr: 0.00017982  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:51:53 d2.utils.events]: \u001b[0m eta: 7:43:17  iter: 199  total_loss: 1.513  loss_cls: 0.6805  loss_box_reg: 0.7224  loss_rpn_cls: 0.05535  loss_rpn_loc: 0.04496  time: 1.8822  data_time: 0.1998  lr: 0.0001998  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:52:31 d2.utils.events]: \u001b[0m eta: 7:42:42  iter: 219  total_loss: 1.425  loss_cls: 0.6444  loss_box_reg: 0.6935  loss_rpn_cls: 0.04271  loss_rpn_loc: 0.03548  time: 1.8821  data_time: 0.1980  lr: 0.00021978  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:53:09 d2.utils.events]: \u001b[0m eta: 7:42:04  iter: 239  total_loss: 1.316  loss_cls: 0.5847  loss_box_reg: 0.6621  loss_rpn_cls: 0.03072  loss_rpn_loc: 0.03431  time: 1.8818  data_time: 0.1993  lr: 0.00023976  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:53:46 d2.utils.events]: \u001b[0m eta: 7:41:29  iter: 259  total_loss: 1.444  loss_cls: 0.6607  loss_box_reg: 0.7025  loss_rpn_cls: 0.04097  loss_rpn_loc: 0.03988  time: 1.8821  data_time: 0.2026  lr: 0.00025974  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:54:24 d2.utils.events]: \u001b[0m eta: 7:40:51  iter: 279  total_loss: 1.382  loss_cls: 0.6305  loss_box_reg: 0.6636  loss_rpn_cls: 0.04073  loss_rpn_loc: 0.03684  time: 1.8820  data_time: 0.1979  lr: 0.00027972  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:55:02 d2.utils.events]: \u001b[0m eta: 7:40:14  iter: 299  total_loss: 1.251  loss_cls: 0.5516  loss_box_reg: 0.6115  loss_rpn_cls: 0.02827  loss_rpn_loc: 0.03856  time: 1.8819  data_time: 0.2022  lr: 0.0002997  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:55:39 d2.utils.events]: \u001b[0m eta: 7:39:42  iter: 319  total_loss: 1.238  loss_cls: 0.5679  loss_box_reg: 0.5799  loss_rpn_cls: 0.03524  loss_rpn_loc: 0.04343  time: 1.8824  data_time: 0.2076  lr: 0.00031968  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:56:17 d2.utils.events]: \u001b[0m eta: 7:39:05  iter: 339  total_loss: 1.233  loss_cls: 0.5759  loss_box_reg: 0.569  loss_rpn_cls: 0.03932  loss_rpn_loc: 0.0367  time: 1.8825  data_time: 0.2025  lr: 0.00033966  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:56:55 d2.utils.events]: \u001b[0m eta: 7:38:27  iter: 359  total_loss: 1.089  loss_cls: 0.531  loss_box_reg: 0.4801  loss_rpn_cls: 0.03709  loss_rpn_loc: 0.03501  time: 1.8826  data_time: 0.2007  lr: 0.00035964  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:57:32 d2.utils.events]: \u001b[0m eta: 7:37:48  iter: 379  total_loss: 0.9586  loss_cls: 0.4851  loss_box_reg: 0.4161  loss_rpn_cls: 0.02636  loss_rpn_loc: 0.02947  time: 1.8824  data_time: 0.1953  lr: 0.00037962  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:58:10 d2.utils.events]: \u001b[0m eta: 7:37:08  iter: 399  total_loss: 1.002  loss_cls: 0.4979  loss_box_reg: 0.4307  loss_rpn_cls: 0.0354  loss_rpn_loc: 0.04141  time: 1.8820  data_time: 0.1964  lr: 0.0003996  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:58:48 d2.utils.events]: \u001b[0m eta: 7:36:29  iter: 419  total_loss: 1.05  loss_cls: 0.5251  loss_box_reg: 0.4225  loss_rpn_cls: 0.03053  loss_rpn_loc: 0.04157  time: 1.8819  data_time: 0.1972  lr: 0.00041958  max_mem: 24877M\n",
      "\u001b[32m[01/08 15:59:25 d2.utils.events]: \u001b[0m eta: 7:35:50  iter: 439  total_loss: 1.02  loss_cls: 0.5193  loss_box_reg: 0.4013  loss_rpn_cls: 0.03435  loss_rpn_loc: 0.04207  time: 1.8820  data_time: 0.2031  lr: 0.00043956  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:00:03 d2.utils.events]: \u001b[0m eta: 7:35:14  iter: 459  total_loss: 0.893  loss_cls: 0.4677  loss_box_reg: 0.3585  loss_rpn_cls: 0.03053  loss_rpn_loc: 0.03313  time: 1.8822  data_time: 0.2016  lr: 0.00045954  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:00:41 d2.utils.events]: \u001b[0m eta: 7:34:36  iter: 479  total_loss: 0.9309  loss_cls: 0.4878  loss_box_reg: 0.3671  loss_rpn_cls: 0.0312  loss_rpn_loc: 0.03335  time: 1.8822  data_time: 0.2006  lr: 0.00047952  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:01:18 d2.utils.events]: \u001b[0m eta: 7:34:03  iter: 499  total_loss: 0.9713  loss_cls: 0.5115  loss_box_reg: 0.3746  loss_rpn_cls: 0.03147  loss_rpn_loc: 0.04387  time: 1.8824  data_time: 0.2020  lr: 0.0004995  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:01:56 d2.utils.events]: \u001b[0m eta: 7:33:26  iter: 519  total_loss: 0.9077  loss_cls: 0.4819  loss_box_reg: 0.3604  loss_rpn_cls: 0.03447  loss_rpn_loc: 0.03488  time: 1.8825  data_time: 0.2009  lr: 0.00051948  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:02:34 d2.utils.events]: \u001b[0m eta: 7:32:47  iter: 539  total_loss: 0.9459  loss_cls: 0.4645  loss_box_reg: 0.3496  loss_rpn_cls: 0.03636  loss_rpn_loc: 0.04527  time: 1.8823  data_time: 0.1974  lr: 0.00053946  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:03:11 d2.utils.events]: \u001b[0m eta: 7:32:11  iter: 559  total_loss: 0.845  loss_cls: 0.4744  loss_box_reg: 0.3217  loss_rpn_cls: 0.02764  loss_rpn_loc: 0.03056  time: 1.8824  data_time: 0.2030  lr: 0.00055944  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:03:49 d2.utils.events]: \u001b[0m eta: 7:31:32  iter: 579  total_loss: 0.8537  loss_cls: 0.4599  loss_box_reg: 0.3345  loss_rpn_cls: 0.03319  loss_rpn_loc: 0.03994  time: 1.8824  data_time: 0.2019  lr: 0.00057942  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:04:27 d2.utils.events]: \u001b[0m eta: 7:30:54  iter: 599  total_loss: 0.9149  loss_cls: 0.4747  loss_box_reg: 0.3302  loss_rpn_cls: 0.03244  loss_rpn_loc: 0.0341  time: 1.8823  data_time: 0.2011  lr: 0.0005994  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:05:04 d2.utils.events]: \u001b[0m eta: 7:30:15  iter: 619  total_loss: 0.8189  loss_cls: 0.4544  loss_box_reg: 0.3099  loss_rpn_cls: 0.03045  loss_rpn_loc: 0.0308  time: 1.8823  data_time: 0.1994  lr: 0.00061938  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:05:42 d2.utils.events]: \u001b[0m eta: 7:29:39  iter: 639  total_loss: 0.8777  loss_cls: 0.4755  loss_box_reg: 0.331  loss_rpn_cls: 0.03617  loss_rpn_loc: 0.04867  time: 1.8824  data_time: 0.2029  lr: 0.00063936  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:06:20 d2.utils.events]: \u001b[0m eta: 7:29:02  iter: 659  total_loss: 0.8634  loss_cls: 0.4734  loss_box_reg: 0.3338  loss_rpn_cls: 0.03023  loss_rpn_loc: 0.03299  time: 1.8826  data_time: 0.2005  lr: 0.00065934  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:06:58 d2.utils.events]: \u001b[0m eta: 7:28:28  iter: 679  total_loss: 0.847  loss_cls: 0.4569  loss_box_reg: 0.3024  loss_rpn_cls: 0.03396  loss_rpn_loc: 0.02901  time: 1.8829  data_time: 0.2060  lr: 0.00067932  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:07:35 d2.utils.events]: \u001b[0m eta: 7:27:50  iter: 699  total_loss: 0.8495  loss_cls: 0.4467  loss_box_reg: 0.2895  loss_rpn_cls: 0.02829  loss_rpn_loc: 0.02994  time: 1.8828  data_time: 0.2011  lr: 0.0006993  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:08:13 d2.utils.events]: \u001b[0m eta: 7:27:12  iter: 719  total_loss: 0.8047  loss_cls: 0.439  loss_box_reg: 0.2893  loss_rpn_cls: 0.02315  loss_rpn_loc: 0.02665  time: 1.8828  data_time: 0.2014  lr: 0.00071928  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:08:51 d2.utils.events]: \u001b[0m eta: 7:26:34  iter: 739  total_loss: 0.8046  loss_cls: 0.4307  loss_box_reg: 0.2967  loss_rpn_cls: 0.02598  loss_rpn_loc: 0.0329  time: 1.8828  data_time: 0.1965  lr: 0.00073926  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:09:28 d2.utils.events]: \u001b[0m eta: 7:25:56  iter: 759  total_loss: 0.7772  loss_cls: 0.4315  loss_box_reg: 0.2912  loss_rpn_cls: 0.02531  loss_rpn_loc: 0.03778  time: 1.8827  data_time: 0.1992  lr: 0.00075924  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:10:06 d2.utils.events]: \u001b[0m eta: 7:25:20  iter: 779  total_loss: 0.7446  loss_cls: 0.4074  loss_box_reg: 0.2867  loss_rpn_cls: 0.02717  loss_rpn_loc: 0.02675  time: 1.8827  data_time: 0.1974  lr: 0.00077922  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:10:44 d2.utils.events]: \u001b[0m eta: 7:24:44  iter: 799  total_loss: 0.8437  loss_cls: 0.4529  loss_box_reg: 0.3079  loss_rpn_cls: 0.03337  loss_rpn_loc: 0.04334  time: 1.8829  data_time: 0.2016  lr: 0.0007992  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:11:21 d2.utils.events]: \u001b[0m eta: 7:24:06  iter: 819  total_loss: 0.8193  loss_cls: 0.4526  loss_box_reg: 0.3059  loss_rpn_cls: 0.02649  loss_rpn_loc: 0.03694  time: 1.8827  data_time: 0.1954  lr: 0.00081918  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:11:59 d2.utils.events]: \u001b[0m eta: 7:23:29  iter: 839  total_loss: 0.7436  loss_cls: 0.4116  loss_box_reg: 0.2572  loss_rpn_cls: 0.02457  loss_rpn_loc: 0.03867  time: 1.8830  data_time: 0.1998  lr: 0.00083916  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:12:37 d2.utils.events]: \u001b[0m eta: 7:22:54  iter: 859  total_loss: 0.7937  loss_cls: 0.4331  loss_box_reg: 0.3097  loss_rpn_cls: 0.02813  loss_rpn_loc: 0.03296  time: 1.8830  data_time: 0.2020  lr: 0.00085914  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:13:15 d2.utils.events]: \u001b[0m eta: 7:22:15  iter: 879  total_loss: 0.8459  loss_cls: 0.4571  loss_box_reg: 0.3182  loss_rpn_cls: 0.03271  loss_rpn_loc: 0.04223  time: 1.8830  data_time: 0.1994  lr: 0.00087912  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:13:52 d2.utils.events]: \u001b[0m eta: 7:21:38  iter: 899  total_loss: 0.7638  loss_cls: 0.4224  loss_box_reg: 0.2783  loss_rpn_cls: 0.02853  loss_rpn_loc: 0.03117  time: 1.8829  data_time: 0.1983  lr: 0.0008991  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:14:30 d2.utils.events]: \u001b[0m eta: 7:21:00  iter: 919  total_loss: 0.8178  loss_cls: 0.4389  loss_box_reg: 0.3054  loss_rpn_cls: 0.02488  loss_rpn_loc: 0.03314  time: 1.8828  data_time: 0.1952  lr: 0.00091908  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:15:07 d2.utils.events]: \u001b[0m eta: 7:20:23  iter: 939  total_loss: 0.7397  loss_cls: 0.4158  loss_box_reg: 0.2724  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.03277  time: 1.8828  data_time: 0.1995  lr: 0.00093906  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:15:45 d2.utils.events]: \u001b[0m eta: 7:19:46  iter: 959  total_loss: 0.7537  loss_cls: 0.4124  loss_box_reg: 0.2894  loss_rpn_cls: 0.0291  loss_rpn_loc: 0.03436  time: 1.8827  data_time: 0.1991  lr: 0.00095904  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:16:23 d2.utils.events]: \u001b[0m eta: 7:19:10  iter: 979  total_loss: 0.7831  loss_cls: 0.4392  loss_box_reg: 0.292  loss_rpn_cls: 0.02995  loss_rpn_loc: 0.03183  time: 1.8829  data_time: 0.2093  lr: 0.00097902  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:17:01 d2.utils.events]: \u001b[0m eta: 7:18:35  iter: 999  total_loss: 0.8032  loss_cls: 0.4261  loss_box_reg: 0.2752  loss_rpn_cls: 0.03628  loss_rpn_loc: 0.04255  time: 1.8830  data_time: 0.2004  lr: 0.000999  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:17:38 d2.utils.events]: \u001b[0m eta: 7:17:58  iter: 1019  total_loss: 0.7913  loss_cls: 0.4101  loss_box_reg: 0.2888  loss_rpn_cls: 0.0277  loss_rpn_loc: 0.03661  time: 1.8830  data_time: 0.1985  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:18:16 d2.utils.events]: \u001b[0m eta: 7:17:21  iter: 1039  total_loss: 0.7418  loss_cls: 0.4193  loss_box_reg: 0.2708  loss_rpn_cls: 0.02253  loss_rpn_loc: 0.03829  time: 1.8830  data_time: 0.1996  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:18:54 d2.utils.events]: \u001b[0m eta: 7:16:44  iter: 1059  total_loss: 0.7102  loss_cls: 0.3901  loss_box_reg: 0.2612  loss_rpn_cls: 0.03579  loss_rpn_loc: 0.03552  time: 1.8830  data_time: 0.1985  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:19:31 d2.utils.events]: \u001b[0m eta: 7:16:10  iter: 1079  total_loss: 0.7957  loss_cls: 0.4459  loss_box_reg: 0.3018  loss_rpn_cls: 0.02604  loss_rpn_loc: 0.03013  time: 1.8830  data_time: 0.1997  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:20:09 d2.utils.events]: \u001b[0m eta: 7:15:30  iter: 1099  total_loss: 0.7674  loss_cls: 0.4184  loss_box_reg: 0.295  loss_rpn_cls: 0.02722  loss_rpn_loc: 0.03823  time: 1.8829  data_time: 0.1950  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:20:47 d2.utils.events]: \u001b[0m eta: 7:14:52  iter: 1119  total_loss: 0.7474  loss_cls: 0.3986  loss_box_reg: 0.2758  loss_rpn_cls: 0.02065  loss_rpn_loc: 0.03651  time: 1.8828  data_time: 0.1996  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:21:24 d2.utils.events]: \u001b[0m eta: 7:14:18  iter: 1139  total_loss: 0.7829  loss_cls: 0.4094  loss_box_reg: 0.2974  loss_rpn_cls: 0.02404  loss_rpn_loc: 0.04301  time: 1.8829  data_time: 0.2027  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:22:02 d2.utils.events]: \u001b[0m eta: 7:13:42  iter: 1159  total_loss: 0.7218  loss_cls: 0.417  loss_box_reg: 0.2566  loss_rpn_cls: 0.02057  loss_rpn_loc: 0.03223  time: 1.8830  data_time: 0.2069  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:22:40 d2.utils.events]: \u001b[0m eta: 7:13:06  iter: 1179  total_loss: 0.7366  loss_cls: 0.4115  loss_box_reg: 0.2527  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.02698  time: 1.8831  data_time: 0.2047  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:23:18 d2.utils.events]: \u001b[0m eta: 7:12:27  iter: 1199  total_loss: 0.7433  loss_cls: 0.3809  loss_box_reg: 0.2764  loss_rpn_cls: 0.02098  loss_rpn_loc: 0.03049  time: 1.8831  data_time: 0.2028  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:23:55 d2.utils.events]: \u001b[0m eta: 7:11:50  iter: 1219  total_loss: 0.7574  loss_cls: 0.4072  loss_box_reg: 0.283  loss_rpn_cls: 0.0255  loss_rpn_loc: 0.03629  time: 1.8831  data_time: 0.2007  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:24:33 d2.utils.events]: \u001b[0m eta: 7:11:13  iter: 1239  total_loss: 0.7123  loss_cls: 0.3925  loss_box_reg: 0.2745  loss_rpn_cls: 0.02205  loss_rpn_loc: 0.03367  time: 1.8831  data_time: 0.1985  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:25:11 d2.utils.events]: \u001b[0m eta: 7:10:36  iter: 1259  total_loss: 0.6908  loss_cls: 0.3806  loss_box_reg: 0.2587  loss_rpn_cls: 0.02094  loss_rpn_loc: 0.02659  time: 1.8830  data_time: 0.2001  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:25:48 d2.utils.events]: \u001b[0m eta: 7:10:00  iter: 1279  total_loss: 0.7256  loss_cls: 0.3996  loss_box_reg: 0.26  loss_rpn_cls: 0.02195  loss_rpn_loc: 0.03934  time: 1.8831  data_time: 0.1991  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:26:26 d2.utils.events]: \u001b[0m eta: 7:09:23  iter: 1299  total_loss: 0.7116  loss_cls: 0.3813  loss_box_reg: 0.2743  loss_rpn_cls: 0.02769  loss_rpn_loc: 0.02876  time: 1.8832  data_time: 0.2043  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:27:04 d2.utils.events]: \u001b[0m eta: 7:08:44  iter: 1319  total_loss: 0.7095  loss_cls: 0.4044  loss_box_reg: 0.2699  loss_rpn_cls: 0.02686  loss_rpn_loc: 0.03212  time: 1.8832  data_time: 0.2012  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:27:42 d2.utils.events]: \u001b[0m eta: 7:08:08  iter: 1339  total_loss: 0.7  loss_cls: 0.3759  loss_box_reg: 0.2792  loss_rpn_cls: 0.0221  loss_rpn_loc: 0.03335  time: 1.8833  data_time: 0.2063  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:28:19 d2.utils.events]: \u001b[0m eta: 7:07:30  iter: 1359  total_loss: 0.7391  loss_cls: 0.3875  loss_box_reg: 0.2738  loss_rpn_cls: 0.02138  loss_rpn_loc: 0.0351  time: 1.8833  data_time: 0.2046  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:28:57 d2.utils.events]: \u001b[0m eta: 7:06:53  iter: 1379  total_loss: 0.7639  loss_cls: 0.4077  loss_box_reg: 0.2779  loss_rpn_cls: 0.027  loss_rpn_loc: 0.03839  time: 1.8833  data_time: 0.2006  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:29:35 d2.utils.events]: \u001b[0m eta: 7:06:15  iter: 1399  total_loss: 0.7001  loss_cls: 0.3843  loss_box_reg: 0.2645  loss_rpn_cls: 0.02528  loss_rpn_loc: 0.03498  time: 1.8833  data_time: 0.2014  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:30:12 d2.utils.events]: \u001b[0m eta: 7:05:39  iter: 1419  total_loss: 0.7149  loss_cls: 0.3687  loss_box_reg: 0.2818  loss_rpn_cls: 0.02211  loss_rpn_loc: 0.03156  time: 1.8833  data_time: 0.1979  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:30:50 d2.utils.events]: \u001b[0m eta: 7:05:02  iter: 1439  total_loss: 0.7585  loss_cls: 0.408  loss_box_reg: 0.2901  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.04006  time: 1.8833  data_time: 0.1993  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:31:28 d2.utils.events]: \u001b[0m eta: 7:04:24  iter: 1459  total_loss: 0.7255  loss_cls: 0.3809  loss_box_reg: 0.2688  loss_rpn_cls: 0.02743  loss_rpn_loc: 0.03521  time: 1.8833  data_time: 0.1985  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:32:05 d2.utils.events]: \u001b[0m eta: 7:03:49  iter: 1479  total_loss: 0.6933  loss_cls: 0.3859  loss_box_reg: 0.2852  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.03227  time: 1.8833  data_time: 0.1995  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:32:43 d2.utils.events]: \u001b[0m eta: 7:03:10  iter: 1499  total_loss: 0.69  loss_cls: 0.3663  loss_box_reg: 0.2593  loss_rpn_cls: 0.02009  loss_rpn_loc: 0.02958  time: 1.8832  data_time: 0.1973  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:33:21 d2.utils.events]: \u001b[0m eta: 7:02:31  iter: 1519  total_loss: 0.6596  loss_cls: 0.3721  loss_box_reg: 0.2424  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.02801  time: 1.8833  data_time: 0.1964  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:33:58 d2.utils.events]: \u001b[0m eta: 7:01:56  iter: 1539  total_loss: 0.6498  loss_cls: 0.3673  loss_box_reg: 0.2524  loss_rpn_cls: 0.02214  loss_rpn_loc: 0.03792  time: 1.8833  data_time: 0.2022  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:34:36 d2.utils.events]: \u001b[0m eta: 7:01:20  iter: 1559  total_loss: 0.6998  loss_cls: 0.3716  loss_box_reg: 0.2567  loss_rpn_cls: 0.02807  loss_rpn_loc: 0.02988  time: 1.8834  data_time: 0.2107  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:35:14 d2.utils.events]: \u001b[0m eta: 7:00:43  iter: 1579  total_loss: 0.6896  loss_cls: 0.3757  loss_box_reg: 0.2523  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.02821  time: 1.8834  data_time: 0.1992  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:35:52 d2.utils.events]: \u001b[0m eta: 7:00:09  iter: 1599  total_loss: 0.6828  loss_cls: 0.3623  loss_box_reg: 0.2527  loss_rpn_cls: 0.02352  loss_rpn_loc: 0.03501  time: 1.8835  data_time: 0.2031  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:36:29 d2.utils.events]: \u001b[0m eta: 6:59:36  iter: 1619  total_loss: 0.7017  loss_cls: 0.3717  loss_box_reg: 0.2595  loss_rpn_cls: 0.02027  loss_rpn_loc: 0.02927  time: 1.8835  data_time: 0.2006  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:37:07 d2.utils.events]: \u001b[0m eta: 6:58:59  iter: 1639  total_loss: 0.6819  loss_cls: 0.3707  loss_box_reg: 0.2586  loss_rpn_cls: 0.02072  loss_rpn_loc: 0.02534  time: 1.8835  data_time: 0.2044  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:37:45 d2.utils.events]: \u001b[0m eta: 6:58:21  iter: 1659  total_loss: 0.7361  loss_cls: 0.3864  loss_box_reg: 0.2829  loss_rpn_cls: 0.02634  loss_rpn_loc: 0.03319  time: 1.8836  data_time: 0.2057  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:38:23 d2.utils.events]: \u001b[0m eta: 6:57:40  iter: 1679  total_loss: 0.6465  loss_cls: 0.3717  loss_box_reg: 0.2399  loss_rpn_cls: 0.02063  loss_rpn_loc: 0.02384  time: 1.8836  data_time: 0.2019  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:39:00 d2.utils.events]: \u001b[0m eta: 6:57:05  iter: 1699  total_loss: 0.71  loss_cls: 0.3625  loss_box_reg: 0.263  loss_rpn_cls: 0.01928  loss_rpn_loc: 0.03561  time: 1.8837  data_time: 0.2021  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:39:38 d2.utils.events]: \u001b[0m eta: 6:56:29  iter: 1719  total_loss: 0.7462  loss_cls: 0.3925  loss_box_reg: 0.2804  loss_rpn_cls: 0.02722  loss_rpn_loc: 0.0364  time: 1.8837  data_time: 0.2049  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:40:16 d2.utils.events]: \u001b[0m eta: 6:55:54  iter: 1739  total_loss: 0.6898  loss_cls: 0.3655  loss_box_reg: 0.2615  loss_rpn_cls: 0.02295  loss_rpn_loc: 0.02832  time: 1.8838  data_time: 0.2044  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:40:54 d2.utils.events]: \u001b[0m eta: 6:55:16  iter: 1759  total_loss: 0.7014  loss_cls: 0.3706  loss_box_reg: 0.2699  loss_rpn_cls: 0.02487  loss_rpn_loc: 0.03459  time: 1.8838  data_time: 0.1982  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:41:31 d2.utils.events]: \u001b[0m eta: 6:54:38  iter: 1779  total_loss: 0.6819  loss_cls: 0.369  loss_box_reg: 0.2529  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.033  time: 1.8838  data_time: 0.1935  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:42:09 d2.utils.events]: \u001b[0m eta: 6:53:56  iter: 1799  total_loss: 0.6312  loss_cls: 0.3319  loss_box_reg: 0.2521  loss_rpn_cls: 0.01868  loss_rpn_loc: 0.03178  time: 1.8838  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:42:47 d2.utils.events]: \u001b[0m eta: 6:53:24  iter: 1819  total_loss: 0.662  loss_cls: 0.3613  loss_box_reg: 0.2482  loss_rpn_cls: 0.01741  loss_rpn_loc: 0.02926  time: 1.8838  data_time: 0.2064  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:43:25 d2.utils.events]: \u001b[0m eta: 6:52:47  iter: 1839  total_loss: 0.7289  loss_cls: 0.3662  loss_box_reg: 0.2684  loss_rpn_cls: 0.02397  loss_rpn_loc: 0.03845  time: 1.8838  data_time: 0.2016  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:44:02 d2.utils.events]: \u001b[0m eta: 6:52:09  iter: 1859  total_loss: 0.6454  loss_cls: 0.3575  loss_box_reg: 0.2542  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.03065  time: 1.8839  data_time: 0.2013  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:44:40 d2.utils.events]: \u001b[0m eta: 6:51:34  iter: 1879  total_loss: 0.7023  loss_cls: 0.363  loss_box_reg: 0.275  loss_rpn_cls: 0.02187  loss_rpn_loc: 0.03303  time: 1.8839  data_time: 0.2029  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:45:18 d2.utils.events]: \u001b[0m eta: 6:50:56  iter: 1899  total_loss: 0.6165  loss_cls: 0.3411  loss_box_reg: 0.2288  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.023  time: 1.8839  data_time: 0.1981  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:45:56 d2.utils.events]: \u001b[0m eta: 6:50:20  iter: 1919  total_loss: 0.7002  loss_cls: 0.3777  loss_box_reg: 0.2642  loss_rpn_cls: 0.02196  loss_rpn_loc: 0.03238  time: 1.8840  data_time: 0.2095  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:46:33 d2.utils.events]: \u001b[0m eta: 6:49:45  iter: 1939  total_loss: 0.7022  loss_cls: 0.361  loss_box_reg: 0.2679  loss_rpn_cls: 0.02498  loss_rpn_loc: 0.03928  time: 1.8840  data_time: 0.2013  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:47:11 d2.utils.events]: \u001b[0m eta: 6:49:09  iter: 1959  total_loss: 0.6477  loss_cls: 0.3429  loss_box_reg: 0.2492  loss_rpn_cls: 0.02206  loss_rpn_loc: 0.0333  time: 1.8841  data_time: 0.2073  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:47:49 d2.utils.events]: \u001b[0m eta: 6:48:28  iter: 1979  total_loss: 0.6434  loss_cls: 0.3455  loss_box_reg: 0.2534  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.02565  time: 1.8840  data_time: 0.1940  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:48:26 d2.utils.events]: \u001b[0m eta: 6:47:49  iter: 1999  total_loss: 0.6607  loss_cls: 0.3549  loss_box_reg: 0.2658  loss_rpn_cls: 0.01724  loss_rpn_loc: 0.02125  time: 1.8840  data_time: 0.1994  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:49:04 d2.utils.events]: \u001b[0m eta: 6:47:10  iter: 2019  total_loss: 0.648  loss_cls: 0.3504  loss_box_reg: 0.2402  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.03956  time: 1.8840  data_time: 0.1979  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:49:42 d2.utils.events]: \u001b[0m eta: 6:46:32  iter: 2039  total_loss: 0.6568  loss_cls: 0.3306  loss_box_reg: 0.2627  loss_rpn_cls: 0.01742  loss_rpn_loc: 0.02445  time: 1.8840  data_time: 0.2004  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:50:20 d2.utils.events]: \u001b[0m eta: 6:45:53  iter: 2059  total_loss: 0.6318  loss_cls: 0.3369  loss_box_reg: 0.265  loss_rpn_cls: 0.02283  loss_rpn_loc: 0.02692  time: 1.8840  data_time: 0.1961  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:50:57 d2.utils.events]: \u001b[0m eta: 6:45:16  iter: 2079  total_loss: 0.7041  loss_cls: 0.3557  loss_box_reg: 0.2672  loss_rpn_cls: 0.01796  loss_rpn_loc: 0.03636  time: 1.8840  data_time: 0.2028  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:51:35 d2.utils.events]: \u001b[0m eta: 6:44:42  iter: 2099  total_loss: 0.6667  loss_cls: 0.3421  loss_box_reg: 0.2447  loss_rpn_cls: 0.02049  loss_rpn_loc: 0.03079  time: 1.8840  data_time: 0.2015  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:52:13 d2.utils.events]: \u001b[0m eta: 6:44:05  iter: 2119  total_loss: 0.6941  loss_cls: 0.3642  loss_box_reg: 0.2699  loss_rpn_cls: 0.02662  loss_rpn_loc: 0.03693  time: 1.8840  data_time: 0.2014  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:52:51 d2.utils.events]: \u001b[0m eta: 6:43:30  iter: 2139  total_loss: 0.6537  loss_cls: 0.3772  loss_box_reg: 0.2455  loss_rpn_cls: 0.02019  loss_rpn_loc: 0.03204  time: 1.8841  data_time: 0.2106  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:53:28 d2.utils.events]: \u001b[0m eta: 6:42:51  iter: 2159  total_loss: 0.6375  loss_cls: 0.3376  loss_box_reg: 0.2433  loss_rpn_cls: 0.02054  loss_rpn_loc: 0.03611  time: 1.8841  data_time: 0.1995  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:54:06 d2.utils.events]: \u001b[0m eta: 6:42:14  iter: 2179  total_loss: 0.6044  loss_cls: 0.3185  loss_box_reg: 0.2258  loss_rpn_cls: 0.02107  loss_rpn_loc: 0.02878  time: 1.8841  data_time: 0.2052  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:54:44 d2.utils.events]: \u001b[0m eta: 6:41:40  iter: 2199  total_loss: 0.6216  loss_cls: 0.3327  loss_box_reg: 0.2495  loss_rpn_cls: 0.0176  loss_rpn_loc: 0.02734  time: 1.8842  data_time: 0.2024  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:55:22 d2.utils.events]: \u001b[0m eta: 6:41:03  iter: 2219  total_loss: 0.5985  loss_cls: 0.3182  loss_box_reg: 0.2269  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.02964  time: 1.8842  data_time: 0.2047  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:55:59 d2.utils.events]: \u001b[0m eta: 6:40:25  iter: 2239  total_loss: 0.5832  loss_cls: 0.3174  loss_box_reg: 0.2495  loss_rpn_cls: 0.0185  loss_rpn_loc: 0.03238  time: 1.8843  data_time: 0.2042  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:56:37 d2.utils.events]: \u001b[0m eta: 6:39:49  iter: 2259  total_loss: 0.6059  loss_cls: 0.3333  loss_box_reg: 0.2448  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.03296  time: 1.8843  data_time: 0.2044  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:57:15 d2.utils.events]: \u001b[0m eta: 6:39:10  iter: 2279  total_loss: 0.6844  loss_cls: 0.3528  loss_box_reg: 0.2594  loss_rpn_cls: 0.02118  loss_rpn_loc: 0.04018  time: 1.8843  data_time: 0.2014  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:57:53 d2.utils.events]: \u001b[0m eta: 6:38:31  iter: 2299  total_loss: 0.6375  loss_cls: 0.3195  loss_box_reg: 0.2396  loss_rpn_cls: 0.01913  loss_rpn_loc: 0.0265  time: 1.8843  data_time: 0.2018  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:58:31 d2.utils.events]: \u001b[0m eta: 6:37:56  iter: 2319  total_loss: 0.6327  loss_cls: 0.3161  loss_box_reg: 0.2424  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.03178  time: 1.8844  data_time: 0.2042  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:59:08 d2.utils.events]: \u001b[0m eta: 6:37:18  iter: 2339  total_loss: 0.6021  loss_cls: 0.3171  loss_box_reg: 0.2372  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.02028  time: 1.8844  data_time: 0.2053  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 16:59:46 d2.utils.events]: \u001b[0m eta: 6:36:40  iter: 2359  total_loss: 0.6576  loss_cls: 0.3514  loss_box_reg: 0.2542  loss_rpn_cls: 0.02092  loss_rpn_loc: 0.03535  time: 1.8844  data_time: 0.1976  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:00:24 d2.utils.events]: \u001b[0m eta: 6:36:06  iter: 2379  total_loss: 0.6464  loss_cls: 0.3392  loss_box_reg: 0.256  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.02953  time: 1.8844  data_time: 0.2037  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:01:02 d2.utils.events]: \u001b[0m eta: 6:35:30  iter: 2399  total_loss: 0.6546  loss_cls: 0.3525  loss_box_reg: 0.2384  loss_rpn_cls: 0.02843  loss_rpn_loc: 0.03066  time: 1.8845  data_time: 0.2036  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:01:39 d2.utils.events]: \u001b[0m eta: 6:34:56  iter: 2419  total_loss: 0.6978  loss_cls: 0.3765  loss_box_reg: 0.2685  loss_rpn_cls: 0.02467  loss_rpn_loc: 0.04296  time: 1.8845  data_time: 0.2026  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:02:17 d2.utils.events]: \u001b[0m eta: 6:34:19  iter: 2439  total_loss: 0.6511  loss_cls: 0.3473  loss_box_reg: 0.2479  loss_rpn_cls: 0.01999  loss_rpn_loc: 0.0312  time: 1.8845  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:02:55 d2.utils.events]: \u001b[0m eta: 6:33:43  iter: 2459  total_loss: 0.6047  loss_cls: 0.3283  loss_box_reg: 0.2373  loss_rpn_cls: 0.02119  loss_rpn_loc: 0.02499  time: 1.8845  data_time: 0.2037  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:03:33 d2.utils.events]: \u001b[0m eta: 6:33:06  iter: 2479  total_loss: 0.5893  loss_cls: 0.305  loss_box_reg: 0.2446  loss_rpn_cls: 0.02059  loss_rpn_loc: 0.03692  time: 1.8846  data_time: 0.2073  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:04:11 d2.utils.events]: \u001b[0m eta: 6:32:31  iter: 2499  total_loss: 0.6421  loss_cls: 0.3317  loss_box_reg: 0.2736  loss_rpn_cls: 0.01982  loss_rpn_loc: 0.04218  time: 1.8846  data_time: 0.2039  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:04:48 d2.utils.events]: \u001b[0m eta: 6:31:53  iter: 2519  total_loss: 0.5681  loss_cls: 0.3045  loss_box_reg: 0.2375  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.02834  time: 1.8846  data_time: 0.1985  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:05:26 d2.utils.events]: \u001b[0m eta: 6:31:14  iter: 2539  total_loss: 0.6292  loss_cls: 0.3254  loss_box_reg: 0.2514  loss_rpn_cls: 0.022  loss_rpn_loc: 0.02658  time: 1.8847  data_time: 0.2018  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:06:04 d2.utils.events]: \u001b[0m eta: 6:30:33  iter: 2559  total_loss: 0.6355  loss_cls: 0.3198  loss_box_reg: 0.2422  loss_rpn_cls: 0.0175  loss_rpn_loc: 0.03324  time: 1.8847  data_time: 0.2011  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:06:41 d2.utils.events]: \u001b[0m eta: 6:29:57  iter: 2579  total_loss: 0.6316  loss_cls: 0.3276  loss_box_reg: 0.2478  loss_rpn_cls: 0.01785  loss_rpn_loc: 0.03414  time: 1.8847  data_time: 0.2008  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:07:19 d2.utils.events]: \u001b[0m eta: 6:29:20  iter: 2599  total_loss: 0.6473  loss_cls: 0.3441  loss_box_reg: 0.2535  loss_rpn_cls: 0.01747  loss_rpn_loc: 0.02919  time: 1.8847  data_time: 0.2040  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:07:57 d2.utils.events]: \u001b[0m eta: 6:28:44  iter: 2619  total_loss: 0.6835  loss_cls: 0.3585  loss_box_reg: 0.2535  loss_rpn_cls: 0.02439  loss_rpn_loc: 0.02715  time: 1.8847  data_time: 0.2029  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:08:35 d2.utils.events]: \u001b[0m eta: 6:28:07  iter: 2639  total_loss: 0.6008  loss_cls: 0.3158  loss_box_reg: 0.2343  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.02831  time: 1.8848  data_time: 0.2033  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:09:13 d2.utils.events]: \u001b[0m eta: 6:27:30  iter: 2659  total_loss: 0.564  loss_cls: 0.2904  loss_box_reg: 0.2233  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.03359  time: 1.8848  data_time: 0.2027  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:09:50 d2.utils.events]: \u001b[0m eta: 6:26:51  iter: 2679  total_loss: 0.6212  loss_cls: 0.3223  loss_box_reg: 0.2465  loss_rpn_cls: 0.02107  loss_rpn_loc: 0.02842  time: 1.8848  data_time: 0.2007  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:10:28 d2.utils.events]: \u001b[0m eta: 6:26:13  iter: 2699  total_loss: 0.5705  loss_cls: 0.3111  loss_box_reg: 0.2288  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.02316  time: 1.8847  data_time: 0.2008  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:11:06 d2.utils.events]: \u001b[0m eta: 6:25:36  iter: 2719  total_loss: 0.6925  loss_cls: 0.3458  loss_box_reg: 0.2638  loss_rpn_cls: 0.01684  loss_rpn_loc: 0.02981  time: 1.8848  data_time: 0.2052  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:11:44 d2.utils.events]: \u001b[0m eta: 6:24:58  iter: 2739  total_loss: 0.6224  loss_cls: 0.3243  loss_box_reg: 0.2435  loss_rpn_cls: 0.0187  loss_rpn_loc: 0.02716  time: 1.8848  data_time: 0.2016  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:12:21 d2.utils.events]: \u001b[0m eta: 6:24:21  iter: 2759  total_loss: 0.5567  loss_cls: 0.2864  loss_box_reg: 0.2177  loss_rpn_cls: 0.01686  loss_rpn_loc: 0.02776  time: 1.8849  data_time: 0.2060  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:12:59 d2.utils.events]: \u001b[0m eta: 6:23:47  iter: 2779  total_loss: 0.6197  loss_cls: 0.3396  loss_box_reg: 0.2599  loss_rpn_cls: 0.01704  loss_rpn_loc: 0.02908  time: 1.8849  data_time: 0.2045  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:13:37 d2.utils.events]: \u001b[0m eta: 6:23:09  iter: 2799  total_loss: 0.5597  loss_cls: 0.3008  loss_box_reg: 0.2239  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.02708  time: 1.8849  data_time: 0.2078  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:14:15 d2.utils.events]: \u001b[0m eta: 6:22:31  iter: 2819  total_loss: 0.6672  loss_cls: 0.3628  loss_box_reg: 0.2555  loss_rpn_cls: 0.02079  loss_rpn_loc: 0.02909  time: 1.8849  data_time: 0.2050  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:14:52 d2.utils.events]: \u001b[0m eta: 6:21:53  iter: 2839  total_loss: 0.6368  loss_cls: 0.3292  loss_box_reg: 0.2526  loss_rpn_cls: 0.01762  loss_rpn_loc: 0.02945  time: 1.8849  data_time: 0.1984  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:15:30 d2.utils.events]: \u001b[0m eta: 6:21:14  iter: 2859  total_loss: 0.6078  loss_cls: 0.3383  loss_box_reg: 0.2413  loss_rpn_cls: 0.01703  loss_rpn_loc: 0.04151  time: 1.8849  data_time: 0.2005  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:16:08 d2.utils.events]: \u001b[0m eta: 6:20:37  iter: 2879  total_loss: 0.6764  loss_cls: 0.3455  loss_box_reg: 0.2579  loss_rpn_cls: 0.02278  loss_rpn_loc: 0.03813  time: 1.8850  data_time: 0.2070  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:16:46 d2.utils.events]: \u001b[0m eta: 6:19:57  iter: 2899  total_loss: 0.6011  loss_cls: 0.2947  loss_box_reg: 0.2397  loss_rpn_cls: 0.01823  loss_rpn_loc: 0.03002  time: 1.8849  data_time: 0.1985  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:17:23 d2.utils.events]: \u001b[0m eta: 6:19:19  iter: 2919  total_loss: 0.5072  loss_cls: 0.2876  loss_box_reg: 0.2116  loss_rpn_cls: 0.01635  loss_rpn_loc: 0.02803  time: 1.8850  data_time: 0.2010  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:18:01 d2.utils.events]: \u001b[0m eta: 6:18:41  iter: 2939  total_loss: 0.597  loss_cls: 0.309  loss_box_reg: 0.2196  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.02516  time: 1.8850  data_time: 0.2010  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:18:39 d2.utils.events]: \u001b[0m eta: 6:18:03  iter: 2959  total_loss: 0.6006  loss_cls: 0.3257  loss_box_reg: 0.2305  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.03043  time: 1.8850  data_time: 0.2033  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:19:17 d2.utils.events]: \u001b[0m eta: 6:17:31  iter: 2979  total_loss: 0.5809  loss_cls: 0.2966  loss_box_reg: 0.2438  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.02584  time: 1.8850  data_time: 0.2044  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:19:56 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../../../dataset/test.json\n",
      "\u001b[32m[01/08 17:19:56 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 0            |    Paper    | 0            | Paper pack | 0            |\n",
      "|     Metal     | 0            |    Glass    | 0            |  Plastic   | 0            |\n",
      "|   Styrofoam   | 0            | Plastic bag | 0            |  Battery   | 0            |\n",
      "|   Clothing    | 0            |             |              |            |              |\n",
      "|     total     | 0            |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[01/08 17:19:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/08 17:19:56 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/08 17:19:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.53 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/08 17:19:56 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/08 17:19:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[01/08 17:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0015 s/iter. Inference: 0.0468 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:03:55\n",
      "\u001b[32m[01/08 17:20:02 d2.evaluation.evaluator]: \u001b[0mInference done 115/4871. Dataloading: 0.0016 s/iter. Inference: 0.0465 s/iter. Eval: 0.0003 s/iter. Total: 0.0485 s/iter. ETA=0:03:50\n",
      "\u001b[32m[01/08 17:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 226/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:03:38\n",
      "\u001b[32m[01/08 17:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 331/4871. Dataloading: 0.0016 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:03:34\n",
      "\u001b[32m[01/08 17:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 440/4871. Dataloading: 0.0016 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:03:28\n",
      "\u001b[32m[01/08 17:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 546/4871. Dataloading: 0.0016 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:03:23\n",
      "\u001b[32m[01/08 17:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 652/4871. Dataloading: 0.0016 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:03:18\n",
      "\u001b[32m[01/08 17:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 754/4871. Dataloading: 0.0016 s/iter. Inference: 0.0455 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:03:15\n",
      "\u001b[32m[01/08 17:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 863/4871. Dataloading: 0.0016 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:03:09\n",
      "\u001b[32m[01/08 17:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 971/4871. Dataloading: 0.0016 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:03:04\n",
      "\u001b[32m[01/08 17:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 1076/4871. Dataloading: 0.0016 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:02:59\n",
      "\u001b[32m[01/08 17:20:52 d2.evaluation.evaluator]: \u001b[0mInference done 1181/4871. Dataloading: 0.0016 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:02:54\n",
      "\u001b[32m[01/08 17:20:57 d2.evaluation.evaluator]: \u001b[0mInference done 1287/4871. Dataloading: 0.0017 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:02:49\n",
      "\u001b[32m[01/08 17:21:02 d2.evaluation.evaluator]: \u001b[0mInference done 1395/4871. Dataloading: 0.0017 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:02:44\n",
      "\u001b[32m[01/08 17:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 1503/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:02:39\n",
      "\u001b[32m[01/08 17:21:13 d2.evaluation.evaluator]: \u001b[0mInference done 1612/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0002 s/iter. Total: 0.0472 s/iter. ETA=0:02:33\n",
      "\u001b[32m[01/08 17:21:18 d2.evaluation.evaluator]: \u001b[0mInference done 1719/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:02:28\n",
      "\u001b[32m[01/08 17:21:23 d2.evaluation.evaluator]: \u001b[0mInference done 1825/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:02:23\n",
      "\u001b[32m[01/08 17:21:28 d2.evaluation.evaluator]: \u001b[0mInference done 1935/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0002 s/iter. Total: 0.0471 s/iter. ETA=0:02:18\n",
      "\u001b[32m[01/08 17:21:33 d2.evaluation.evaluator]: \u001b[0mInference done 2044/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:02:12\n",
      "\u001b[32m[01/08 17:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 2151/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:02:07\n",
      "\u001b[32m[01/08 17:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 2257/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0471 s/iter. ETA=0:02:02\n",
      "\u001b[32m[01/08 17:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 2367/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:57\n",
      "\u001b[32m[01/08 17:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 2474/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:52\n",
      "\u001b[32m[01/08 17:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 2580/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:47\n",
      "\u001b[32m[01/08 17:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 2686/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:42\n",
      "\u001b[32m[01/08 17:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 2790/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0471 s/iter. ETA=0:01:37\n",
      "\u001b[32m[01/08 17:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 2898/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:32\n",
      "\u001b[32m[01/08 17:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 3007/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:27\n",
      "\u001b[32m[01/08 17:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 3114/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:22\n",
      "\u001b[32m[01/08 17:22:28 d2.evaluation.evaluator]: \u001b[0mInference done 3221/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:17\n",
      "\u001b[32m[01/08 17:22:33 d2.evaluation.evaluator]: \u001b[0mInference done 3329/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:12\n",
      "\u001b[32m[01/08 17:22:38 d2.evaluation.evaluator]: \u001b[0mInference done 3437/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:07\n",
      "\u001b[32m[01/08 17:22:43 d2.evaluation.evaluator]: \u001b[0mInference done 3543/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:01:02\n",
      "\u001b[32m[01/08 17:22:48 d2.evaluation.evaluator]: \u001b[0mInference done 3650/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:00:57\n",
      "\u001b[32m[01/08 17:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 3760/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:00:52\n",
      "\u001b[32m[01/08 17:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 3868/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0469 s/iter. ETA=0:00:47\n",
      "\u001b[32m[01/08 17:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 3974/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0469 s/iter. ETA=0:00:42\n",
      "\u001b[32m[01/08 17:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 4083/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0469 s/iter. ETA=0:00:36\n",
      "\u001b[32m[01/08 17:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 4185/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:00:32\n",
      "\u001b[32m[01/08 17:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 4294/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:00:27\n",
      "\u001b[32m[01/08 17:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 4402/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0002 s/iter. Total: 0.0469 s/iter. ETA=0:00:22\n",
      "\u001b[32m[01/08 17:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 4501/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:00:17\n",
      "\u001b[32m[01/08 17:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 4607/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:00:12\n",
      "\u001b[32m[01/08 17:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 4712/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0471 s/iter. ETA=0:00:07\n",
      "\u001b[32m[01/08 17:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 4820/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0470 s/iter. ETA=0:00:02\n",
      "\u001b[32m[01/08 17:23:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:48.922799 (0.047045 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/08 17:23:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:38 (0.045006 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/08 17:23:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/08 17:23:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[01/08 17:23:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.66s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/08 17:23:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/08 17:23:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.98 seconds.\n",
      "\u001b[32m[01/08 17:23:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/08 17:23:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.25 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/08 17:23:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[01/08 17:23:50 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/08 17:23:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[01/08 17:23:50 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[01/08 17:23:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/08 17:23:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/08 17:23:50 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[01/08 17:23:50 d2.utils.events]: \u001b[0m eta: 6:16:54  iter: 2999  total_loss: 0.5478  loss_cls: 0.3045  loss_box_reg: 0.2017  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.02134  time: 1.8851  data_time: 0.2061  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:24:29 d2.utils.events]: \u001b[0m eta: 6:16:19  iter: 3019  total_loss: 0.6368  loss_cls: 0.329  loss_box_reg: 0.2441  loss_rpn_cls: 0.02188  loss_rpn_loc: 0.03359  time: 1.8852  data_time: 0.2105  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:25:06 d2.utils.events]: \u001b[0m eta: 6:15:41  iter: 3039  total_loss: 0.66  loss_cls: 0.3346  loss_box_reg: 0.2587  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.03399  time: 1.8851  data_time: 0.1999  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:25:44 d2.utils.events]: \u001b[0m eta: 6:15:06  iter: 3059  total_loss: 0.5801  loss_cls: 0.2993  loss_box_reg: 0.2405  loss_rpn_cls: 0.0203  loss_rpn_loc: 0.03608  time: 1.8852  data_time: 0.2115  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:26:22 d2.utils.events]: \u001b[0m eta: 6:14:29  iter: 3079  total_loss: 0.5493  loss_cls: 0.2901  loss_box_reg: 0.221  loss_rpn_cls: 0.01986  loss_rpn_loc: 0.02604  time: 1.8853  data_time: 0.2047  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:27:00 d2.utils.events]: \u001b[0m eta: 6:13:51  iter: 3099  total_loss: 0.6344  loss_cls: 0.3219  loss_box_reg: 0.2408  loss_rpn_cls: 0.01686  loss_rpn_loc: 0.02857  time: 1.8853  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:27:38 d2.utils.events]: \u001b[0m eta: 6:13:14  iter: 3119  total_loss: 0.5785  loss_cls: 0.3054  loss_box_reg: 0.2333  loss_rpn_cls: 0.02111  loss_rpn_loc: 0.03883  time: 1.8853  data_time: 0.2104  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:28:15 d2.utils.events]: \u001b[0m eta: 6:12:35  iter: 3139  total_loss: 0.6062  loss_cls: 0.2972  loss_box_reg: 0.2316  loss_rpn_cls: 0.01933  loss_rpn_loc: 0.04135  time: 1.8853  data_time: 0.2003  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:28:53 d2.utils.events]: \u001b[0m eta: 6:11:55  iter: 3159  total_loss: 0.5703  loss_cls: 0.3125  loss_box_reg: 0.2047  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.02206  time: 1.8853  data_time: 0.1964  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:29:31 d2.utils.events]: \u001b[0m eta: 6:11:17  iter: 3179  total_loss: 0.6078  loss_cls: 0.3285  loss_box_reg: 0.2397  loss_rpn_cls: 0.01761  loss_rpn_loc: 0.02815  time: 1.8853  data_time: 0.2031  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:30:08 d2.utils.events]: \u001b[0m eta: 6:10:38  iter: 3199  total_loss: 0.5743  loss_cls: 0.3126  loss_box_reg: 0.2161  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.03658  time: 1.8853  data_time: 0.2019  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:30:46 d2.utils.events]: \u001b[0m eta: 6:10:02  iter: 3219  total_loss: 0.6203  loss_cls: 0.3036  loss_box_reg: 0.2456  loss_rpn_cls: 0.01903  loss_rpn_loc: 0.03954  time: 1.8853  data_time: 0.1997  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:31:24 d2.utils.events]: \u001b[0m eta: 6:09:25  iter: 3239  total_loss: 0.5711  loss_cls: 0.2962  loss_box_reg: 0.2273  loss_rpn_cls: 0.01887  loss_rpn_loc: 0.0309  time: 1.8853  data_time: 0.2002  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:32:02 d2.utils.events]: \u001b[0m eta: 6:08:47  iter: 3259  total_loss: 0.5776  loss_cls: 0.3022  loss_box_reg: 0.2399  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.02669  time: 1.8853  data_time: 0.2002  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:32:40 d2.utils.events]: \u001b[0m eta: 6:08:09  iter: 3279  total_loss: 0.6441  loss_cls: 0.3251  loss_box_reg: 0.2622  loss_rpn_cls: 0.021  loss_rpn_loc: 0.04205  time: 1.8854  data_time: 0.2047  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:33:17 d2.utils.events]: \u001b[0m eta: 6:07:32  iter: 3299  total_loss: 0.5992  loss_cls: 0.3076  loss_box_reg: 0.2401  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.02839  time: 1.8854  data_time: 0.2011  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:33:55 d2.utils.events]: \u001b[0m eta: 6:06:54  iter: 3319  total_loss: 0.5714  loss_cls: 0.2986  loss_box_reg: 0.2223  loss_rpn_cls: 0.01324  loss_rpn_loc: 0.02206  time: 1.8854  data_time: 0.2009  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:34:33 d2.utils.events]: \u001b[0m eta: 6:06:16  iter: 3339  total_loss: 0.5885  loss_cls: 0.2845  loss_box_reg: 0.2611  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.02474  time: 1.8854  data_time: 0.1995  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:35:10 d2.utils.events]: \u001b[0m eta: 6:05:40  iter: 3359  total_loss: 0.5763  loss_cls: 0.3026  loss_box_reg: 0.2258  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.02739  time: 1.8854  data_time: 0.2015  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:35:48 d2.utils.events]: \u001b[0m eta: 6:05:03  iter: 3379  total_loss: 0.5795  loss_cls: 0.3063  loss_box_reg: 0.2164  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.02871  time: 1.8854  data_time: 0.2053  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:36:26 d2.utils.events]: \u001b[0m eta: 6:04:26  iter: 3399  total_loss: 0.5813  loss_cls: 0.2995  loss_box_reg: 0.2391  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.03207  time: 1.8854  data_time: 0.2064  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:37:04 d2.utils.events]: \u001b[0m eta: 6:03:49  iter: 3419  total_loss: 0.5801  loss_cls: 0.2906  loss_box_reg: 0.2396  loss_rpn_cls: 0.01969  loss_rpn_loc: 0.02766  time: 1.8855  data_time: 0.2067  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:37:42 d2.utils.events]: \u001b[0m eta: 6:03:13  iter: 3439  total_loss: 0.559  loss_cls: 0.2969  loss_box_reg: 0.2248  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.02479  time: 1.8855  data_time: 0.2085  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:38:20 d2.utils.events]: \u001b[0m eta: 6:02:35  iter: 3459  total_loss: 0.5593  loss_cls: 0.2831  loss_box_reg: 0.2225  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.03791  time: 1.8855  data_time: 0.2033  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:38:58 d2.utils.events]: \u001b[0m eta: 6:01:57  iter: 3479  total_loss: 0.5617  loss_cls: 0.2747  loss_box_reg: 0.2268  loss_rpn_cls: 0.017  loss_rpn_loc: 0.03613  time: 1.8856  data_time: 0.2022  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:39:35 d2.utils.events]: \u001b[0m eta: 6:01:21  iter: 3499  total_loss: 0.5897  loss_cls: 0.2938  loss_box_reg: 0.2189  loss_rpn_cls: 0.01633  loss_rpn_loc: 0.02872  time: 1.8856  data_time: 0.2053  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:40:13 d2.utils.events]: \u001b[0m eta: 6:00:45  iter: 3519  total_loss: 0.6412  loss_cls: 0.3407  loss_box_reg: 0.2371  loss_rpn_cls: 0.02368  loss_rpn_loc: 0.03211  time: 1.8856  data_time: 0.2004  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:40:51 d2.utils.events]: \u001b[0m eta: 6:00:08  iter: 3539  total_loss: 0.5856  loss_cls: 0.2835  loss_box_reg: 0.235  loss_rpn_cls: 0.01912  loss_rpn_loc: 0.0356  time: 1.8856  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:41:29 d2.utils.events]: \u001b[0m eta: 5:59:31  iter: 3559  total_loss: 0.5611  loss_cls: 0.2843  loss_box_reg: 0.2372  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.02386  time: 1.8856  data_time: 0.2073  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:42:06 d2.utils.events]: \u001b[0m eta: 5:58:53  iter: 3579  total_loss: 0.6075  loss_cls: 0.2998  loss_box_reg: 0.2539  loss_rpn_cls: 0.02086  loss_rpn_loc: 0.03565  time: 1.8857  data_time: 0.2046  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:42:44 d2.utils.events]: \u001b[0m eta: 5:58:16  iter: 3599  total_loss: 0.5578  loss_cls: 0.2844  loss_box_reg: 0.2158  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.01987  time: 1.8857  data_time: 0.2060  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:43:22 d2.utils.events]: \u001b[0m eta: 5:57:38  iter: 3619  total_loss: 0.556  loss_cls: 0.2842  loss_box_reg: 0.2081  loss_rpn_cls: 0.01883  loss_rpn_loc: 0.02876  time: 1.8857  data_time: 0.1997  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:44:00 d2.utils.events]: \u001b[0m eta: 5:56:58  iter: 3639  total_loss: 0.58  loss_cls: 0.2926  loss_box_reg: 0.2345  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.02962  time: 1.8857  data_time: 0.2015  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:44:37 d2.utils.events]: \u001b[0m eta: 5:56:21  iter: 3659  total_loss: 0.5913  loss_cls: 0.2953  loss_box_reg: 0.2396  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.03067  time: 1.8857  data_time: 0.2045  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:45:15 d2.utils.events]: \u001b[0m eta: 5:55:45  iter: 3679  total_loss: 0.5556  loss_cls: 0.2788  loss_box_reg: 0.226  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.02288  time: 1.8857  data_time: 0.2038  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:45:53 d2.utils.events]: \u001b[0m eta: 5:55:08  iter: 3699  total_loss: 0.5378  loss_cls: 0.2772  loss_box_reg: 0.2111  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.03248  time: 1.8857  data_time: 0.2009  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:46:31 d2.utils.events]: \u001b[0m eta: 5:54:30  iter: 3719  total_loss: 0.5926  loss_cls: 0.2907  loss_box_reg: 0.2391  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.02962  time: 1.8857  data_time: 0.1997  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:47:09 d2.utils.events]: \u001b[0m eta: 5:53:53  iter: 3739  total_loss: 0.5565  loss_cls: 0.2802  loss_box_reg: 0.2182  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.02726  time: 1.8857  data_time: 0.2079  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:47:46 d2.utils.events]: \u001b[0m eta: 5:53:15  iter: 3759  total_loss: 0.5747  loss_cls: 0.2864  loss_box_reg: 0.2245  loss_rpn_cls: 0.01945  loss_rpn_loc: 0.03719  time: 1.8858  data_time: 0.2017  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:48:24 d2.utils.events]: \u001b[0m eta: 5:52:38  iter: 3779  total_loss: 0.6056  loss_cls: 0.3122  loss_box_reg: 0.2475  loss_rpn_cls: 0.01807  loss_rpn_loc: 0.03546  time: 1.8858  data_time: 0.1991  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:49:02 d2.utils.events]: \u001b[0m eta: 5:52:01  iter: 3799  total_loss: 0.5473  loss_cls: 0.2814  loss_box_reg: 0.2131  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.0299  time: 1.8858  data_time: 0.2055  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:49:40 d2.utils.events]: \u001b[0m eta: 5:51:24  iter: 3819  total_loss: 0.5905  loss_cls: 0.2862  loss_box_reg: 0.2432  loss_rpn_cls: 0.01958  loss_rpn_loc: 0.03599  time: 1.8858  data_time: 0.2013  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:50:17 d2.utils.events]: \u001b[0m eta: 5:50:48  iter: 3839  total_loss: 0.5348  loss_cls: 0.2781  loss_box_reg: 0.2169  loss_rpn_cls: 0.01639  loss_rpn_loc: 0.02629  time: 1.8858  data_time: 0.1981  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:50:55 d2.utils.events]: \u001b[0m eta: 5:50:12  iter: 3859  total_loss: 0.5978  loss_cls: 0.2961  loss_box_reg: 0.2383  loss_rpn_cls: 0.01965  loss_rpn_loc: 0.03376  time: 1.8858  data_time: 0.2085  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:51:33 d2.utils.events]: \u001b[0m eta: 5:49:34  iter: 3879  total_loss: 0.6015  loss_cls: 0.301  loss_box_reg: 0.25  loss_rpn_cls: 0.0211  loss_rpn_loc: 0.03298  time: 1.8859  data_time: 0.2014  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:52:11 d2.utils.events]: \u001b[0m eta: 5:48:59  iter: 3899  total_loss: 0.5443  loss_cls: 0.2999  loss_box_reg: 0.2102  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.02348  time: 1.8859  data_time: 0.2060  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:52:49 d2.utils.events]: \u001b[0m eta: 5:48:21  iter: 3919  total_loss: 0.5979  loss_cls: 0.2978  loss_box_reg: 0.2318  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.03335  time: 1.8859  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:53:27 d2.utils.events]: \u001b[0m eta: 5:47:44  iter: 3939  total_loss: 0.5689  loss_cls: 0.2835  loss_box_reg: 0.222  loss_rpn_cls: 0.01611  loss_rpn_loc: 0.02356  time: 1.8859  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:54:05 d2.utils.events]: \u001b[0m eta: 5:47:06  iter: 3959  total_loss: 0.585  loss_cls: 0.3047  loss_box_reg: 0.2271  loss_rpn_cls: 0.01812  loss_rpn_loc: 0.03252  time: 1.8860  data_time: 0.2030  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:54:42 d2.utils.events]: \u001b[0m eta: 5:46:26  iter: 3979  total_loss: 0.507  loss_cls: 0.2701  loss_box_reg: 0.2015  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.0223  time: 1.8860  data_time: 0.2011  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:55:20 d2.utils.events]: \u001b[0m eta: 5:45:47  iter: 3999  total_loss: 0.5498  loss_cls: 0.2744  loss_box_reg: 0.2203  loss_rpn_cls: 0.01779  loss_rpn_loc: 0.03275  time: 1.8860  data_time: 0.2035  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:55:58 d2.utils.events]: \u001b[0m eta: 5:45:07  iter: 4019  total_loss: 0.572  loss_cls: 0.2908  loss_box_reg: 0.2241  loss_rpn_cls: 0.01895  loss_rpn_loc: 0.02954  time: 1.8859  data_time: 0.1987  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:56:35 d2.utils.events]: \u001b[0m eta: 5:44:31  iter: 4039  total_loss: 0.5645  loss_cls: 0.2831  loss_box_reg: 0.2352  loss_rpn_cls: 0.01924  loss_rpn_loc: 0.03333  time: 1.8859  data_time: 0.1991  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:57:13 d2.utils.events]: \u001b[0m eta: 5:43:53  iter: 4059  total_loss: 0.5571  loss_cls: 0.292  loss_box_reg: 0.2332  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.0258  time: 1.8860  data_time: 0.2038  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:57:51 d2.utils.events]: \u001b[0m eta: 5:43:14  iter: 4079  total_loss: 0.5585  loss_cls: 0.2798  loss_box_reg: 0.234  loss_rpn_cls: 0.02165  loss_rpn_loc: 0.02712  time: 1.8860  data_time: 0.2005  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:58:29 d2.utils.events]: \u001b[0m eta: 5:42:35  iter: 4099  total_loss: 0.5686  loss_cls: 0.2957  loss_box_reg: 0.2275  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.03444  time: 1.8859  data_time: 0.2002  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:59:06 d2.utils.events]: \u001b[0m eta: 5:41:56  iter: 4119  total_loss: 0.506  loss_cls: 0.2686  loss_box_reg: 0.2195  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.02549  time: 1.8859  data_time: 0.2012  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 17:59:44 d2.utils.events]: \u001b[0m eta: 5:41:18  iter: 4139  total_loss: 0.6136  loss_cls: 0.2882  loss_box_reg: 0.2444  loss_rpn_cls: 0.02081  loss_rpn_loc: 0.02971  time: 1.8859  data_time: 0.1996  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:00:22 d2.utils.events]: \u001b[0m eta: 5:40:43  iter: 4159  total_loss: 0.5369  loss_cls: 0.2799  loss_box_reg: 0.2025  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.02746  time: 1.8860  data_time: 0.2087  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:01:00 d2.utils.events]: \u001b[0m eta: 5:40:07  iter: 4179  total_loss: 0.5199  loss_cls: 0.253  loss_box_reg: 0.2175  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.02834  time: 1.8860  data_time: 0.2028  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:01:38 d2.utils.events]: \u001b[0m eta: 5:39:29  iter: 4199  total_loss: 0.5452  loss_cls: 0.2767  loss_box_reg: 0.2161  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.02387  time: 1.8860  data_time: 0.2021  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:02:15 d2.utils.events]: \u001b[0m eta: 5:38:51  iter: 4219  total_loss: 0.5988  loss_cls: 0.3073  loss_box_reg: 0.2359  loss_rpn_cls: 0.01978  loss_rpn_loc: 0.0274  time: 1.8860  data_time: 0.2028  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:02:53 d2.utils.events]: \u001b[0m eta: 5:38:12  iter: 4239  total_loss: 0.5897  loss_cls: 0.2967  loss_box_reg: 0.2383  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.02902  time: 1.8860  data_time: 0.1991  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:03:31 d2.utils.events]: \u001b[0m eta: 5:37:35  iter: 4259  total_loss: 0.5752  loss_cls: 0.3046  loss_box_reg: 0.2225  loss_rpn_cls: 0.01569  loss_rpn_loc: 0.03165  time: 1.8861  data_time: 0.2093  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:04:09 d2.utils.events]: \u001b[0m eta: 5:36:58  iter: 4279  total_loss: 0.5482  loss_cls: 0.2701  loss_box_reg: 0.2071  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.02427  time: 1.8861  data_time: 0.2022  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:04:47 d2.utils.events]: \u001b[0m eta: 5:36:21  iter: 4299  total_loss: 0.5522  loss_cls: 0.2565  loss_box_reg: 0.2399  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.02938  time: 1.8861  data_time: 0.2016  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:05:24 d2.utils.events]: \u001b[0m eta: 5:35:42  iter: 4319  total_loss: 0.5187  loss_cls: 0.2626  loss_box_reg: 0.2126  loss_rpn_cls: 0.01713  loss_rpn_loc: 0.02452  time: 1.8861  data_time: 0.1977  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:06:02 d2.utils.events]: \u001b[0m eta: 5:35:05  iter: 4339  total_loss: 0.5517  loss_cls: 0.273  loss_box_reg: 0.2366  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.04169  time: 1.8861  data_time: 0.2038  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:06:40 d2.utils.events]: \u001b[0m eta: 5:34:28  iter: 4359  total_loss: 0.5657  loss_cls: 0.2716  loss_box_reg: 0.2324  loss_rpn_cls: 0.01879  loss_rpn_loc: 0.02888  time: 1.8861  data_time: 0.2075  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:07:18 d2.utils.events]: \u001b[0m eta: 5:33:50  iter: 4379  total_loss: 0.5117  loss_cls: 0.2676  loss_box_reg: 0.2008  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.02736  time: 1.8861  data_time: 0.2005  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:07:55 d2.utils.events]: \u001b[0m eta: 5:33:10  iter: 4399  total_loss: 0.538  loss_cls: 0.2797  loss_box_reg: 0.2132  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.0231  time: 1.8861  data_time: 0.2031  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:08:33 d2.utils.events]: \u001b[0m eta: 5:32:32  iter: 4419  total_loss: 0.6045  loss_cls: 0.2743  loss_box_reg: 0.2466  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.03476  time: 1.8861  data_time: 0.2043  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:09:11 d2.utils.events]: \u001b[0m eta: 5:31:54  iter: 4439  total_loss: 0.5313  loss_cls: 0.2678  loss_box_reg: 0.2312  loss_rpn_cls: 0.01602  loss_rpn_loc: 0.02909  time: 1.8861  data_time: 0.2039  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:09:49 d2.utils.events]: \u001b[0m eta: 5:31:16  iter: 4459  total_loss: 0.5827  loss_cls: 0.2822  loss_box_reg: 0.2319  loss_rpn_cls: 0.01773  loss_rpn_loc: 0.03678  time: 1.8862  data_time: 0.2040  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:10:27 d2.utils.events]: \u001b[0m eta: 5:30:39  iter: 4479  total_loss: 0.5132  loss_cls: 0.2666  loss_box_reg: 0.1931  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.02981  time: 1.8862  data_time: 0.2050  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:11:05 d2.utils.events]: \u001b[0m eta: 5:29:57  iter: 4499  total_loss: 0.4872  loss_cls: 0.2698  loss_box_reg: 0.2011  loss_rpn_cls: 0.01849  loss_rpn_loc: 0.02713  time: 1.8862  data_time: 0.2026  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:11:42 d2.utils.events]: \u001b[0m eta: 5:29:21  iter: 4519  total_loss: 0.5494  loss_cls: 0.291  loss_box_reg: 0.2093  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.03053  time: 1.8862  data_time: 0.2058  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:12:20 d2.utils.events]: \u001b[0m eta: 5:28:46  iter: 4539  total_loss: 0.5776  loss_cls: 0.2813  loss_box_reg: 0.2317  loss_rpn_cls: 0.01673  loss_rpn_loc: 0.02747  time: 1.8863  data_time: 0.2084  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:12:58 d2.utils.events]: \u001b[0m eta: 5:28:06  iter: 4559  total_loss: 0.5279  loss_cls: 0.2606  loss_box_reg: 0.2118  loss_rpn_cls: 0.01685  loss_rpn_loc: 0.02552  time: 1.8863  data_time: 0.2056  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:13:36 d2.utils.events]: \u001b[0m eta: 5:27:28  iter: 4579  total_loss: 0.5052  loss_cls: 0.2752  loss_box_reg: 0.2074  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.02872  time: 1.8862  data_time: 0.1995  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:14:13 d2.utils.events]: \u001b[0m eta: 5:26:50  iter: 4599  total_loss: 0.5276  loss_cls: 0.2555  loss_box_reg: 0.2076  loss_rpn_cls: 0.01531  loss_rpn_loc: 0.02502  time: 1.8863  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:14:51 d2.utils.events]: \u001b[0m eta: 5:26:12  iter: 4619  total_loss: 0.5098  loss_cls: 0.2684  loss_box_reg: 0.2069  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.02945  time: 1.8863  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:15:29 d2.utils.events]: \u001b[0m eta: 5:25:36  iter: 4639  total_loss: 0.5064  loss_cls: 0.2647  loss_box_reg: 0.2121  loss_rpn_cls: 0.01764  loss_rpn_loc: 0.02896  time: 1.8863  data_time: 0.2071  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:16:07 d2.utils.events]: \u001b[0m eta: 5:24:57  iter: 4659  total_loss: 0.53  loss_cls: 0.2575  loss_box_reg: 0.2235  loss_rpn_cls: 0.01681  loss_rpn_loc: 0.0306  time: 1.8863  data_time: 0.1961  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:16:45 d2.utils.events]: \u001b[0m eta: 5:24:19  iter: 4679  total_loss: 0.5468  loss_cls: 0.2758  loss_box_reg: 0.2325  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.03094  time: 1.8863  data_time: 0.2048  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:17:22 d2.utils.events]: \u001b[0m eta: 5:23:42  iter: 4699  total_loss: 0.5209  loss_cls: 0.2664  loss_box_reg: 0.2117  loss_rpn_cls: 0.01648  loss_rpn_loc: 0.03258  time: 1.8863  data_time: 0.2063  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:18:00 d2.utils.events]: \u001b[0m eta: 5:23:05  iter: 4719  total_loss: 0.5723  loss_cls: 0.2799  loss_box_reg: 0.2164  loss_rpn_cls: 0.01843  loss_rpn_loc: 0.03267  time: 1.8863  data_time: 0.2016  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:18:38 d2.utils.events]: \u001b[0m eta: 5:22:25  iter: 4739  total_loss: 0.5119  loss_cls: 0.2735  loss_box_reg: 0.2038  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.02379  time: 1.8863  data_time: 0.2016  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:19:16 d2.utils.events]: \u001b[0m eta: 5:21:46  iter: 4759  total_loss: 0.5682  loss_cls: 0.2699  loss_box_reg: 0.2353  loss_rpn_cls: 0.01631  loss_rpn_loc: 0.03264  time: 1.8863  data_time: 0.2025  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:19:53 d2.utils.events]: \u001b[0m eta: 5:21:08  iter: 4779  total_loss: 0.5775  loss_cls: 0.2737  loss_box_reg: 0.219  loss_rpn_cls: 0.01522  loss_rpn_loc: 0.02968  time: 1.8863  data_time: 0.2042  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:20:31 d2.utils.events]: \u001b[0m eta: 5:20:30  iter: 4799  total_loss: 0.4766  loss_cls: 0.2368  loss_box_reg: 0.2071  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.03177  time: 1.8863  data_time: 0.2038  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:21:09 d2.utils.events]: \u001b[0m eta: 5:19:53  iter: 4819  total_loss: 0.5462  loss_cls: 0.2877  loss_box_reg: 0.2149  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.03166  time: 1.8864  data_time: 0.2076  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:21:47 d2.utils.events]: \u001b[0m eta: 5:19:17  iter: 4839  total_loss: 0.5225  loss_cls: 0.2578  loss_box_reg: 0.2195  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.02319  time: 1.8864  data_time: 0.2043  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:22:25 d2.utils.events]: \u001b[0m eta: 5:18:37  iter: 4859  total_loss: 0.5103  loss_cls: 0.2652  loss_box_reg: 0.2005  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.02519  time: 1.8864  data_time: 0.2014  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:23:03 d2.utils.events]: \u001b[0m eta: 5:17:58  iter: 4879  total_loss: 0.5455  loss_cls: 0.2772  loss_box_reg: 0.2218  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.02758  time: 1.8864  data_time: 0.2098  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:23:41 d2.utils.events]: \u001b[0m eta: 5:17:20  iter: 4899  total_loss: 0.5902  loss_cls: 0.2908  loss_box_reg: 0.2441  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.03961  time: 1.8865  data_time: 0.2021  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:24:18 d2.utils.events]: \u001b[0m eta: 5:16:43  iter: 4919  total_loss: 0.4995  loss_cls: 0.2428  loss_box_reg: 0.2087  loss_rpn_cls: 0.01761  loss_rpn_loc: 0.02723  time: 1.8865  data_time: 0.2071  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:24:56 d2.utils.events]: \u001b[0m eta: 5:16:07  iter: 4939  total_loss: 0.5055  loss_cls: 0.2513  loss_box_reg: 0.215  loss_rpn_cls: 0.01365  loss_rpn_loc: 0.02872  time: 1.8865  data_time: 0.2090  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:25:34 d2.utils.events]: \u001b[0m eta: 5:15:30  iter: 4959  total_loss: 0.5581  loss_cls: 0.2668  loss_box_reg: 0.2288  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.03264  time: 1.8865  data_time: 0.2056  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:26:12 d2.utils.events]: \u001b[0m eta: 5:14:55  iter: 4979  total_loss: 0.5232  loss_cls: 0.2708  loss_box_reg: 0.2155  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.0295  time: 1.8866  data_time: 0.2136  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:26:50 d2.utils.events]: \u001b[0m eta: 5:14:18  iter: 4999  total_loss: 0.5596  loss_cls: 0.2883  loss_box_reg: 0.238  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.02812  time: 1.8866  data_time: 0.2016  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:27:28 d2.utils.events]: \u001b[0m eta: 5:13:42  iter: 5019  total_loss: 0.497  loss_cls: 0.2571  loss_box_reg: 0.201  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.02543  time: 1.8866  data_time: 0.2032  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:28:05 d2.utils.events]: \u001b[0m eta: 5:13:04  iter: 5039  total_loss: 0.5337  loss_cls: 0.2583  loss_box_reg: 0.227  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.03044  time: 1.8866  data_time: 0.2024  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:28:43 d2.utils.events]: \u001b[0m eta: 5:12:25  iter: 5059  total_loss: 0.4983  loss_cls: 0.2468  loss_box_reg: 0.1982  loss_rpn_cls: 0.01577  loss_rpn_loc: 0.03185  time: 1.8866  data_time: 0.1999  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:29:21 d2.utils.events]: \u001b[0m eta: 5:11:47  iter: 5079  total_loss: 0.522  loss_cls: 0.2662  loss_box_reg: 0.2072  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.02746  time: 1.8866  data_time: 0.2045  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:29:59 d2.utils.events]: \u001b[0m eta: 5:11:09  iter: 5099  total_loss: 0.5249  loss_cls: 0.2586  loss_box_reg: 0.2164  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.02869  time: 1.8866  data_time: 0.2015  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:30:36 d2.utils.events]: \u001b[0m eta: 5:10:32  iter: 5119  total_loss: 0.5061  loss_cls: 0.2629  loss_box_reg: 0.2167  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.02723  time: 1.8866  data_time: 0.1995  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:31:14 d2.utils.events]: \u001b[0m eta: 5:09:56  iter: 5139  total_loss: 0.5034  loss_cls: 0.2523  loss_box_reg: 0.2068  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.03247  time: 1.8866  data_time: 0.2091  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:31:52 d2.utils.events]: \u001b[0m eta: 5:09:17  iter: 5159  total_loss: 0.531  loss_cls: 0.2598  loss_box_reg: 0.2124  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.02178  time: 1.8866  data_time: 0.2013  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:32:30 d2.utils.events]: \u001b[0m eta: 5:08:39  iter: 5179  total_loss: 0.5034  loss_cls: 0.2486  loss_box_reg: 0.2289  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.02515  time: 1.8866  data_time: 0.2057  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:33:08 d2.utils.events]: \u001b[0m eta: 5:08:02  iter: 5199  total_loss: 0.5713  loss_cls: 0.2826  loss_box_reg: 0.2415  loss_rpn_cls: 0.01639  loss_rpn_loc: 0.0252  time: 1.8866  data_time: 0.2057  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:33:46 d2.utils.events]: \u001b[0m eta: 5:07:23  iter: 5219  total_loss: 0.498  loss_cls: 0.2469  loss_box_reg: 0.2046  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.02408  time: 1.8866  data_time: 0.2059  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:34:23 d2.utils.events]: \u001b[0m eta: 5:06:45  iter: 5239  total_loss: 0.4974  loss_cls: 0.2426  loss_box_reg: 0.2164  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.02443  time: 1.8866  data_time: 0.1984  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:35:01 d2.utils.events]: \u001b[0m eta: 5:06:06  iter: 5259  total_loss: 0.4709  loss_cls: 0.231  loss_box_reg: 0.2001  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.02872  time: 1.8866  data_time: 0.2051  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:35:39 d2.utils.events]: \u001b[0m eta: 5:05:30  iter: 5279  total_loss: 0.515  loss_cls: 0.2663  loss_box_reg: 0.2167  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.02841  time: 1.8867  data_time: 0.2107  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:36:17 d2.utils.events]: \u001b[0m eta: 5:04:52  iter: 5299  total_loss: 0.5246  loss_cls: 0.2564  loss_box_reg: 0.2221  loss_rpn_cls: 0.0145  loss_rpn_loc: 0.03039  time: 1.8867  data_time: 0.2002  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:36:54 d2.utils.events]: \u001b[0m eta: 5:04:14  iter: 5319  total_loss: 0.4934  loss_cls: 0.2442  loss_box_reg: 0.2003  loss_rpn_cls: 0.01732  loss_rpn_loc: 0.0338  time: 1.8867  data_time: 0.2017  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:37:32 d2.utils.events]: \u001b[0m eta: 5:03:37  iter: 5339  total_loss: 0.4637  loss_cls: 0.2216  loss_box_reg: 0.187  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.02298  time: 1.8867  data_time: 0.2051  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:38:10 d2.utils.events]: \u001b[0m eta: 5:02:59  iter: 5359  total_loss: 0.4999  loss_cls: 0.2497  loss_box_reg: 0.2156  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.02528  time: 1.8867  data_time: 0.2035  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:38:48 d2.utils.events]: \u001b[0m eta: 5:02:22  iter: 5379  total_loss: 0.526  loss_cls: 0.2694  loss_box_reg: 0.211  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.02364  time: 1.8867  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:39:26 d2.utils.events]: \u001b[0m eta: 5:01:45  iter: 5399  total_loss: 0.6317  loss_cls: 0.3058  loss_box_reg: 0.2434  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.04089  time: 1.8867  data_time: 0.2042  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:40:03 d2.utils.events]: \u001b[0m eta: 5:01:05  iter: 5419  total_loss: 0.5073  loss_cls: 0.2512  loss_box_reg: 0.2126  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.029  time: 1.8867  data_time: 0.2020  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:40:41 d2.utils.events]: \u001b[0m eta: 5:00:25  iter: 5439  total_loss: 0.5487  loss_cls: 0.27  loss_box_reg: 0.2255  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.0249  time: 1.8867  data_time: 0.2045  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:41:19 d2.utils.events]: \u001b[0m eta: 4:59:47  iter: 5459  total_loss: 0.5184  loss_cls: 0.2598  loss_box_reg: 0.2175  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.0309  time: 1.8867  data_time: 0.2018  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:41:57 d2.utils.events]: \u001b[0m eta: 4:59:10  iter: 5479  total_loss: 0.5528  loss_cls: 0.2699  loss_box_reg: 0.2232  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.03059  time: 1.8868  data_time: 0.2024  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:42:35 d2.utils.events]: \u001b[0m eta: 4:58:35  iter: 5499  total_loss: 0.4925  loss_cls: 0.2431  loss_box_reg: 0.2102  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.02839  time: 1.8868  data_time: 0.2056  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:43:13 d2.utils.events]: \u001b[0m eta: 4:57:57  iter: 5519  total_loss: 0.5561  loss_cls: 0.2665  loss_box_reg: 0.2277  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.04146  time: 1.8868  data_time: 0.2062  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:43:50 d2.utils.events]: \u001b[0m eta: 4:57:19  iter: 5539  total_loss: 0.4646  loss_cls: 0.2365  loss_box_reg: 0.1885  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.02544  time: 1.8868  data_time: 0.2054  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:44:28 d2.utils.events]: \u001b[0m eta: 4:56:41  iter: 5559  total_loss: 0.4994  loss_cls: 0.2471  loss_box_reg: 0.2136  loss_rpn_cls: 0.014  loss_rpn_loc: 0.02488  time: 1.8868  data_time: 0.2023  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:45:06 d2.utils.events]: \u001b[0m eta: 4:56:03  iter: 5579  total_loss: 0.5145  loss_cls: 0.2532  loss_box_reg: 0.211  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.02882  time: 1.8868  data_time: 0.2013  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:45:44 d2.utils.events]: \u001b[0m eta: 4:55:26  iter: 5599  total_loss: 0.493  loss_cls: 0.2437  loss_box_reg: 0.2016  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.02744  time: 1.8868  data_time: 0.2065  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:46:21 d2.utils.events]: \u001b[0m eta: 4:54:48  iter: 5619  total_loss: 0.4427  loss_cls: 0.2204  loss_box_reg: 0.2003  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.01942  time: 1.8868  data_time: 0.2007  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:46:59 d2.utils.events]: \u001b[0m eta: 4:54:11  iter: 5639  total_loss: 0.5309  loss_cls: 0.2594  loss_box_reg: 0.2158  loss_rpn_cls: 0.01426  loss_rpn_loc: 0.02498  time: 1.8868  data_time: 0.1993  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:47:37 d2.utils.events]: \u001b[0m eta: 4:53:33  iter: 5659  total_loss: 0.5353  loss_cls: 0.2594  loss_box_reg: 0.2188  loss_rpn_cls: 0.01716  loss_rpn_loc: 0.0338  time: 1.8868  data_time: 0.2039  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:48:15 d2.utils.events]: \u001b[0m eta: 4:52:55  iter: 5679  total_loss: 0.5015  loss_cls: 0.2424  loss_box_reg: 0.2093  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.02662  time: 1.8868  data_time: 0.2006  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:48:52 d2.utils.events]: \u001b[0m eta: 4:52:17  iter: 5699  total_loss: 0.4909  loss_cls: 0.2495  loss_box_reg: 0.2004  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.02485  time: 1.8868  data_time: 0.2013  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:49:30 d2.utils.events]: \u001b[0m eta: 4:51:40  iter: 5719  total_loss: 0.5411  loss_cls: 0.2771  loss_box_reg: 0.2214  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.03134  time: 1.8868  data_time: 0.2035  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:50:08 d2.utils.events]: \u001b[0m eta: 4:51:02  iter: 5739  total_loss: 0.5259  loss_cls: 0.2564  loss_box_reg: 0.2231  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.03224  time: 1.8868  data_time: 0.2024  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:50:46 d2.utils.events]: \u001b[0m eta: 4:50:25  iter: 5759  total_loss: 0.5171  loss_cls: 0.2674  loss_box_reg: 0.2154  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.02842  time: 1.8868  data_time: 0.2042  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:51:24 d2.utils.events]: \u001b[0m eta: 4:49:47  iter: 5779  total_loss: 0.4769  loss_cls: 0.2527  loss_box_reg: 0.1917  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.02548  time: 1.8868  data_time: 0.1951  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:52:01 d2.utils.events]: \u001b[0m eta: 4:49:09  iter: 5799  total_loss: 0.5089  loss_cls: 0.252  loss_box_reg: 0.2102  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.02555  time: 1.8868  data_time: 0.2014  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:52:39 d2.utils.events]: \u001b[0m eta: 4:48:31  iter: 5819  total_loss: 0.3882  loss_cls: 0.1959  loss_box_reg: 0.1725  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.02011  time: 1.8869  data_time: 0.2054  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:53:17 d2.utils.events]: \u001b[0m eta: 4:47:53  iter: 5839  total_loss: 0.4707  loss_cls: 0.229  loss_box_reg: 0.2023  loss_rpn_cls: 0.01585  loss_rpn_loc: 0.02308  time: 1.8869  data_time: 0.2027  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:53:55 d2.utils.events]: \u001b[0m eta: 4:47:15  iter: 5859  total_loss: 0.5269  loss_cls: 0.2546  loss_box_reg: 0.2246  loss_rpn_cls: 0.01443  loss_rpn_loc: 0.02437  time: 1.8869  data_time: 0.2025  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:54:33 d2.utils.events]: \u001b[0m eta: 4:46:38  iter: 5879  total_loss: 0.467  loss_cls: 0.2319  loss_box_reg: 0.2  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.02877  time: 1.8869  data_time: 0.2062  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:55:10 d2.utils.events]: \u001b[0m eta: 4:46:00  iter: 5899  total_loss: 0.4672  loss_cls: 0.2234  loss_box_reg: 0.2105  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.02423  time: 1.8869  data_time: 0.2023  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:55:48 d2.utils.events]: \u001b[0m eta: 4:45:22  iter: 5919  total_loss: 0.4776  loss_cls: 0.2371  loss_box_reg: 0.201  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.02747  time: 1.8869  data_time: 0.2039  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:56:26 d2.utils.events]: \u001b[0m eta: 4:44:45  iter: 5939  total_loss: 0.5386  loss_cls: 0.2495  loss_box_reg: 0.229  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.03192  time: 1.8869  data_time: 0.2062  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:57:04 d2.utils.events]: \u001b[0m eta: 4:44:07  iter: 5959  total_loss: 0.4841  loss_cls: 0.2363  loss_box_reg: 0.2024  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.02962  time: 1.8869  data_time: 0.2097  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:57:42 d2.utils.events]: \u001b[0m eta: 4:43:29  iter: 5979  total_loss: 0.4828  loss_cls: 0.2481  loss_box_reg: 0.212  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.02564  time: 1.8869  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 18:58:21 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../../../dataset/test.json\n",
      "\u001b[32m[01/08 18:58:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/08 18:58:21 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/08 18:58:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.53 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/08 18:58:21 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/08 18:58:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[01/08 18:58:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0012 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:03:50\n",
      "\u001b[32m[01/08 18:58:27 d2.evaluation.evaluator]: \u001b[0mInference done 122/4871. Dataloading: 0.0014 s/iter. Inference: 0.0436 s/iter. Eval: 0.0002 s/iter. Total: 0.0454 s/iter. ETA=0:03:35\n",
      "\u001b[32m[01/08 18:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 228/4871. Dataloading: 0.0015 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:03:34\n",
      "\u001b[32m[01/08 18:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 332/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0002 s/iter. Total: 0.0469 s/iter. ETA=0:03:32\n",
      "\u001b[32m[01/08 18:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 436/4871. Dataloading: 0.0016 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:03:29\n",
      "\u001b[32m[01/08 18:58:47 d2.evaluation.evaluator]: \u001b[0mInference done 542/4871. Dataloading: 0.0016 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:03:24\n",
      "\u001b[32m[01/08 18:58:52 d2.evaluation.evaluator]: \u001b[0mInference done 647/4871. Dataloading: 0.0016 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:03:20\n",
      "\u001b[32m[01/08 18:58:57 d2.evaluation.evaluator]: \u001b[0mInference done 753/4871. Dataloading: 0.0016 s/iter. Inference: 0.0454 s/iter. Eval: 0.0002 s/iter. Total: 0.0474 s/iter. ETA=0:03:15\n",
      "\u001b[32m[01/08 18:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 857/4871. Dataloading: 0.0017 s/iter. Inference: 0.0455 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:03:10\n",
      "\u001b[32m[01/08 18:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 959/4871. Dataloading: 0.0017 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:03:06\n",
      "\u001b[32m[01/08 18:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 1065/4871. Dataloading: 0.0017 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:03:01\n",
      "\u001b[32m[01/08 18:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 1173/4871. Dataloading: 0.0017 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:55\n",
      "\u001b[32m[01/08 18:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 1275/4871. Dataloading: 0.0017 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:02:51\n",
      "\u001b[32m[01/08 18:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 1379/4871. Dataloading: 0.0017 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:02:46\n",
      "\u001b[32m[01/08 18:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 1486/4871. Dataloading: 0.0018 s/iter. Inference: 0.0456 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:02:41\n",
      "\u001b[32m[01/08 18:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 1592/4871. Dataloading: 0.0018 s/iter. Inference: 0.0455 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:02:36\n",
      "\u001b[32m[01/08 18:59:42 d2.evaluation.evaluator]: \u001b[0mInference done 1699/4871. Dataloading: 0.0018 s/iter. Inference: 0.0455 s/iter. Eval: 0.0003 s/iter. Total: 0.0476 s/iter. ETA=0:02:30\n",
      "\u001b[32m[01/08 18:59:47 d2.evaluation.evaluator]: \u001b[0mInference done 1807/4871. Dataloading: 0.0017 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:25\n",
      "\u001b[32m[01/08 18:59:52 d2.evaluation.evaluator]: \u001b[0mInference done 1914/4871. Dataloading: 0.0017 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:20\n",
      "\u001b[32m[01/08 18:59:57 d2.evaluation.evaluator]: \u001b[0mInference done 2020/4871. Dataloading: 0.0017 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:15\n",
      "\u001b[32m[01/08 19:00:02 d2.evaluation.evaluator]: \u001b[0mInference done 2126/4871. Dataloading: 0.0017 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:02:10\n",
      "\u001b[32m[01/08 19:00:07 d2.evaluation.evaluator]: \u001b[0mInference done 2234/4871. Dataloading: 0.0017 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:02:05\n",
      "\u001b[32m[01/08 19:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 2342/4871. Dataloading: 0.0017 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:01:59\n",
      "\u001b[32m[01/08 19:00:17 d2.evaluation.evaluator]: \u001b[0mInference done 2450/4871. Dataloading: 0.0017 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:01:54\n",
      "\u001b[32m[01/08 19:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 2556/4871. Dataloading: 0.0017 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:49\n",
      "\u001b[32m[01/08 19:00:27 d2.evaluation.evaluator]: \u001b[0mInference done 2663/4871. Dataloading: 0.0017 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:44\n",
      "\u001b[32m[01/08 19:00:32 d2.evaluation.evaluator]: \u001b[0mInference done 2770/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:39\n",
      "\u001b[32m[01/08 19:00:37 d2.evaluation.evaluator]: \u001b[0mInference done 2880/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:34\n",
      "\u001b[32m[01/08 19:00:42 d2.evaluation.evaluator]: \u001b[0mInference done 2984/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:29\n",
      "\u001b[32m[01/08 19:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 3089/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:24\n",
      "\u001b[32m[01/08 19:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 3198/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:19\n",
      "\u001b[32m[01/08 19:00:57 d2.evaluation.evaluator]: \u001b[0mInference done 3304/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:14\n",
      "\u001b[32m[01/08 19:01:02 d2.evaluation.evaluator]: \u001b[0mInference done 3410/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:09\n",
      "\u001b[32m[01/08 19:01:07 d2.evaluation.evaluator]: \u001b[0mInference done 3517/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:03\n",
      "\u001b[32m[01/08 19:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 3624/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:00:58\n",
      "\u001b[32m[01/08 19:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 3730/4871. Dataloading: 0.0018 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:00:53\n",
      "\u001b[32m[01/08 19:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 3838/4871. Dataloading: 0.0018 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:48\n",
      "\u001b[32m[01/08 19:01:27 d2.evaluation.evaluator]: \u001b[0mInference done 3945/4871. Dataloading: 0.0018 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:43\n",
      "\u001b[32m[01/08 19:01:32 d2.evaluation.evaluator]: \u001b[0mInference done 4058/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:38\n",
      "\u001b[32m[01/08 19:01:37 d2.evaluation.evaluator]: \u001b[0mInference done 4169/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:00:33\n",
      "\u001b[32m[01/08 19:01:42 d2.evaluation.evaluator]: \u001b[0mInference done 4281/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:27\n",
      "\u001b[32m[01/08 19:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 4392/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:22\n",
      "\u001b[32m[01/08 19:01:53 d2.evaluation.evaluator]: \u001b[0mInference done 4503/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:17\n",
      "\u001b[32m[01/08 19:01:58 d2.evaluation.evaluator]: \u001b[0mInference done 4615/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:00:12\n",
      "\u001b[32m[01/08 19:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 4725/4871. Dataloading: 0.0017 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:00:06\n",
      "\u001b[32m[01/08 19:02:08 d2.evaluation.evaluator]: \u001b[0mInference done 4832/4871. Dataloading: 0.0017 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:00:01\n",
      "\u001b[32m[01/08 19:02:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:48.147917 (0.046886 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/08 19:02:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:38 (0.044847 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/08 19:02:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/08 19:02:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[01/08 19:02:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.67s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/08 19:02:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/08 19:02:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.84 seconds.\n",
      "\u001b[32m[01/08 19:02:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/08 19:02:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.23 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/08 19:02:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[01/08 19:02:14 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/08 19:02:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[01/08 19:02:14 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[01/08 19:02:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/08 19:02:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/08 19:02:14 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[01/08 19:02:14 d2.utils.events]: \u001b[0m eta: 4:42:49  iter: 5999  total_loss: 0.4935  loss_cls: 0.2375  loss_box_reg: 0.2091  loss_rpn_cls: 0.01352  loss_rpn_loc: 0.02756  time: 1.8869  data_time: 0.1989  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:02:52 d2.utils.events]: \u001b[0m eta: 4:42:12  iter: 6019  total_loss: 0.519  loss_cls: 0.2463  loss_box_reg: 0.215  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.03056  time: 1.8869  data_time: 0.2063  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:03:30 d2.utils.events]: \u001b[0m eta: 4:41:33  iter: 6039  total_loss: 0.5453  loss_cls: 0.2621  loss_box_reg: 0.2194  loss_rpn_cls: 0.01577  loss_rpn_loc: 0.03592  time: 1.8869  data_time: 0.2029  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:04:08 d2.utils.events]: \u001b[0m eta: 4:40:56  iter: 6059  total_loss: 0.4655  loss_cls: 0.2335  loss_box_reg: 0.2142  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.02329  time: 1.8869  data_time: 0.2110  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:04:45 d2.utils.events]: \u001b[0m eta: 4:40:19  iter: 6079  total_loss: 0.5021  loss_cls: 0.2625  loss_box_reg: 0.2223  loss_rpn_cls: 0.01551  loss_rpn_loc: 0.02773  time: 1.8869  data_time: 0.2005  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:05:23 d2.utils.events]: \u001b[0m eta: 4:39:43  iter: 6099  total_loss: 0.5184  loss_cls: 0.2529  loss_box_reg: 0.2125  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.02648  time: 1.8869  data_time: 0.2041  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:06:01 d2.utils.events]: \u001b[0m eta: 4:39:06  iter: 6119  total_loss: 0.4752  loss_cls: 0.2308  loss_box_reg: 0.2108  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.02509  time: 1.8869  data_time: 0.2084  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:06:39 d2.utils.events]: \u001b[0m eta: 4:38:28  iter: 6139  total_loss: 0.4811  loss_cls: 0.2399  loss_box_reg: 0.2161  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.03094  time: 1.8870  data_time: 0.2110  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:07:17 d2.utils.events]: \u001b[0m eta: 4:37:51  iter: 6159  total_loss: 0.4919  loss_cls: 0.2446  loss_box_reg: 0.2101  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.02921  time: 1.8870  data_time: 0.1995  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:07:54 d2.utils.events]: \u001b[0m eta: 4:37:13  iter: 6179  total_loss: 0.5308  loss_cls: 0.2631  loss_box_reg: 0.2158  loss_rpn_cls: 0.01529  loss_rpn_loc: 0.03441  time: 1.8870  data_time: 0.2062  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:08:32 d2.utils.events]: \u001b[0m eta: 4:36:35  iter: 6199  total_loss: 0.5011  loss_cls: 0.2313  loss_box_reg: 0.2114  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.02508  time: 1.8870  data_time: 0.2008  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:09:10 d2.utils.events]: \u001b[0m eta: 4:35:58  iter: 6219  total_loss: 0.4767  loss_cls: 0.2323  loss_box_reg: 0.206  loss_rpn_cls: 0.0143  loss_rpn_loc: 0.0292  time: 1.8870  data_time: 0.2056  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:09:48 d2.utils.events]: \u001b[0m eta: 4:35:20  iter: 6239  total_loss: 0.5055  loss_cls: 0.243  loss_box_reg: 0.205  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.02958  time: 1.8870  data_time: 0.1973  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:10:26 d2.utils.events]: \u001b[0m eta: 4:34:44  iter: 6259  total_loss: 0.4662  loss_cls: 0.2294  loss_box_reg: 0.2095  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.02268  time: 1.8870  data_time: 0.2070  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:11:03 d2.utils.events]: \u001b[0m eta: 4:34:05  iter: 6279  total_loss: 0.5137  loss_cls: 0.2473  loss_box_reg: 0.1949  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.03003  time: 1.8870  data_time: 0.2036  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:11:41 d2.utils.events]: \u001b[0m eta: 4:33:28  iter: 6299  total_loss: 0.5123  loss_cls: 0.2601  loss_box_reg: 0.2162  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.02989  time: 1.8870  data_time: 0.2053  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:12:19 d2.utils.events]: \u001b[0m eta: 4:32:51  iter: 6319  total_loss: 0.4924  loss_cls: 0.2385  loss_box_reg: 0.2011  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.02285  time: 1.8870  data_time: 0.2046  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:12:57 d2.utils.events]: \u001b[0m eta: 4:32:12  iter: 6339  total_loss: 0.4793  loss_cls: 0.2198  loss_box_reg: 0.2025  loss_rpn_cls: 0.01693  loss_rpn_loc: 0.02736  time: 1.8870  data_time: 0.2010  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:13:35 d2.utils.events]: \u001b[0m eta: 4:31:34  iter: 6359  total_loss: 0.4985  loss_cls: 0.2436  loss_box_reg: 0.2049  loss_rpn_cls: 0.016  loss_rpn_loc: 0.03179  time: 1.8870  data_time: 0.2076  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:14:12 d2.utils.events]: \u001b[0m eta: 4:30:57  iter: 6379  total_loss: 0.4811  loss_cls: 0.2366  loss_box_reg: 0.2041  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.02573  time: 1.8870  data_time: 0.2051  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:14:50 d2.utils.events]: \u001b[0m eta: 4:30:18  iter: 6399  total_loss: 0.4897  loss_cls: 0.2521  loss_box_reg: 0.2117  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.02852  time: 1.8870  data_time: 0.2011  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:15:28 d2.utils.events]: \u001b[0m eta: 4:29:42  iter: 6419  total_loss: 0.4767  loss_cls: 0.2238  loss_box_reg: 0.1997  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.02569  time: 1.8870  data_time: 0.2064  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:16:06 d2.utils.events]: \u001b[0m eta: 4:29:04  iter: 6439  total_loss: 0.5163  loss_cls: 0.2436  loss_box_reg: 0.2213  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.03546  time: 1.8870  data_time: 0.1976  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:16:43 d2.utils.events]: \u001b[0m eta: 4:28:26  iter: 6459  total_loss: 0.4466  loss_cls: 0.2097  loss_box_reg: 0.1986  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.02791  time: 1.8870  data_time: 0.2077  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:17:21 d2.utils.events]: \u001b[0m eta: 4:27:48  iter: 6479  total_loss: 0.5157  loss_cls: 0.2592  loss_box_reg: 0.2225  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.02528  time: 1.8870  data_time: 0.2022  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:17:59 d2.utils.events]: \u001b[0m eta: 4:27:10  iter: 6499  total_loss: 0.4845  loss_cls: 0.2289  loss_box_reg: 0.2037  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.02481  time: 1.8870  data_time: 0.1982  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:18:37 d2.utils.events]: \u001b[0m eta: 4:26:32  iter: 6519  total_loss: 0.4526  loss_cls: 0.2129  loss_box_reg: 0.1885  loss_rpn_cls: 0.009857  loss_rpn_loc: 0.02931  time: 1.8871  data_time: 0.2048  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:19:15 d2.utils.events]: \u001b[0m eta: 4:25:55  iter: 6539  total_loss: 0.4773  loss_cls: 0.2315  loss_box_reg: 0.2092  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.0225  time: 1.8871  data_time: 0.2048  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:19:52 d2.utils.events]: \u001b[0m eta: 4:25:17  iter: 6559  total_loss: 0.4709  loss_cls: 0.2169  loss_box_reg: 0.2108  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.02818  time: 1.8871  data_time: 0.2000  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:20:30 d2.utils.events]: \u001b[0m eta: 4:24:39  iter: 6579  total_loss: 0.4678  loss_cls: 0.2237  loss_box_reg: 0.204  loss_rpn_cls: 0.0108  loss_rpn_loc: 0.02832  time: 1.8871  data_time: 0.2040  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:21:08 d2.utils.events]: \u001b[0m eta: 4:24:01  iter: 6599  total_loss: 0.4615  loss_cls: 0.2299  loss_box_reg: 0.1973  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.02468  time: 1.8871  data_time: 0.2032  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:21:46 d2.utils.events]: \u001b[0m eta: 4:23:24  iter: 6619  total_loss: 0.4941  loss_cls: 0.2217  loss_box_reg: 0.2194  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.02714  time: 1.8871  data_time: 0.2032  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:22:24 d2.utils.events]: \u001b[0m eta: 4:22:48  iter: 6639  total_loss: 0.4585  loss_cls: 0.2373  loss_box_reg: 0.2006  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.02876  time: 1.8871  data_time: 0.2063  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:23:02 d2.utils.events]: \u001b[0m eta: 4:22:10  iter: 6659  total_loss: 0.5121  loss_cls: 0.236  loss_box_reg: 0.2249  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.02694  time: 1.8871  data_time: 0.2039  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:23:40 d2.utils.events]: \u001b[0m eta: 4:21:35  iter: 6679  total_loss: 0.45  loss_cls: 0.2321  loss_box_reg: 0.1961  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.02543  time: 1.8872  data_time: 0.2060  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:24:17 d2.utils.events]: \u001b[0m eta: 4:21:00  iter: 6699  total_loss: 0.4882  loss_cls: 0.2279  loss_box_reg: 0.2195  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.03235  time: 1.8872  data_time: 0.2026  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:24:55 d2.utils.events]: \u001b[0m eta: 4:20:22  iter: 6719  total_loss: 0.4782  loss_cls: 0.2243  loss_box_reg: 0.1971  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.02925  time: 1.8872  data_time: 0.2113  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:25:33 d2.utils.events]: \u001b[0m eta: 4:19:46  iter: 6739  total_loss: 0.4917  loss_cls: 0.2225  loss_box_reg: 0.216  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.03577  time: 1.8872  data_time: 0.2057  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:26:11 d2.utils.events]: \u001b[0m eta: 4:19:09  iter: 6759  total_loss: 0.4463  loss_cls: 0.218  loss_box_reg: 0.1896  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.02383  time: 1.8873  data_time: 0.2078  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:26:49 d2.utils.events]: \u001b[0m eta: 4:18:34  iter: 6779  total_loss: 0.4461  loss_cls: 0.2069  loss_box_reg: 0.1951  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.02379  time: 1.8873  data_time: 0.2063  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:27:27 d2.utils.events]: \u001b[0m eta: 4:17:56  iter: 6799  total_loss: 0.4544  loss_cls: 0.2063  loss_box_reg: 0.2073  loss_rpn_cls: 0.01022  loss_rpn_loc: 0.03364  time: 1.8873  data_time: 0.2037  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:28:05 d2.utils.events]: \u001b[0m eta: 4:17:18  iter: 6819  total_loss: 0.4904  loss_cls: 0.2235  loss_box_reg: 0.2024  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.02653  time: 1.8873  data_time: 0.2027  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:28:43 d2.utils.events]: \u001b[0m eta: 4:16:41  iter: 6839  total_loss: 0.4693  loss_cls: 0.2202  loss_box_reg: 0.2055  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.03424  time: 1.8873  data_time: 0.2035  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:29:20 d2.utils.events]: \u001b[0m eta: 4:16:03  iter: 6859  total_loss: 0.4611  loss_cls: 0.2188  loss_box_reg: 0.1964  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.02891  time: 1.8873  data_time: 0.2052  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:29:58 d2.utils.events]: \u001b[0m eta: 4:15:26  iter: 6879  total_loss: 0.4713  loss_cls: 0.2201  loss_box_reg: 0.1938  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.02899  time: 1.8873  data_time: 0.2030  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:30:36 d2.utils.events]: \u001b[0m eta: 4:14:49  iter: 6899  total_loss: 0.4116  loss_cls: 0.1952  loss_box_reg: 0.1818  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.02807  time: 1.8873  data_time: 0.2022  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:31:14 d2.utils.events]: \u001b[0m eta: 4:14:10  iter: 6919  total_loss: 0.4699  loss_cls: 0.2243  loss_box_reg: 0.2121  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.03061  time: 1.8873  data_time: 0.2041  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:31:51 d2.utils.events]: \u001b[0m eta: 4:13:32  iter: 6939  total_loss: 0.4933  loss_cls: 0.2343  loss_box_reg: 0.2265  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.02878  time: 1.8873  data_time: 0.2013  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:32:29 d2.utils.events]: \u001b[0m eta: 4:12:53  iter: 6959  total_loss: 0.4847  loss_cls: 0.2289  loss_box_reg: 0.1847  loss_rpn_cls: 0.01555  loss_rpn_loc: 0.02552  time: 1.8873  data_time: 0.2006  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:33:07 d2.utils.events]: \u001b[0m eta: 4:12:17  iter: 6979  total_loss: 0.4355  loss_cls: 0.2122  loss_box_reg: 0.1959  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.02935  time: 1.8873  data_time: 0.2019  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:33:45 d2.utils.events]: \u001b[0m eta: 4:11:39  iter: 6999  total_loss: 0.5022  loss_cls: 0.2373  loss_box_reg: 0.2167  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.02909  time: 1.8873  data_time: 0.2014  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:34:22 d2.utils.events]: \u001b[0m eta: 4:11:01  iter: 7019  total_loss: 0.4904  loss_cls: 0.2454  loss_box_reg: 0.206  loss_rpn_cls: 0.01654  loss_rpn_loc: 0.03039  time: 1.8873  data_time: 0.2009  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:35:00 d2.utils.events]: \u001b[0m eta: 4:10:23  iter: 7039  total_loss: 0.4934  loss_cls: 0.2321  loss_box_reg: 0.2122  loss_rpn_cls: 0.01527  loss_rpn_loc: 0.035  time: 1.8873  data_time: 0.2055  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:35:38 d2.utils.events]: \u001b[0m eta: 4:09:46  iter: 7059  total_loss: 0.4913  loss_cls: 0.2262  loss_box_reg: 0.2002  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.0325  time: 1.8873  data_time: 0.1990  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:36:16 d2.utils.events]: \u001b[0m eta: 4:09:09  iter: 7079  total_loss: 0.4457  loss_cls: 0.2023  loss_box_reg: 0.1932  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.02689  time: 1.8873  data_time: 0.2006  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:36:53 d2.utils.events]: \u001b[0m eta: 4:08:30  iter: 7099  total_loss: 0.4212  loss_cls: 0.1921  loss_box_reg: 0.1889  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.02105  time: 1.8873  data_time: 0.2031  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:37:31 d2.utils.events]: \u001b[0m eta: 4:07:53  iter: 7119  total_loss: 0.4434  loss_cls: 0.2016  loss_box_reg: 0.1913  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.03165  time: 1.8873  data_time: 0.2051  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:38:09 d2.utils.events]: \u001b[0m eta: 4:07:15  iter: 7139  total_loss: 0.4045  loss_cls: 0.2009  loss_box_reg: 0.1769  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.02  time: 1.8873  data_time: 0.2098  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:38:47 d2.utils.events]: \u001b[0m eta: 4:06:38  iter: 7159  total_loss: 0.4616  loss_cls: 0.2203  loss_box_reg: 0.2083  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.02738  time: 1.8873  data_time: 0.2026  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:39:25 d2.utils.events]: \u001b[0m eta: 4:05:59  iter: 7179  total_loss: 0.511  loss_cls: 0.2345  loss_box_reg: 0.2138  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.02595  time: 1.8873  data_time: 0.2025  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:40:03 d2.utils.events]: \u001b[0m eta: 4:05:22  iter: 7199  total_loss: 0.4485  loss_cls: 0.219  loss_box_reg: 0.1963  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.02972  time: 1.8873  data_time: 0.2046  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:40:41 d2.utils.events]: \u001b[0m eta: 4:04:45  iter: 7219  total_loss: 0.483  loss_cls: 0.2398  loss_box_reg: 0.2057  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.02908  time: 1.8874  data_time: 0.2092  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:41:18 d2.utils.events]: \u001b[0m eta: 4:04:07  iter: 7239  total_loss: 0.4212  loss_cls: 0.1982  loss_box_reg: 0.1771  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.02792  time: 1.8874  data_time: 0.1998  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:41:56 d2.utils.events]: \u001b[0m eta: 4:03:29  iter: 7259  total_loss: 0.501  loss_cls: 0.2288  loss_box_reg: 0.2088  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.02605  time: 1.8874  data_time: 0.2059  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:42:34 d2.utils.events]: \u001b[0m eta: 4:02:52  iter: 7279  total_loss: 0.4919  loss_cls: 0.2324  loss_box_reg: 0.2152  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.02851  time: 1.8874  data_time: 0.2051  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:43:12 d2.utils.events]: \u001b[0m eta: 4:02:14  iter: 7299  total_loss: 0.4678  loss_cls: 0.2249  loss_box_reg: 0.1976  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.03227  time: 1.8874  data_time: 0.2052  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:43:50 d2.utils.events]: \u001b[0m eta: 4:01:36  iter: 7319  total_loss: 0.4786  loss_cls: 0.2303  loss_box_reg: 0.211  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.0259  time: 1.8874  data_time: 0.2035  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:44:28 d2.utils.events]: \u001b[0m eta: 4:01:00  iter: 7339  total_loss: 0.499  loss_cls: 0.228  loss_box_reg: 0.2184  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.04491  time: 1.8874  data_time: 0.2093  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:45:06 d2.utils.events]: \u001b[0m eta: 4:00:22  iter: 7359  total_loss: 0.4933  loss_cls: 0.2202  loss_box_reg: 0.2128  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.02871  time: 1.8874  data_time: 0.2081  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:45:43 d2.utils.events]: \u001b[0m eta: 3:59:44  iter: 7379  total_loss: 0.4247  loss_cls: 0.2069  loss_box_reg: 0.1863  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.02672  time: 1.8875  data_time: 0.2048  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:46:21 d2.utils.events]: \u001b[0m eta: 3:59:07  iter: 7399  total_loss: 0.4597  loss_cls: 0.2121  loss_box_reg: 0.196  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.02635  time: 1.8875  data_time: 0.2012  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:46:59 d2.utils.events]: \u001b[0m eta: 3:58:29  iter: 7419  total_loss: 0.4269  loss_cls: 0.1938  loss_box_reg: 0.1904  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.026  time: 1.8875  data_time: 0.2078  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:47:37 d2.utils.events]: \u001b[0m eta: 3:57:53  iter: 7439  total_loss: 0.4618  loss_cls: 0.2201  loss_box_reg: 0.2071  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.03466  time: 1.8875  data_time: 0.2056  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:48:15 d2.utils.events]: \u001b[0m eta: 3:57:15  iter: 7459  total_loss: 0.4077  loss_cls: 0.2113  loss_box_reg: 0.1729  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.02151  time: 1.8875  data_time: 0.2069  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:48:53 d2.utils.events]: \u001b[0m eta: 3:56:38  iter: 7479  total_loss: 0.4712  loss_cls: 0.2151  loss_box_reg: 0.2021  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.03136  time: 1.8875  data_time: 0.2046  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:49:31 d2.utils.events]: \u001b[0m eta: 3:56:00  iter: 7499  total_loss: 0.4506  loss_cls: 0.2365  loss_box_reg: 0.1797  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.02677  time: 1.8875  data_time: 0.2032  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:50:09 d2.utils.events]: \u001b[0m eta: 3:55:23  iter: 7519  total_loss: 0.411  loss_cls: 0.1971  loss_box_reg: 0.1917  loss_rpn_cls: 0.009399  loss_rpn_loc: 0.01924  time: 1.8876  data_time: 0.2038  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:50:46 d2.utils.events]: \u001b[0m eta: 3:54:44  iter: 7539  total_loss: 0.4356  loss_cls: 0.1938  loss_box_reg: 0.1946  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.02064  time: 1.8876  data_time: 0.2018  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:51:24 d2.utils.events]: \u001b[0m eta: 3:54:08  iter: 7559  total_loss: 0.4803  loss_cls: 0.2242  loss_box_reg: 0.2144  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.03071  time: 1.8876  data_time: 0.2074  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:52:02 d2.utils.events]: \u001b[0m eta: 3:53:30  iter: 7579  total_loss: 0.4568  loss_cls: 0.2204  loss_box_reg: 0.1894  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.0285  time: 1.8876  data_time: 0.2042  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:52:40 d2.utils.events]: \u001b[0m eta: 3:52:52  iter: 7599  total_loss: 0.4767  loss_cls: 0.2187  loss_box_reg: 0.2154  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.02757  time: 1.8876  data_time: 0.1985  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:53:18 d2.utils.events]: \u001b[0m eta: 3:52:14  iter: 7619  total_loss: 0.4907  loss_cls: 0.213  loss_box_reg: 0.2167  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.03181  time: 1.8876  data_time: 0.2059  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:53:56 d2.utils.events]: \u001b[0m eta: 3:51:35  iter: 7639  total_loss: 0.4662  loss_cls: 0.2123  loss_box_reg: 0.2042  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.03242  time: 1.8876  data_time: 0.2037  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:54:33 d2.utils.events]: \u001b[0m eta: 3:50:57  iter: 7659  total_loss: 0.4517  loss_cls: 0.2082  loss_box_reg: 0.1946  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.02984  time: 1.8876  data_time: 0.2050  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:55:11 d2.utils.events]: \u001b[0m eta: 3:50:19  iter: 7679  total_loss: 0.47  loss_cls: 0.2244  loss_box_reg: 0.2151  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.02788  time: 1.8876  data_time: 0.2047  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:55:49 d2.utils.events]: \u001b[0m eta: 3:49:40  iter: 7699  total_loss: 0.445  loss_cls: 0.2046  loss_box_reg: 0.1986  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.02469  time: 1.8876  data_time: 0.2053  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:56:27 d2.utils.events]: \u001b[0m eta: 3:49:01  iter: 7719  total_loss: 0.4408  loss_cls: 0.1952  loss_box_reg: 0.1974  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.03257  time: 1.8877  data_time: 0.2049  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:57:05 d2.utils.events]: \u001b[0m eta: 3:48:23  iter: 7739  total_loss: 0.422  loss_cls: 0.1971  loss_box_reg: 0.2071  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.02571  time: 1.8877  data_time: 0.2034  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:57:43 d2.utils.events]: \u001b[0m eta: 3:47:45  iter: 7759  total_loss: 0.4549  loss_cls: 0.2187  loss_box_reg: 0.1955  loss_rpn_cls: 0.009944  loss_rpn_loc: 0.03015  time: 1.8877  data_time: 0.2083  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:58:20 d2.utils.events]: \u001b[0m eta: 3:47:07  iter: 7779  total_loss: 0.4395  loss_cls: 0.2056  loss_box_reg: 0.1928  loss_rpn_cls: 0.009256  loss_rpn_loc: 0.02529  time: 1.8877  data_time: 0.2047  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:58:58 d2.utils.events]: \u001b[0m eta: 3:46:29  iter: 7799  total_loss: 0.4885  loss_cls: 0.2294  loss_box_reg: 0.2046  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.0331  time: 1.8877  data_time: 0.2035  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 19:59:36 d2.utils.events]: \u001b[0m eta: 3:45:52  iter: 7819  total_loss: 0.4719  loss_cls: 0.2218  loss_box_reg: 0.2026  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.02965  time: 1.8877  data_time: 0.2008  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:00:14 d2.utils.events]: \u001b[0m eta: 3:45:14  iter: 7839  total_loss: 0.3818  loss_cls: 0.1832  loss_box_reg: 0.1685  loss_rpn_cls: 0.01022  loss_rpn_loc: 0.02249  time: 1.8877  data_time: 0.2062  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:00:52 d2.utils.events]: \u001b[0m eta: 3:44:36  iter: 7859  total_loss: 0.4684  loss_cls: 0.2176  loss_box_reg: 0.1971  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.02707  time: 1.8877  data_time: 0.2047  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:01:30 d2.utils.events]: \u001b[0m eta: 3:43:58  iter: 7879  total_loss: 0.4628  loss_cls: 0.2115  loss_box_reg: 0.2011  loss_rpn_cls: 0.009456  loss_rpn_loc: 0.02649  time: 1.8877  data_time: 0.2055  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:02:08 d2.utils.events]: \u001b[0m eta: 3:43:21  iter: 7899  total_loss: 0.446  loss_cls: 0.2071  loss_box_reg: 0.1992  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.02854  time: 1.8877  data_time: 0.2031  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:02:45 d2.utils.events]: \u001b[0m eta: 3:42:44  iter: 7919  total_loss: 0.422  loss_cls: 0.2036  loss_box_reg: 0.1765  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.03026  time: 1.8878  data_time: 0.2113  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:03:23 d2.utils.events]: \u001b[0m eta: 3:42:06  iter: 7939  total_loss: 0.481  loss_cls: 0.2304  loss_box_reg: 0.1965  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.02942  time: 1.8878  data_time: 0.2071  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:04:01 d2.utils.events]: \u001b[0m eta: 3:41:28  iter: 7959  total_loss: 0.421  loss_cls: 0.1917  loss_box_reg: 0.1773  loss_rpn_cls: 0.009944  loss_rpn_loc: 0.02431  time: 1.8878  data_time: 0.2029  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:04:39 d2.utils.events]: \u001b[0m eta: 3:40:50  iter: 7979  total_loss: 0.4087  loss_cls: 0.1844  loss_box_reg: 0.1936  loss_rpn_cls: 0.009629  loss_rpn_loc: 0.02678  time: 1.8878  data_time: 0.2056  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:05:17 d2.utils.events]: \u001b[0m eta: 3:40:14  iter: 7999  total_loss: 0.4499  loss_cls: 0.2152  loss_box_reg: 0.2027  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.02915  time: 1.8878  data_time: 0.2040  lr: 0.001  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:05:55 d2.utils.events]: \u001b[0m eta: 3:39:39  iter: 8019  total_loss: 0.4501  loss_cls: 0.2123  loss_box_reg: 0.1994  loss_rpn_cls: 0.01032  loss_rpn_loc: 0.02477  time: 1.8878  data_time: 0.2080  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:06:33 d2.utils.events]: \u001b[0m eta: 3:39:02  iter: 8039  total_loss: 0.4939  loss_cls: 0.2166  loss_box_reg: 0.2172  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.03142  time: 1.8878  data_time: 0.2093  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:07:10 d2.utils.events]: \u001b[0m eta: 3:38:23  iter: 8059  total_loss: 0.4573  loss_cls: 0.2128  loss_box_reg: 0.2091  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.03181  time: 1.8878  data_time: 0.2004  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:07:48 d2.utils.events]: \u001b[0m eta: 3:37:46  iter: 8079  total_loss: 0.4004  loss_cls: 0.1914  loss_box_reg: 0.1887  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.02945  time: 1.8878  data_time: 0.2001  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:08:26 d2.utils.events]: \u001b[0m eta: 3:37:08  iter: 8099  total_loss: 0.4058  loss_cls: 0.1934  loss_box_reg: 0.1955  loss_rpn_cls: 0.012  loss_rpn_loc: 0.01993  time: 1.8878  data_time: 0.1984  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:09:04 d2.utils.events]: \u001b[0m eta: 3:36:29  iter: 8119  total_loss: 0.4504  loss_cls: 0.2013  loss_box_reg: 0.2046  loss_rpn_cls: 0.01072  loss_rpn_loc: 0.02469  time: 1.8878  data_time: 0.2059  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:09:41 d2.utils.events]: \u001b[0m eta: 3:35:52  iter: 8139  total_loss: 0.4222  loss_cls: 0.2047  loss_box_reg: 0.1914  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.0228  time: 1.8878  data_time: 0.2070  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:10:19 d2.utils.events]: \u001b[0m eta: 3:35:13  iter: 8159  total_loss: 0.3912  loss_cls: 0.1895  loss_box_reg: 0.1761  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.02108  time: 1.8878  data_time: 0.2021  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:10:57 d2.utils.events]: \u001b[0m eta: 3:34:37  iter: 8179  total_loss: 0.4365  loss_cls: 0.198  loss_box_reg: 0.2012  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.02987  time: 1.8878  data_time: 0.2031  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:11:35 d2.utils.events]: \u001b[0m eta: 3:33:58  iter: 8199  total_loss: 0.4365  loss_cls: 0.188  loss_box_reg: 0.1973  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.0277  time: 1.8878  data_time: 0.2052  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:12:13 d2.utils.events]: \u001b[0m eta: 3:33:20  iter: 8219  total_loss: 0.4419  loss_cls: 0.2028  loss_box_reg: 0.1993  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.02643  time: 1.8878  data_time: 0.2021  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:12:50 d2.utils.events]: \u001b[0m eta: 3:32:42  iter: 8239  total_loss: 0.4513  loss_cls: 0.2  loss_box_reg: 0.1979  loss_rpn_cls: 0.01178  loss_rpn_loc: 0.0263  time: 1.8878  data_time: 0.2017  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:13:28 d2.utils.events]: \u001b[0m eta: 3:32:05  iter: 8259  total_loss: 0.3948  loss_cls: 0.1725  loss_box_reg: 0.1825  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.02367  time: 1.8879  data_time: 0.2020  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:14:06 d2.utils.events]: \u001b[0m eta: 3:31:27  iter: 8279  total_loss: 0.4186  loss_cls: 0.1878  loss_box_reg: 0.1843  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.03175  time: 1.8879  data_time: 0.2019  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:14:44 d2.utils.events]: \u001b[0m eta: 3:30:48  iter: 8299  total_loss: 0.4291  loss_cls: 0.1938  loss_box_reg: 0.1955  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.02446  time: 1.8879  data_time: 0.2021  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:15:22 d2.utils.events]: \u001b[0m eta: 3:30:12  iter: 8319  total_loss: 0.4084  loss_cls: 0.1903  loss_box_reg: 0.1873  loss_rpn_cls: 0.009859  loss_rpn_loc: 0.02897  time: 1.8879  data_time: 0.2051  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:16:00 d2.utils.events]: \u001b[0m eta: 3:29:33  iter: 8339  total_loss: 0.4312  loss_cls: 0.2035  loss_box_reg: 0.1893  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.02335  time: 1.8879  data_time: 0.2031  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:16:37 d2.utils.events]: \u001b[0m eta: 3:28:54  iter: 8359  total_loss: 0.4014  loss_cls: 0.1925  loss_box_reg: 0.1823  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.02173  time: 1.8879  data_time: 0.2031  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:17:15 d2.utils.events]: \u001b[0m eta: 3:28:17  iter: 8379  total_loss: 0.4064  loss_cls: 0.1834  loss_box_reg: 0.1797  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.02653  time: 1.8879  data_time: 0.2066  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:17:53 d2.utils.events]: \u001b[0m eta: 3:27:42  iter: 8399  total_loss: 0.4783  loss_cls: 0.2074  loss_box_reg: 0.2048  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.03573  time: 1.8879  data_time: 0.2038  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:18:31 d2.utils.events]: \u001b[0m eta: 3:27:03  iter: 8419  total_loss: 0.4539  loss_cls: 0.2119  loss_box_reg: 0.2056  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.02738  time: 1.8879  data_time: 0.2037  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:19:09 d2.utils.events]: \u001b[0m eta: 3:26:26  iter: 8439  total_loss: 0.3845  loss_cls: 0.1631  loss_box_reg: 0.1718  loss_rpn_cls: 0.008596  loss_rpn_loc: 0.03173  time: 1.8879  data_time: 0.2022  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:19:47 d2.utils.events]: \u001b[0m eta: 3:25:46  iter: 8459  total_loss: 0.3862  loss_cls: 0.1793  loss_box_reg: 0.1771  loss_rpn_cls: 0.008384  loss_rpn_loc: 0.02679  time: 1.8879  data_time: 0.2004  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:20:25 d2.utils.events]: \u001b[0m eta: 3:25:10  iter: 8479  total_loss: 0.4271  loss_cls: 0.195  loss_box_reg: 0.1955  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.028  time: 1.8879  data_time: 0.2075  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:21:02 d2.utils.events]: \u001b[0m eta: 3:24:34  iter: 8499  total_loss: 0.419  loss_cls: 0.1915  loss_box_reg: 0.1897  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.02933  time: 1.8879  data_time: 0.2058  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:21:40 d2.utils.events]: \u001b[0m eta: 3:23:56  iter: 8519  total_loss: 0.4214  loss_cls: 0.1855  loss_box_reg: 0.181  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.02739  time: 1.8880  data_time: 0.2060  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:22:18 d2.utils.events]: \u001b[0m eta: 3:23:18  iter: 8539  total_loss: 0.4708  loss_cls: 0.2055  loss_box_reg: 0.2055  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.02505  time: 1.8880  data_time: 0.2006  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:22:56 d2.utils.events]: \u001b[0m eta: 3:22:39  iter: 8559  total_loss: 0.4439  loss_cls: 0.2039  loss_box_reg: 0.1998  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.0306  time: 1.8880  data_time: 0.2014  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:23:34 d2.utils.events]: \u001b[0m eta: 3:22:00  iter: 8579  total_loss: 0.4292  loss_cls: 0.1919  loss_box_reg: 0.1892  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.03269  time: 1.8879  data_time: 0.2011  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:24:11 d2.utils.events]: \u001b[0m eta: 3:21:23  iter: 8599  total_loss: 0.4145  loss_cls: 0.1824  loss_box_reg: 0.1924  loss_rpn_cls: 0.009564  loss_rpn_loc: 0.02969  time: 1.8880  data_time: 0.2040  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:24:49 d2.utils.events]: \u001b[0m eta: 3:20:45  iter: 8619  total_loss: 0.4169  loss_cls: 0.1867  loss_box_reg: 0.1993  loss_rpn_cls: 0.008396  loss_rpn_loc: 0.02343  time: 1.8880  data_time: 0.2033  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:25:27 d2.utils.events]: \u001b[0m eta: 3:20:08  iter: 8639  total_loss: 0.4859  loss_cls: 0.2094  loss_box_reg: 0.2145  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.03669  time: 1.8880  data_time: 0.2070  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:26:05 d2.utils.events]: \u001b[0m eta: 3:19:30  iter: 8659  total_loss: 0.4103  loss_cls: 0.1967  loss_box_reg: 0.1762  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.02347  time: 1.8880  data_time: 0.2004  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:26:43 d2.utils.events]: \u001b[0m eta: 3:18:52  iter: 8679  total_loss: 0.356  loss_cls: 0.1618  loss_box_reg: 0.1601  loss_rpn_cls: 0.009821  loss_rpn_loc: 0.02505  time: 1.8880  data_time: 0.2034  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:27:21 d2.utils.events]: \u001b[0m eta: 3:18:15  iter: 8699  total_loss: 0.4036  loss_cls: 0.1857  loss_box_reg: 0.1921  loss_rpn_cls: 0.009042  loss_rpn_loc: 0.02246  time: 1.8880  data_time: 0.2041  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:27:58 d2.utils.events]: \u001b[0m eta: 3:17:38  iter: 8719  total_loss: 0.407  loss_cls: 0.191  loss_box_reg: 0.1831  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.0229  time: 1.8880  data_time: 0.2049  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:28:36 d2.utils.events]: \u001b[0m eta: 3:17:02  iter: 8739  total_loss: 0.4881  loss_cls: 0.2143  loss_box_reg: 0.2166  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.0322  time: 1.8880  data_time: 0.2043  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:29:14 d2.utils.events]: \u001b[0m eta: 3:16:24  iter: 8759  total_loss: 0.418  loss_cls: 0.192  loss_box_reg: 0.1842  loss_rpn_cls: 0.01056  loss_rpn_loc: 0.03163  time: 1.8880  data_time: 0.2031  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:29:52 d2.utils.events]: \u001b[0m eta: 3:15:46  iter: 8779  total_loss: 0.4308  loss_cls: 0.1851  loss_box_reg: 0.1797  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.02502  time: 1.8880  data_time: 0.2041  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:30:30 d2.utils.events]: \u001b[0m eta: 3:15:09  iter: 8799  total_loss: 0.4074  loss_cls: 0.1818  loss_box_reg: 0.1808  loss_rpn_cls: 0.007707  loss_rpn_loc: 0.02485  time: 1.8880  data_time: 0.2063  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:31:08 d2.utils.events]: \u001b[0m eta: 3:14:31  iter: 8819  total_loss: 0.4016  loss_cls: 0.194  loss_box_reg: 0.1785  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.02661  time: 1.8880  data_time: 0.2074  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:31:46 d2.utils.events]: \u001b[0m eta: 3:13:53  iter: 8839  total_loss: 0.413  loss_cls: 0.1988  loss_box_reg: 0.1753  loss_rpn_cls: 0.009692  loss_rpn_loc: 0.02354  time: 1.8881  data_time: 0.2034  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:32:23 d2.utils.events]: \u001b[0m eta: 3:13:15  iter: 8859  total_loss: 0.4304  loss_cls: 0.1891  loss_box_reg: 0.1884  loss_rpn_cls: 0.013  loss_rpn_loc: 0.02358  time: 1.8881  data_time: 0.2064  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:33:01 d2.utils.events]: \u001b[0m eta: 3:12:37  iter: 8879  total_loss: 0.4599  loss_cls: 0.2116  loss_box_reg: 0.1999  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.03185  time: 1.8881  data_time: 0.2146  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:33:39 d2.utils.events]: \u001b[0m eta: 3:12:00  iter: 8899  total_loss: 0.3898  loss_cls: 0.1843  loss_box_reg: 0.1786  loss_rpn_cls: 0.009643  loss_rpn_loc: 0.0223  time: 1.8881  data_time: 0.2065  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:34:17 d2.utils.events]: \u001b[0m eta: 3:11:22  iter: 8919  total_loss: 0.4288  loss_cls: 0.2004  loss_box_reg: 0.2021  loss_rpn_cls: 0.011  loss_rpn_loc: 0.02431  time: 1.8881  data_time: 0.2054  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:34:55 d2.utils.events]: \u001b[0m eta: 3:10:47  iter: 8939  total_loss: 0.3794  loss_cls: 0.1715  loss_box_reg: 0.1683  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.02625  time: 1.8881  data_time: 0.2079  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:35:33 d2.utils.events]: \u001b[0m eta: 3:10:10  iter: 8959  total_loss: 0.3979  loss_cls: 0.1696  loss_box_reg: 0.1754  loss_rpn_cls: 0.009288  loss_rpn_loc: 0.02394  time: 1.8882  data_time: 0.2073  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:36:11 d2.utils.events]: \u001b[0m eta: 3:09:32  iter: 8979  total_loss: 0.3666  loss_cls: 0.164  loss_box_reg: 0.1688  loss_rpn_cls: 0.01003  loss_rpn_loc: 0.03217  time: 1.8881  data_time: 0.1968  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:36:50 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../../../dataset/test.json\n",
      "\u001b[32m[01/08 20:36:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/08 20:36:50 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/08 20:36:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.53 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/08 20:36:50 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/08 20:36:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[01/08 20:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0010 s/iter. Inference: 0.0440 s/iter. Eval: 0.0003 s/iter. Total: 0.0452 s/iter. ETA=0:03:39\n",
      "\u001b[32m[01/08 20:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 117/4871. Dataloading: 0.0015 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:03:43\n",
      "\u001b[32m[01/08 20:37:01 d2.evaluation.evaluator]: \u001b[0mInference done 225/4871. Dataloading: 0.0015 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0467 s/iter. ETA=0:03:36\n",
      "\u001b[32m[01/08 20:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 331/4871. Dataloading: 0.0015 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:03:33\n",
      "\u001b[32m[01/08 20:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 444/4871. Dataloading: 0.0015 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:03:25\n",
      "\u001b[32m[01/08 20:37:16 d2.evaluation.evaluator]: \u001b[0mInference done 557/4871. Dataloading: 0.0015 s/iter. Inference: 0.0441 s/iter. Eval: 0.0002 s/iter. Total: 0.0459 s/iter. ETA=0:03:18\n",
      "\u001b[32m[01/08 20:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 668/4871. Dataloading: 0.0015 s/iter. Inference: 0.0440 s/iter. Eval: 0.0002 s/iter. Total: 0.0458 s/iter. ETA=0:03:12\n",
      "\u001b[32m[01/08 20:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 778/4871. Dataloading: 0.0015 s/iter. Inference: 0.0440 s/iter. Eval: 0.0002 s/iter. Total: 0.0458 s/iter. ETA=0:03:07\n",
      "\u001b[32m[01/08 20:37:31 d2.evaluation.evaluator]: \u001b[0mInference done 892/4871. Dataloading: 0.0015 s/iter. Inference: 0.0438 s/iter. Eval: 0.0002 s/iter. Total: 0.0456 s/iter. ETA=0:03:01\n",
      "\u001b[32m[01/08 20:37:36 d2.evaluation.evaluator]: \u001b[0mInference done 1001/4871. Dataloading: 0.0015 s/iter. Inference: 0.0438 s/iter. Eval: 0.0002 s/iter. Total: 0.0456 s/iter. ETA=0:02:56\n",
      "\u001b[32m[01/08 20:37:41 d2.evaluation.evaluator]: \u001b[0mInference done 1109/4871. Dataloading: 0.0015 s/iter. Inference: 0.0439 s/iter. Eval: 0.0002 s/iter. Total: 0.0457 s/iter. ETA=0:02:52\n",
      "\u001b[32m[01/08 20:37:46 d2.evaluation.evaluator]: \u001b[0mInference done 1223/4871. Dataloading: 0.0015 s/iter. Inference: 0.0438 s/iter. Eval: 0.0002 s/iter. Total: 0.0456 s/iter. ETA=0:02:46\n",
      "\u001b[32m[01/08 20:37:51 d2.evaluation.evaluator]: \u001b[0mInference done 1336/4871. Dataloading: 0.0015 s/iter. Inference: 0.0437 s/iter. Eval: 0.0002 s/iter. Total: 0.0455 s/iter. ETA=0:02:40\n",
      "\u001b[32m[01/08 20:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 1449/4871. Dataloading: 0.0015 s/iter. Inference: 0.0436 s/iter. Eval: 0.0002 s/iter. Total: 0.0454 s/iter. ETA=0:02:35\n",
      "\u001b[32m[01/08 20:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 1559/4871. Dataloading: 0.0015 s/iter. Inference: 0.0436 s/iter. Eval: 0.0002 s/iter. Total: 0.0454 s/iter. ETA=0:02:30\n",
      "\u001b[32m[01/08 20:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 1666/4871. Dataloading: 0.0015 s/iter. Inference: 0.0437 s/iter. Eval: 0.0002 s/iter. Total: 0.0455 s/iter. ETA=0:02:25\n",
      "\u001b[32m[01/08 20:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 1773/4871. Dataloading: 0.0015 s/iter. Inference: 0.0438 s/iter. Eval: 0.0002 s/iter. Total: 0.0456 s/iter. ETA=0:02:21\n",
      "\u001b[32m[01/08 20:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 1880/4871. Dataloading: 0.0016 s/iter. Inference: 0.0438 s/iter. Eval: 0.0002 s/iter. Total: 0.0457 s/iter. ETA=0:02:16\n",
      "\u001b[32m[01/08 20:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 1988/4871. Dataloading: 0.0015 s/iter. Inference: 0.0439 s/iter. Eval: 0.0002 s/iter. Total: 0.0457 s/iter. ETA=0:02:11\n",
      "\u001b[32m[01/08 20:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 2094/4871. Dataloading: 0.0016 s/iter. Inference: 0.0439 s/iter. Eval: 0.0002 s/iter. Total: 0.0458 s/iter. ETA=0:02:07\n",
      "\u001b[32m[01/08 20:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 2201/4871. Dataloading: 0.0016 s/iter. Inference: 0.0440 s/iter. Eval: 0.0002 s/iter. Total: 0.0459 s/iter. ETA=0:02:02\n",
      "\u001b[32m[01/08 20:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 2308/4871. Dataloading: 0.0016 s/iter. Inference: 0.0440 s/iter. Eval: 0.0002 s/iter. Total: 0.0459 s/iter. ETA=0:01:57\n",
      "\u001b[32m[01/08 20:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 2415/4871. Dataloading: 0.0016 s/iter. Inference: 0.0441 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:01:52\n",
      "\u001b[32m[01/08 20:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 2520/4871. Dataloading: 0.0016 s/iter. Inference: 0.0441 s/iter. Eval: 0.0002 s/iter. Total: 0.0460 s/iter. ETA=0:01:48\n",
      "\u001b[32m[01/08 20:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 2626/4871. Dataloading: 0.0016 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:43\n",
      "\u001b[32m[01/08 20:38:57 d2.evaluation.evaluator]: \u001b[0mInference done 2733/4871. Dataloading: 0.0016 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:38\n",
      "\u001b[32m[01/08 20:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 2840/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:33\n",
      "\u001b[32m[01/08 20:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 2948/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:28\n",
      "\u001b[32m[01/08 20:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 3053/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:24\n",
      "\u001b[32m[01/08 20:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 3164/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:18\n",
      "\u001b[32m[01/08 20:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 3276/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:01:13\n",
      "\u001b[32m[01/08 20:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 3386/4871. Dataloading: 0.0016 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:08\n",
      "\u001b[32m[01/08 20:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 3495/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0461 s/iter. ETA=0:01:03\n",
      "\u001b[32m[01/08 20:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 3599/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:00:58\n",
      "\u001b[32m[01/08 20:39:42 d2.evaluation.evaluator]: \u001b[0mInference done 3707/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:00:53\n",
      "\u001b[32m[01/08 20:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 3815/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:00:48\n",
      "\u001b[32m[01/08 20:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 3923/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:00:43\n",
      "\u001b[32m[01/08 20:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 4030/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0462 s/iter. ETA=0:00:38\n",
      "\u001b[32m[01/08 20:40:02 d2.evaluation.evaluator]: \u001b[0mInference done 4133/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:00:34\n",
      "\u001b[32m[01/08 20:40:07 d2.evaluation.evaluator]: \u001b[0mInference done 4240/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:00:29\n",
      "\u001b[32m[01/08 20:40:12 d2.evaluation.evaluator]: \u001b[0mInference done 4346/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:00:24\n",
      "\u001b[32m[01/08 20:40:17 d2.evaluation.evaluator]: \u001b[0mInference done 4452/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:00:19\n",
      "\u001b[32m[01/08 20:40:22 d2.evaluation.evaluator]: \u001b[0mInference done 4561/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:00:14\n",
      "\u001b[32m[01/08 20:40:27 d2.evaluation.evaluator]: \u001b[0mInference done 4669/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0002 s/iter. Total: 0.0464 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/08 20:40:32 d2.evaluation.evaluator]: \u001b[0mInference done 4780/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0463 s/iter. ETA=0:00:04\n",
      "\u001b[32m[01/08 20:40:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:45.457550 (0.046333 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/08 20:40:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:36 (0.044412 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/08 20:40:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/08 20:40:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[01/08 20:40:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.64s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/08 20:40:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/08 20:40:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.70 seconds.\n",
      "\u001b[32m[01/08 20:40:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/08 20:40:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.22 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/08 20:40:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[01/08 20:40:40 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/08 20:40:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[01/08 20:40:41 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[01/08 20:40:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/08 20:40:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/08 20:40:41 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[01/08 20:40:41 d2.utils.events]: \u001b[0m eta: 3:08:54  iter: 8999  total_loss: 0.4141  loss_cls: 0.1945  loss_box_reg: 0.1881  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.02774  time: 1.8882  data_time: 0.2075  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:41:18 d2.utils.events]: \u001b[0m eta: 3:08:15  iter: 9019  total_loss: 0.4036  loss_cls: 0.192  loss_box_reg: 0.1833  loss_rpn_cls: 0.009524  loss_rpn_loc: 0.02642  time: 1.8882  data_time: 0.2031  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:41:56 d2.utils.events]: \u001b[0m eta: 3:07:37  iter: 9039  total_loss: 0.4017  loss_cls: 0.1829  loss_box_reg: 0.1865  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.03084  time: 1.8882  data_time: 0.2045  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:42:34 d2.utils.events]: \u001b[0m eta: 3:07:01  iter: 9059  total_loss: 0.427  loss_cls: 0.1932  loss_box_reg: 0.1824  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.02733  time: 1.8882  data_time: 0.2092  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:43:12 d2.utils.events]: \u001b[0m eta: 3:06:23  iter: 9079  total_loss: 0.4167  loss_cls: 0.1861  loss_box_reg: 0.1902  loss_rpn_cls: 0.009013  loss_rpn_loc: 0.02564  time: 1.8882  data_time: 0.2044  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:43:50 d2.utils.events]: \u001b[0m eta: 3:05:46  iter: 9099  total_loss: 0.4311  loss_cls: 0.2031  loss_box_reg: 0.1924  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.02419  time: 1.8882  data_time: 0.2079  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:44:28 d2.utils.events]: \u001b[0m eta: 3:05:08  iter: 9119  total_loss: 0.4489  loss_cls: 0.1977  loss_box_reg: 0.1998  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.03157  time: 1.8882  data_time: 0.2049  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:45:06 d2.utils.events]: \u001b[0m eta: 3:04:30  iter: 9139  total_loss: 0.3927  loss_cls: 0.1781  loss_box_reg: 0.1878  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.02278  time: 1.8882  data_time: 0.2040  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:45:44 d2.utils.events]: \u001b[0m eta: 3:03:52  iter: 9159  total_loss: 0.4133  loss_cls: 0.2017  loss_box_reg: 0.2012  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.0289  time: 1.8882  data_time: 0.2074  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:46:22 d2.utils.events]: \u001b[0m eta: 3:03:15  iter: 9179  total_loss: 0.427  loss_cls: 0.1988  loss_box_reg: 0.1914  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.02875  time: 1.8883  data_time: 0.2089  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:46:59 d2.utils.events]: \u001b[0m eta: 3:02:37  iter: 9199  total_loss: 0.3564  loss_cls: 0.1644  loss_box_reg: 0.1625  loss_rpn_cls: 0.008609  loss_rpn_loc: 0.0193  time: 1.8883  data_time: 0.2001  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:47:37 d2.utils.events]: \u001b[0m eta: 3:02:00  iter: 9219  total_loss: 0.4144  loss_cls: 0.1904  loss_box_reg: 0.1912  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.02343  time: 1.8883  data_time: 0.2052  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:48:15 d2.utils.events]: \u001b[0m eta: 3:01:23  iter: 9239  total_loss: 0.3894  loss_cls: 0.1725  loss_box_reg: 0.1834  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.02325  time: 1.8883  data_time: 0.2045  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:48:53 d2.utils.events]: \u001b[0m eta: 3:00:46  iter: 9259  total_loss: 0.4029  loss_cls: 0.1891  loss_box_reg: 0.1825  loss_rpn_cls: 0.008165  loss_rpn_loc: 0.03176  time: 1.8883  data_time: 0.2102  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:49:31 d2.utils.events]: \u001b[0m eta: 3:00:09  iter: 9279  total_loss: 0.4118  loss_cls: 0.185  loss_box_reg: 0.177  loss_rpn_cls: 0.01009  loss_rpn_loc: 0.02642  time: 1.8883  data_time: 0.2107  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:50:09 d2.utils.events]: \u001b[0m eta: 2:59:32  iter: 9299  total_loss: 0.3862  loss_cls: 0.1751  loss_box_reg: 0.1819  loss_rpn_cls: 0.008898  loss_rpn_loc: 0.0231  time: 1.8883  data_time: 0.2047  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:50:47 d2.utils.events]: \u001b[0m eta: 2:58:54  iter: 9319  total_loss: 0.4144  loss_cls: 0.1974  loss_box_reg: 0.1826  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.02568  time: 1.8883  data_time: 0.2073  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:51:25 d2.utils.events]: \u001b[0m eta: 2:58:16  iter: 9339  total_loss: 0.3958  loss_cls: 0.1814  loss_box_reg: 0.1871  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.02581  time: 1.8884  data_time: 0.2083  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:52:03 d2.utils.events]: \u001b[0m eta: 2:57:39  iter: 9359  total_loss: 0.4374  loss_cls: 0.1973  loss_box_reg: 0.191  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.03606  time: 1.8884  data_time: 0.2087  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:52:41 d2.utils.events]: \u001b[0m eta: 2:57:01  iter: 9379  total_loss: 0.4519  loss_cls: 0.2007  loss_box_reg: 0.1904  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.02705  time: 1.8884  data_time: 0.2058  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:53:19 d2.utils.events]: \u001b[0m eta: 2:56:22  iter: 9399  total_loss: 0.4376  loss_cls: 0.1839  loss_box_reg: 0.1963  loss_rpn_cls: 0.009619  loss_rpn_loc: 0.02841  time: 1.8884  data_time: 0.2067  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:53:56 d2.utils.events]: \u001b[0m eta: 2:55:45  iter: 9419  total_loss: 0.4458  loss_cls: 0.1991  loss_box_reg: 0.1927  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.03041  time: 1.8884  data_time: 0.2029  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:54:34 d2.utils.events]: \u001b[0m eta: 2:55:07  iter: 9439  total_loss: 0.3915  loss_cls: 0.1683  loss_box_reg: 0.1779  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.02407  time: 1.8884  data_time: 0.2031  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:55:12 d2.utils.events]: \u001b[0m eta: 2:54:31  iter: 9459  total_loss: 0.4144  loss_cls: 0.1992  loss_box_reg: 0.182  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.0255  time: 1.8884  data_time: 0.2056  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:55:50 d2.utils.events]: \u001b[0m eta: 2:53:53  iter: 9479  total_loss: 0.4259  loss_cls: 0.1864  loss_box_reg: 0.1898  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.02611  time: 1.8884  data_time: 0.2055  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:56:28 d2.utils.events]: \u001b[0m eta: 2:53:15  iter: 9499  total_loss: 0.4163  loss_cls: 0.1894  loss_box_reg: 0.1876  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.02852  time: 1.8884  data_time: 0.2023  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:57:06 d2.utils.events]: \u001b[0m eta: 2:52:37  iter: 9519  total_loss: 0.4048  loss_cls: 0.1838  loss_box_reg: 0.1811  loss_rpn_cls: 0.008528  loss_rpn_loc: 0.02696  time: 1.8884  data_time: 0.2030  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:57:43 d2.utils.events]: \u001b[0m eta: 2:51:59  iter: 9539  total_loss: 0.3978  loss_cls: 0.1912  loss_box_reg: 0.1775  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.02236  time: 1.8884  data_time: 0.2038  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:58:21 d2.utils.events]: \u001b[0m eta: 2:51:23  iter: 9559  total_loss: 0.4179  loss_cls: 0.1984  loss_box_reg: 0.1828  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.03268  time: 1.8884  data_time: 0.2023  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:58:59 d2.utils.events]: \u001b[0m eta: 2:50:46  iter: 9579  total_loss: 0.3896  loss_cls: 0.1832  loss_box_reg: 0.1792  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.02332  time: 1.8884  data_time: 0.2011  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 20:59:37 d2.utils.events]: \u001b[0m eta: 2:50:10  iter: 9599  total_loss: 0.4201  loss_cls: 0.2058  loss_box_reg: 0.1861  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.02955  time: 1.8885  data_time: 0.2075  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:00:15 d2.utils.events]: \u001b[0m eta: 2:49:33  iter: 9619  total_loss: 0.3997  loss_cls: 0.1761  loss_box_reg: 0.1798  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.02499  time: 1.8885  data_time: 0.2121  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:00:53 d2.utils.events]: \u001b[0m eta: 2:48:53  iter: 9639  total_loss: 0.4148  loss_cls: 0.2024  loss_box_reg: 0.1734  loss_rpn_cls: 0.009226  loss_rpn_loc: 0.0245  time: 1.8885  data_time: 0.2014  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:01:30 d2.utils.events]: \u001b[0m eta: 2:48:15  iter: 9659  total_loss: 0.4286  loss_cls: 0.2009  loss_box_reg: 0.1887  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.02638  time: 1.8885  data_time: 0.2032  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:02:08 d2.utils.events]: \u001b[0m eta: 2:47:39  iter: 9679  total_loss: 0.3998  loss_cls: 0.1726  loss_box_reg: 0.1719  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.01959  time: 1.8885  data_time: 0.2060  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:02:46 d2.utils.events]: \u001b[0m eta: 2:47:00  iter: 9699  total_loss: 0.4893  loss_cls: 0.2275  loss_box_reg: 0.2284  loss_rpn_cls: 0.01385  loss_rpn_loc: 0.02958  time: 1.8885  data_time: 0.2024  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:03:24 d2.utils.events]: \u001b[0m eta: 2:46:21  iter: 9719  total_loss: 0.3888  loss_cls: 0.1842  loss_box_reg: 0.1755  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.02463  time: 1.8885  data_time: 0.1968  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:04:02 d2.utils.events]: \u001b[0m eta: 2:45:42  iter: 9739  total_loss: 0.4283  loss_cls: 0.1927  loss_box_reg: 0.2029  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.03233  time: 1.8885  data_time: 0.2036  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:04:40 d2.utils.events]: \u001b[0m eta: 2:45:04  iter: 9759  total_loss: 0.391  loss_cls: 0.176  loss_box_reg: 0.187  loss_rpn_cls: 0.008097  loss_rpn_loc: 0.02058  time: 1.8885  data_time: 0.2050  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:05:18 d2.utils.events]: \u001b[0m eta: 2:44:26  iter: 9779  total_loss: 0.4566  loss_cls: 0.2041  loss_box_reg: 0.2017  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.03206  time: 1.8885  data_time: 0.2058  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:05:55 d2.utils.events]: \u001b[0m eta: 2:43:48  iter: 9799  total_loss: 0.3591  loss_cls: 0.1656  loss_box_reg: 0.169  loss_rpn_cls: 0.009512  loss_rpn_loc: 0.01859  time: 1.8885  data_time: 0.2055  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:06:33 d2.utils.events]: \u001b[0m eta: 2:43:10  iter: 9819  total_loss: 0.4005  loss_cls: 0.1841  loss_box_reg: 0.1674  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.02987  time: 1.8885  data_time: 0.1995  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:07:11 d2.utils.events]: \u001b[0m eta: 2:42:32  iter: 9839  total_loss: 0.4201  loss_cls: 0.1985  loss_box_reg: 0.18  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.02309  time: 1.8885  data_time: 0.2047  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:07:49 d2.utils.events]: \u001b[0m eta: 2:41:54  iter: 9859  total_loss: 0.4216  loss_cls: 0.178  loss_box_reg: 0.1943  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.0265  time: 1.8885  data_time: 0.2045  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:08:27 d2.utils.events]: \u001b[0m eta: 2:41:16  iter: 9879  total_loss: 0.4502  loss_cls: 0.2091  loss_box_reg: 0.1981  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.03546  time: 1.8885  data_time: 0.2053  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:09:05 d2.utils.events]: \u001b[0m eta: 2:40:38  iter: 9899  total_loss: 0.4118  loss_cls: 0.1849  loss_box_reg: 0.1802  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.01813  time: 1.8885  data_time: 0.2068  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:09:43 d2.utils.events]: \u001b[0m eta: 2:40:01  iter: 9919  total_loss: 0.4172  loss_cls: 0.1756  loss_box_reg: 0.1803  loss_rpn_cls: 0.0107  loss_rpn_loc: 0.02237  time: 1.8886  data_time: 0.2053  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:10:21 d2.utils.events]: \u001b[0m eta: 2:39:23  iter: 9939  total_loss: 0.4235  loss_cls: 0.1959  loss_box_reg: 0.1855  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.02625  time: 1.8886  data_time: 0.2086  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:10:59 d2.utils.events]: \u001b[0m eta: 2:38:43  iter: 9959  total_loss: 0.449  loss_cls: 0.2215  loss_box_reg: 0.2023  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.03048  time: 1.8886  data_time: 0.2100  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:11:37 d2.utils.events]: \u001b[0m eta: 2:38:07  iter: 9979  total_loss: 0.4188  loss_cls: 0.1788  loss_box_reg: 0.1904  loss_rpn_cls: 0.009138  loss_rpn_loc: 0.02401  time: 1.8886  data_time: 0.2087  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:12:14 d2.utils.events]: \u001b[0m eta: 2:37:29  iter: 9999  total_loss: 0.3609  loss_cls: 0.1607  loss_box_reg: 0.1672  loss_rpn_cls: 0.009369  loss_rpn_loc: 0.0202  time: 1.8886  data_time: 0.2040  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:12:52 d2.utils.events]: \u001b[0m eta: 2:36:52  iter: 10019  total_loss: 0.3978  loss_cls: 0.1808  loss_box_reg: 0.1766  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.03192  time: 1.8886  data_time: 0.2077  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:13:30 d2.utils.events]: \u001b[0m eta: 2:36:13  iter: 10039  total_loss: 0.3848  loss_cls: 0.179  loss_box_reg: 0.1743  loss_rpn_cls: 0.00991  loss_rpn_loc: 0.02813  time: 1.8886  data_time: 0.2017  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:14:08 d2.utils.events]: \u001b[0m eta: 2:35:35  iter: 10059  total_loss: 0.4058  loss_cls: 0.1812  loss_box_reg: 0.1952  loss_rpn_cls: 0.008934  loss_rpn_loc: 0.02274  time: 1.8887  data_time: 0.2065  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:14:46 d2.utils.events]: \u001b[0m eta: 2:34:57  iter: 10079  total_loss: 0.4205  loss_cls: 0.197  loss_box_reg: 0.1913  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.02905  time: 1.8887  data_time: 0.2027  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:15:24 d2.utils.events]: \u001b[0m eta: 2:34:19  iter: 10099  total_loss: 0.3836  loss_cls: 0.1823  loss_box_reg: 0.1631  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.02372  time: 1.8887  data_time: 0.2049  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:16:02 d2.utils.events]: \u001b[0m eta: 2:33:41  iter: 10119  total_loss: 0.3631  loss_cls: 0.1764  loss_box_reg: 0.1674  loss_rpn_cls: 0.009684  loss_rpn_loc: 0.01932  time: 1.8887  data_time: 0.2022  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:16:39 d2.utils.events]: \u001b[0m eta: 2:33:04  iter: 10139  total_loss: 0.4148  loss_cls: 0.1954  loss_box_reg: 0.1828  loss_rpn_cls: 0.008773  loss_rpn_loc: 0.02277  time: 1.8887  data_time: 0.2027  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:17:17 d2.utils.events]: \u001b[0m eta: 2:32:25  iter: 10159  total_loss: 0.4364  loss_cls: 0.1861  loss_box_reg: 0.1852  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.03409  time: 1.8887  data_time: 0.2029  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:17:55 d2.utils.events]: \u001b[0m eta: 2:31:47  iter: 10179  total_loss: 0.3843  loss_cls: 0.1695  loss_box_reg: 0.1932  loss_rpn_cls: 0.009783  loss_rpn_loc: 0.02007  time: 1.8887  data_time: 0.2036  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:18:33 d2.utils.events]: \u001b[0m eta: 2:31:10  iter: 10199  total_loss: 0.4776  loss_cls: 0.2075  loss_box_reg: 0.2099  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.03628  time: 1.8887  data_time: 0.2067  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:19:11 d2.utils.events]: \u001b[0m eta: 2:30:33  iter: 10219  total_loss: 0.4298  loss_cls: 0.1998  loss_box_reg: 0.1854  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.0311  time: 1.8887  data_time: 0.2049  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:19:49 d2.utils.events]: \u001b[0m eta: 2:29:55  iter: 10239  total_loss: 0.4167  loss_cls: 0.1995  loss_box_reg: 0.1787  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.02461  time: 1.8887  data_time: 0.2050  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:20:26 d2.utils.events]: \u001b[0m eta: 2:29:16  iter: 10259  total_loss: 0.3698  loss_cls: 0.1804  loss_box_reg: 0.1643  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.01783  time: 1.8887  data_time: 0.2035  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:21:04 d2.utils.events]: \u001b[0m eta: 2:28:37  iter: 10279  total_loss: 0.4051  loss_cls: 0.1803  loss_box_reg: 0.1831  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.03381  time: 1.8887  data_time: 0.2072  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:21:42 d2.utils.events]: \u001b[0m eta: 2:27:59  iter: 10299  total_loss: 0.4338  loss_cls: 0.1951  loss_box_reg: 0.1928  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.03124  time: 1.8887  data_time: 0.1979  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:22:20 d2.utils.events]: \u001b[0m eta: 2:27:21  iter: 10319  total_loss: 0.4558  loss_cls: 0.1976  loss_box_reg: 0.1963  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.02666  time: 1.8887  data_time: 0.2032  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:22:58 d2.utils.events]: \u001b[0m eta: 2:26:43  iter: 10339  total_loss: 0.4068  loss_cls: 0.1937  loss_box_reg: 0.1749  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.02577  time: 1.8887  data_time: 0.2093  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:23:36 d2.utils.events]: \u001b[0m eta: 2:26:05  iter: 10359  total_loss: 0.4768  loss_cls: 0.2166  loss_box_reg: 0.2123  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.02873  time: 1.8887  data_time: 0.2044  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:24:14 d2.utils.events]: \u001b[0m eta: 2:25:27  iter: 10379  total_loss: 0.3835  loss_cls: 0.1616  loss_box_reg: 0.1852  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.02468  time: 1.8887  data_time: 0.2103  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:24:51 d2.utils.events]: \u001b[0m eta: 2:24:50  iter: 10399  total_loss: 0.4033  loss_cls: 0.1921  loss_box_reg: 0.185  loss_rpn_cls: 0.009865  loss_rpn_loc: 0.02548  time: 1.8887  data_time: 0.2073  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:25:29 d2.utils.events]: \u001b[0m eta: 2:24:12  iter: 10419  total_loss: 0.4188  loss_cls: 0.1744  loss_box_reg: 0.2058  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.02748  time: 1.8887  data_time: 0.1991  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:26:07 d2.utils.events]: \u001b[0m eta: 2:23:34  iter: 10439  total_loss: 0.402  loss_cls: 0.1867  loss_box_reg: 0.1767  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.02866  time: 1.8887  data_time: 0.2022  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:26:45 d2.utils.events]: \u001b[0m eta: 2:22:57  iter: 10459  total_loss: 0.3948  loss_cls: 0.1718  loss_box_reg: 0.185  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.02391  time: 1.8888  data_time: 0.2046  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:27:23 d2.utils.events]: \u001b[0m eta: 2:22:18  iter: 10479  total_loss: 0.4248  loss_cls: 0.197  loss_box_reg: 0.1943  loss_rpn_cls: 0.01155  loss_rpn_loc: 0.0303  time: 1.8888  data_time: 0.2034  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:28:01 d2.utils.events]: \u001b[0m eta: 2:21:39  iter: 10499  total_loss: 0.4192  loss_cls: 0.1832  loss_box_reg: 0.1791  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.02921  time: 1.8888  data_time: 0.2064  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:28:38 d2.utils.events]: \u001b[0m eta: 2:21:02  iter: 10519  total_loss: 0.4373  loss_cls: 0.1833  loss_box_reg: 0.1913  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.0246  time: 1.8888  data_time: 0.2078  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:29:16 d2.utils.events]: \u001b[0m eta: 2:20:24  iter: 10539  total_loss: 0.4374  loss_cls: 0.2043  loss_box_reg: 0.1908  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.02612  time: 1.8888  data_time: 0.2035  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:29:54 d2.utils.events]: \u001b[0m eta: 2:19:46  iter: 10559  total_loss: 0.3958  loss_cls: 0.1793  loss_box_reg: 0.1814  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.02543  time: 1.8888  data_time: 0.1966  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:30:32 d2.utils.events]: \u001b[0m eta: 2:19:07  iter: 10579  total_loss: 0.3975  loss_cls: 0.1764  loss_box_reg: 0.1745  loss_rpn_cls: 0.009129  loss_rpn_loc: 0.0247  time: 1.8888  data_time: 0.1996  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:31:10 d2.utils.events]: \u001b[0m eta: 2:18:30  iter: 10599  total_loss: 0.4316  loss_cls: 0.1977  loss_box_reg: 0.1957  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.02788  time: 1.8888  data_time: 0.2096  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:31:48 d2.utils.events]: \u001b[0m eta: 2:17:52  iter: 10619  total_loss: 0.3676  loss_cls: 0.1815  loss_box_reg: 0.1647  loss_rpn_cls: 0.009535  loss_rpn_loc: 0.02225  time: 1.8888  data_time: 0.2094  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:32:25 d2.utils.events]: \u001b[0m eta: 2:17:14  iter: 10639  total_loss: 0.3829  loss_cls: 0.1737  loss_box_reg: 0.1698  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.03121  time: 1.8888  data_time: 0.2041  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:33:03 d2.utils.events]: \u001b[0m eta: 2:16:36  iter: 10659  total_loss: 0.5068  loss_cls: 0.2217  loss_box_reg: 0.2127  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.03511  time: 1.8888  data_time: 0.2085  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:33:41 d2.utils.events]: \u001b[0m eta: 2:15:58  iter: 10679  total_loss: 0.4052  loss_cls: 0.1874  loss_box_reg: 0.1816  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.02454  time: 1.8888  data_time: 0.2061  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:34:19 d2.utils.events]: \u001b[0m eta: 2:15:21  iter: 10699  total_loss: 0.4286  loss_cls: 0.1881  loss_box_reg: 0.1991  loss_rpn_cls: 0.01018  loss_rpn_loc: 0.02151  time: 1.8888  data_time: 0.2018  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:34:57 d2.utils.events]: \u001b[0m eta: 2:14:44  iter: 10719  total_loss: 0.4154  loss_cls: 0.1847  loss_box_reg: 0.1792  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.02971  time: 1.8888  data_time: 0.2099  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:35:35 d2.utils.events]: \u001b[0m eta: 2:14:07  iter: 10739  total_loss: 0.4218  loss_cls: 0.1931  loss_box_reg: 0.1787  loss_rpn_cls: 0.01057  loss_rpn_loc: 0.02768  time: 1.8888  data_time: 0.2115  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:36:13 d2.utils.events]: \u001b[0m eta: 2:13:28  iter: 10759  total_loss: 0.4836  loss_cls: 0.2099  loss_box_reg: 0.2182  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.03729  time: 1.8888  data_time: 0.2035  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:36:51 d2.utils.events]: \u001b[0m eta: 2:12:51  iter: 10779  total_loss: 0.3772  loss_cls: 0.163  loss_box_reg: 0.1758  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.02211  time: 1.8889  data_time: 0.2078  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:37:28 d2.utils.events]: \u001b[0m eta: 2:12:13  iter: 10799  total_loss: 0.4426  loss_cls: 0.1852  loss_box_reg: 0.1931  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.02572  time: 1.8889  data_time: 0.1997  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:38:06 d2.utils.events]: \u001b[0m eta: 2:11:35  iter: 10819  total_loss: 0.3991  loss_cls: 0.1792  loss_box_reg: 0.188  loss_rpn_cls: 0.009001  loss_rpn_loc: 0.02315  time: 1.8889  data_time: 0.2051  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:38:44 d2.utils.events]: \u001b[0m eta: 2:10:57  iter: 10839  total_loss: 0.4038  loss_cls: 0.1797  loss_box_reg: 0.1841  loss_rpn_cls: 0.01024  loss_rpn_loc: 0.02179  time: 1.8889  data_time: 0.2054  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:39:22 d2.utils.events]: \u001b[0m eta: 2:10:19  iter: 10859  total_loss: 0.4385  loss_cls: 0.1934  loss_box_reg: 0.1972  loss_rpn_cls: 0.01072  loss_rpn_loc: 0.02759  time: 1.8889  data_time: 0.2029  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:40:00 d2.utils.events]: \u001b[0m eta: 2:09:42  iter: 10879  total_loss: 0.4377  loss_cls: 0.2103  loss_box_reg: 0.1933  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.02985  time: 1.8889  data_time: 0.2016  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:40:38 d2.utils.events]: \u001b[0m eta: 2:09:04  iter: 10899  total_loss: 0.4069  loss_cls: 0.1842  loss_box_reg: 0.1802  loss_rpn_cls: 0.009711  loss_rpn_loc: 0.02509  time: 1.8889  data_time: 0.2029  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:41:16 d2.utils.events]: \u001b[0m eta: 2:08:26  iter: 10919  total_loss: 0.4058  loss_cls: 0.1828  loss_box_reg: 0.1862  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.0212  time: 1.8889  data_time: 0.2089  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:42:02 d2.utils.events]: \u001b[0m eta: 2:07:49  iter: 10939  total_loss: 0.4323  loss_cls: 0.1922  loss_box_reg: 0.1997  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.02759  time: 1.8897  data_time: 0.2106  lr: 5e-06  max_mem: 24877M\n",
      "\u001b[32m[01/08 21:42:58 d2.utils.events]: \u001b[0m eta: 2:07:12  iter: 10959  total_loss: 0.3918  loss_cls: 0.1785  loss_box_reg: 0.1719  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.02451  time: 1.8914  data_time: 0.2279  lr: 5e-06  max_mem: 24877M\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
