{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build\n",
      "running build_py\n",
      "running build_ext\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:411: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "running develop\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running egg_info\n",
      "writing manifest file 'detectron2.egg-info/SOURCES.txt'\n",
      "running build_ext\n"
     ]
    }
   ],
   "source": [
    "# Run only on the first execution\n",
    "!python setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_train', {}, '../../../dataset/train.json', '../../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '../../../dataset/test.json', '../../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 0\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml')\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.0001\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (8000,12000)\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 3000\n",
    "\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 12\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "import detectron2.data.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3),\n",
    "        T.Resize(1024)\n",
    "        # A.Resize(1024, 1024),\n",
    "        # ToTensorV2(p=0.1)\n",
    "\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/05 16:30:51 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=13, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=48, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/05 16:30:52 d2.data.datasets.coco]: \u001b[0mLoaded 4883 images in COCO format from ../../../dataset/train.json\n",
      "\u001b[32m[01/05 16:30:52 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4883 images left.\n",
      "\u001b[32m[01/05 16:30:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/05 16:30:52 d2.data.common]: \u001b[0mSerializing 4883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/05 16:30:52 d2.data.common]: \u001b[0mSerialized dataset takes 2.20 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (13, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (48, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (48,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/05 16:30:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/boxes.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = torch.as_tensor(tensor, dtype=torch.float32, device=device)\n",
      "/data/ephemeral/home/level2-objectdetection-cv-10/develop/StringZero/detectron2/detectron2/structures/image_list.py:99: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/05 16:31:33 d2.utils.events]: \u001b[0m eta: 7:55:19  iter: 19  total_loss: 3.436  loss_cls: 2.6  loss_box_reg: 0.6815  loss_rpn_cls: 0.1235  loss_rpn_loc: 0.04505  time: 1.9134  data_time: 0.2448  lr: 1.9981e-06  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:32:11 d2.utils.events]: \u001b[0m eta: 7:56:21  iter: 39  total_loss: 3.405  loss_cls: 2.554  loss_box_reg: 0.696  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.03898  time: 1.9129  data_time: 0.2273  lr: 3.9961e-06  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:32:49 d2.utils.events]: \u001b[0m eta: 7:54:27  iter: 59  total_loss: 3.296  loss_cls: 2.446  loss_box_reg: 0.6892  loss_rpn_cls: 0.1127  loss_rpn_loc: 0.03907  time: 1.9101  data_time: 0.2227  lr: 5.9941e-06  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:33:28 d2.utils.events]: \u001b[0m eta: 7:54:14  iter: 79  total_loss: 3.128  loss_cls: 2.285  loss_box_reg: 0.6832  loss_rpn_cls: 0.09384  loss_rpn_loc: 0.03813  time: 1.9112  data_time: 0.2263  lr: 7.9921e-06  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:34:06 d2.utils.events]: \u001b[0m eta: 7:54:14  iter: 99  total_loss: 2.91  loss_cls: 2.105  loss_box_reg: 0.6726  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.04608  time: 1.9122  data_time: 0.2283  lr: 9.9901e-06  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:34:44 d2.utils.events]: \u001b[0m eta: 7:53:49  iter: 119  total_loss: 2.644  loss_cls: 1.843  loss_box_reg: 0.7007  loss_rpn_cls: 0.06212  loss_rpn_loc: 0.04024  time: 1.9130  data_time: 0.2269  lr: 1.1988e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:35:23 d2.utils.events]: \u001b[0m eta: 7:53:17  iter: 139  total_loss: 2.461  loss_cls: 1.603  loss_box_reg: 0.6877  loss_rpn_cls: 0.1292  loss_rpn_loc: 0.0407  time: 1.9139  data_time: 0.2340  lr: 1.3986e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:36:01 d2.utils.events]: \u001b[0m eta: 7:52:42  iter: 159  total_loss: 2.158  loss_cls: 1.313  loss_box_reg: 0.708  loss_rpn_cls: 0.09045  loss_rpn_loc: 0.04887  time: 1.9139  data_time: 0.2259  lr: 1.5984e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:36:39 d2.utils.events]: \u001b[0m eta: 7:52:05  iter: 179  total_loss: 1.962  loss_cls: 1.104  loss_box_reg: 0.6934  loss_rpn_cls: 0.1297  loss_rpn_loc: 0.03504  time: 1.9143  data_time: 0.2321  lr: 1.7982e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:37:18 d2.utils.events]: \u001b[0m eta: 7:51:35  iter: 199  total_loss: 1.829  loss_cls: 0.9389  loss_box_reg: 0.708  loss_rpn_cls: 0.13  loss_rpn_loc: 0.04052  time: 1.9158  data_time: 0.2374  lr: 1.998e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:37:56 d2.utils.events]: \u001b[0m eta: 7:50:59  iter: 219  total_loss: 1.664  loss_cls: 0.8423  loss_box_reg: 0.7012  loss_rpn_cls: 0.08168  loss_rpn_loc: 0.03116  time: 1.9162  data_time: 0.2313  lr: 2.1978e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:38:35 d2.utils.events]: \u001b[0m eta: 7:50:24  iter: 239  total_loss: 1.625  loss_cls: 0.7738  loss_box_reg: 0.6626  loss_rpn_cls: 0.1355  loss_rpn_loc: 0.0404  time: 1.9164  data_time: 0.2316  lr: 2.3976e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:39:13 d2.utils.events]: \u001b[0m eta: 7:49:55  iter: 259  total_loss: 1.754  loss_cls: 0.807  loss_box_reg: 0.7095  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.04812  time: 1.9166  data_time: 0.2293  lr: 2.5974e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:39:51 d2.utils.events]: \u001b[0m eta: 7:49:10  iter: 279  total_loss: 1.598  loss_cls: 0.7572  loss_box_reg: 0.6874  loss_rpn_cls: 0.09667  loss_rpn_loc: 0.03649  time: 1.9163  data_time: 0.2262  lr: 2.7972e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:40:30 d2.utils.events]: \u001b[0m eta: 7:48:40  iter: 299  total_loss: 1.608  loss_cls: 0.7602  loss_box_reg: 0.7163  loss_rpn_cls: 0.09781  loss_rpn_loc: 0.04543  time: 1.9164  data_time: 0.2326  lr: 2.997e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:41:08 d2.utils.events]: \u001b[0m eta: 7:48:00  iter: 319  total_loss: 1.614  loss_cls: 0.7675  loss_box_reg: 0.7146  loss_rpn_cls: 0.07094  loss_rpn_loc: 0.03989  time: 1.9163  data_time: 0.2267  lr: 3.1968e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:41:46 d2.utils.events]: \u001b[0m eta: 7:47:21  iter: 339  total_loss: 1.62  loss_cls: 0.7435  loss_box_reg: 0.7119  loss_rpn_cls: 0.09186  loss_rpn_loc: 0.04471  time: 1.9163  data_time: 0.2280  lr: 3.3966e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:42:25 d2.utils.events]: \u001b[0m eta: 7:46:37  iter: 359  total_loss: 1.576  loss_cls: 0.7484  loss_box_reg: 0.718  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.04579  time: 1.9160  data_time: 0.2253  lr: 3.5964e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:43:03 d2.utils.events]: \u001b[0m eta: 7:45:51  iter: 379  total_loss: 1.541  loss_cls: 0.7213  loss_box_reg: 0.7062  loss_rpn_cls: 0.07453  loss_rpn_loc: 0.04349  time: 1.9157  data_time: 0.2250  lr: 3.7962e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:43:41 d2.utils.events]: \u001b[0m eta: 7:45:14  iter: 399  total_loss: 1.529  loss_cls: 0.7283  loss_box_reg: 0.7288  loss_rpn_cls: 0.06026  loss_rpn_loc: 0.03697  time: 1.9159  data_time: 0.2331  lr: 3.996e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:44:20 d2.utils.events]: \u001b[0m eta: 7:44:39  iter: 419  total_loss: 1.563  loss_cls: 0.7346  loss_box_reg: 0.7361  loss_rpn_cls: 0.06432  loss_rpn_loc: 0.03097  time: 1.9160  data_time: 0.2310  lr: 4.1958e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:44:58 d2.utils.events]: \u001b[0m eta: 7:43:59  iter: 439  total_loss: 1.511  loss_cls: 0.7096  loss_box_reg: 0.699  loss_rpn_cls: 0.05126  loss_rpn_loc: 0.0416  time: 1.9159  data_time: 0.2267  lr: 4.3956e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:45:36 d2.utils.events]: \u001b[0m eta: 7:43:20  iter: 459  total_loss: 1.541  loss_cls: 0.6783  loss_box_reg: 0.6947  loss_rpn_cls: 0.05482  loss_rpn_loc: 0.03775  time: 1.9158  data_time: 0.2278  lr: 4.5954e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:46:14 d2.utils.events]: \u001b[0m eta: 7:42:40  iter: 479  total_loss: 1.548  loss_cls: 0.7063  loss_box_reg: 0.7213  loss_rpn_cls: 0.04584  loss_rpn_loc: 0.03687  time: 1.9157  data_time: 0.2278  lr: 4.7952e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:46:53 d2.utils.events]: \u001b[0m eta: 7:42:00  iter: 499  total_loss: 1.453  loss_cls: 0.6849  loss_box_reg: 0.6768  loss_rpn_cls: 0.05057  loss_rpn_loc: 0.03343  time: 1.9155  data_time: 0.2270  lr: 4.995e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:47:31 d2.utils.events]: \u001b[0m eta: 7:41:24  iter: 519  total_loss: 1.465  loss_cls: 0.6654  loss_box_reg: 0.6881  loss_rpn_cls: 0.04446  loss_rpn_loc: 0.03655  time: 1.9157  data_time: 0.2272  lr: 5.1948e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:48:10 d2.utils.events]: \u001b[0m eta: 7:40:48  iter: 539  total_loss: 1.465  loss_cls: 0.659  loss_box_reg: 0.6996  loss_rpn_cls: 0.03891  loss_rpn_loc: 0.03234  time: 1.9159  data_time: 0.2340  lr: 5.3946e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:48:48 d2.utils.events]: \u001b[0m eta: 7:40:10  iter: 559  total_loss: 1.472  loss_cls: 0.68  loss_box_reg: 0.6904  loss_rpn_cls: 0.0419  loss_rpn_loc: 0.03604  time: 1.9158  data_time: 0.2270  lr: 5.5944e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:49:26 d2.utils.events]: \u001b[0m eta: 7:39:30  iter: 579  total_loss: 1.431  loss_cls: 0.6327  loss_box_reg: 0.6825  loss_rpn_cls: 0.03402  loss_rpn_loc: 0.03645  time: 1.9157  data_time: 0.2246  lr: 5.7942e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:50:05 d2.utils.events]: \u001b[0m eta: 7:38:51  iter: 599  total_loss: 1.434  loss_cls: 0.6242  loss_box_reg: 0.668  loss_rpn_cls: 0.04028  loss_rpn_loc: 0.04062  time: 1.9159  data_time: 0.2334  lr: 5.994e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:50:43 d2.utils.events]: \u001b[0m eta: 7:38:14  iter: 619  total_loss: 1.473  loss_cls: 0.6512  loss_box_reg: 0.6979  loss_rpn_cls: 0.04266  loss_rpn_loc: 0.03104  time: 1.9158  data_time: 0.2281  lr: 6.1938e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:51:21 d2.utils.events]: \u001b[0m eta: 7:37:35  iter: 639  total_loss: 1.449  loss_cls: 0.6463  loss_box_reg: 0.6793  loss_rpn_cls: 0.05431  loss_rpn_loc: 0.03709  time: 1.9157  data_time: 0.2285  lr: 6.3936e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:52:00 d2.utils.events]: \u001b[0m eta: 7:37:02  iter: 659  total_loss: 1.414  loss_cls: 0.6391  loss_box_reg: 0.6871  loss_rpn_cls: 0.03871  loss_rpn_loc: 0.03642  time: 1.9160  data_time: 0.2329  lr: 6.5934e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:52:38 d2.utils.events]: \u001b[0m eta: 7:36:21  iter: 679  total_loss: 1.407  loss_cls: 0.6296  loss_box_reg: 0.6911  loss_rpn_cls: 0.03166  loss_rpn_loc: 0.03559  time: 1.9160  data_time: 0.2309  lr: 6.7932e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:53:16 d2.utils.events]: \u001b[0m eta: 7:35:42  iter: 699  total_loss: 1.31  loss_cls: 0.587  loss_box_reg: 0.6352  loss_rpn_cls: 0.04301  loss_rpn_loc: 0.03411  time: 1.9161  data_time: 0.2343  lr: 6.993e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:53:55 d2.utils.events]: \u001b[0m eta: 7:35:02  iter: 719  total_loss: 1.339  loss_cls: 0.6058  loss_box_reg: 0.6589  loss_rpn_cls: 0.04083  loss_rpn_loc: 0.03027  time: 1.9158  data_time: 0.2231  lr: 7.1928e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:54:33 d2.utils.events]: \u001b[0m eta: 7:34:23  iter: 739  total_loss: 1.418  loss_cls: 0.6207  loss_box_reg: 0.7018  loss_rpn_cls: 0.04381  loss_rpn_loc: 0.04341  time: 1.9158  data_time: 0.2282  lr: 7.3926e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:55:11 d2.utils.events]: \u001b[0m eta: 7:33:45  iter: 759  total_loss: 1.373  loss_cls: 0.6075  loss_box_reg: 0.6832  loss_rpn_cls: 0.03927  loss_rpn_loc: 0.05085  time: 1.9157  data_time: 0.2279  lr: 7.5924e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:55:49 d2.utils.events]: \u001b[0m eta: 7:33:04  iter: 779  total_loss: 1.324  loss_cls: 0.5859  loss_box_reg: 0.6522  loss_rpn_cls: 0.03964  loss_rpn_loc: 0.03714  time: 1.9156  data_time: 0.2245  lr: 7.7922e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:56:28 d2.utils.events]: \u001b[0m eta: 7:32:26  iter: 799  total_loss: 1.393  loss_cls: 0.6305  loss_box_reg: 0.6718  loss_rpn_cls: 0.04293  loss_rpn_loc: 0.03926  time: 1.9156  data_time: 0.2322  lr: 7.992e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:57:06 d2.utils.events]: \u001b[0m eta: 7:31:48  iter: 819  total_loss: 1.305  loss_cls: 0.603  loss_box_reg: 0.6271  loss_rpn_cls: 0.0409  loss_rpn_loc: 0.03232  time: 1.9155  data_time: 0.2290  lr: 8.1918e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:57:45 d2.utils.events]: \u001b[0m eta: 7:31:11  iter: 839  total_loss: 1.308  loss_cls: 0.5947  loss_box_reg: 0.6365  loss_rpn_cls: 0.03239  loss_rpn_loc: 0.03269  time: 1.9160  data_time: 0.2398  lr: 8.3916e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:58:23 d2.utils.events]: \u001b[0m eta: 7:30:33  iter: 859  total_loss: 1.3  loss_cls: 0.5768  loss_box_reg: 0.6394  loss_rpn_cls: 0.03189  loss_rpn_loc: 0.03765  time: 1.9160  data_time: 0.2312  lr: 8.5914e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:59:01 d2.utils.events]: \u001b[0m eta: 7:29:53  iter: 879  total_loss: 1.288  loss_cls: 0.5731  loss_box_reg: 0.613  loss_rpn_cls: 0.03636  loss_rpn_loc: 0.03654  time: 1.9158  data_time: 0.2281  lr: 8.7912e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 16:59:40 d2.utils.events]: \u001b[0m eta: 7:29:15  iter: 899  total_loss: 1.303  loss_cls: 0.585  loss_box_reg: 0.6239  loss_rpn_cls: 0.04084  loss_rpn_loc: 0.02977  time: 1.9158  data_time: 0.2275  lr: 8.991e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:00:18 d2.utils.events]: \u001b[0m eta: 7:28:38  iter: 919  total_loss: 1.282  loss_cls: 0.5843  loss_box_reg: 0.6144  loss_rpn_cls: 0.03933  loss_rpn_loc: 0.0403  time: 1.9160  data_time: 0.2365  lr: 9.1908e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:00:56 d2.utils.events]: \u001b[0m eta: 7:27:59  iter: 939  total_loss: 1.281  loss_cls: 0.6014  loss_box_reg: 0.6122  loss_rpn_cls: 0.03919  loss_rpn_loc: 0.04104  time: 1.9160  data_time: 0.2282  lr: 9.3906e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:01:35 d2.utils.events]: \u001b[0m eta: 7:27:21  iter: 959  total_loss: 1.269  loss_cls: 0.5802  loss_box_reg: 0.5927  loss_rpn_cls: 0.03476  loss_rpn_loc: 0.04801  time: 1.9160  data_time: 0.2296  lr: 9.5904e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:02:13 d2.utils.events]: \u001b[0m eta: 7:26:42  iter: 979  total_loss: 1.242  loss_cls: 0.58  loss_box_reg: 0.5774  loss_rpn_cls: 0.03157  loss_rpn_loc: 0.03508  time: 1.9159  data_time: 0.2270  lr: 9.7902e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:02:51 d2.utils.events]: \u001b[0m eta: 7:26:04  iter: 999  total_loss: 1.21  loss_cls: 0.5658  loss_box_reg: 0.5577  loss_rpn_cls: 0.03564  loss_rpn_loc: 0.04284  time: 1.9159  data_time: 0.2348  lr: 9.99e-05  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:03:30 d2.utils.events]: \u001b[0m eta: 7:25:26  iter: 1019  total_loss: 1.169  loss_cls: 0.5361  loss_box_reg: 0.5393  loss_rpn_cls: 0.03724  loss_rpn_loc: 0.03767  time: 1.9160  data_time: 0.2323  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:04:08 d2.utils.events]: \u001b[0m eta: 7:24:46  iter: 1039  total_loss: 1.098  loss_cls: 0.5267  loss_box_reg: 0.5152  loss_rpn_cls: 0.03451  loss_rpn_loc: 0.04019  time: 1.9158  data_time: 0.2259  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:04:46 d2.utils.events]: \u001b[0m eta: 7:24:09  iter: 1059  total_loss: 1.155  loss_cls: 0.5605  loss_box_reg: 0.4831  loss_rpn_cls: 0.02889  loss_rpn_loc: 0.03712  time: 1.9158  data_time: 0.2285  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:05:25 d2.utils.events]: \u001b[0m eta: 7:23:31  iter: 1079  total_loss: 1.046  loss_cls: 0.5317  loss_box_reg: 0.4679  loss_rpn_cls: 0.03539  loss_rpn_loc: 0.03239  time: 1.9159  data_time: 0.2310  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:06:03 d2.utils.events]: \u001b[0m eta: 7:22:52  iter: 1099  total_loss: 1.097  loss_cls: 0.5478  loss_box_reg: 0.4814  loss_rpn_cls: 0.03516  loss_rpn_loc: 0.0335  time: 1.9158  data_time: 0.2278  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:06:41 d2.utils.events]: \u001b[0m eta: 7:22:13  iter: 1119  total_loss: 1.121  loss_cls: 0.5378  loss_box_reg: 0.4792  loss_rpn_cls: 0.05005  loss_rpn_loc: 0.04066  time: 1.9158  data_time: 0.2256  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:07:20 d2.utils.events]: \u001b[0m eta: 7:21:34  iter: 1139  total_loss: 1.078  loss_cls: 0.5476  loss_box_reg: 0.4662  loss_rpn_cls: 0.03467  loss_rpn_loc: 0.04482  time: 1.9158  data_time: 0.2299  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:07:58 d2.utils.events]: \u001b[0m eta: 7:20:55  iter: 1159  total_loss: 1.079  loss_cls: 0.5357  loss_box_reg: 0.4352  loss_rpn_cls: 0.04431  loss_rpn_loc: 0.04687  time: 1.9158  data_time: 0.2305  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:08:36 d2.utils.events]: \u001b[0m eta: 7:20:17  iter: 1179  total_loss: 1.005  loss_cls: 0.51  loss_box_reg: 0.4241  loss_rpn_cls: 0.03659  loss_rpn_loc: 0.0421  time: 1.9158  data_time: 0.2312  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:09:15 d2.utils.events]: \u001b[0m eta: 7:19:38  iter: 1199  total_loss: 1.039  loss_cls: 0.5328  loss_box_reg: 0.4264  loss_rpn_cls: 0.03325  loss_rpn_loc: 0.0344  time: 1.9159  data_time: 0.2352  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:09:53 d2.utils.events]: \u001b[0m eta: 7:18:59  iter: 1219  total_loss: 1.056  loss_cls: 0.5151  loss_box_reg: 0.4205  loss_rpn_cls: 0.04741  loss_rpn_loc: 0.03973  time: 1.9159  data_time: 0.2273  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:10:31 d2.utils.events]: \u001b[0m eta: 7:18:19  iter: 1239  total_loss: 1.023  loss_cls: 0.5132  loss_box_reg: 0.4193  loss_rpn_cls: 0.03776  loss_rpn_loc: 0.03975  time: 1.9158  data_time: 0.2282  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:11:10 d2.utils.events]: \u001b[0m eta: 7:17:39  iter: 1259  total_loss: 1.004  loss_cls: 0.5067  loss_box_reg: 0.4128  loss_rpn_cls: 0.03686  loss_rpn_loc: 0.03716  time: 1.9158  data_time: 0.2324  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:11:48 d2.utils.events]: \u001b[0m eta: 7:17:00  iter: 1279  total_loss: 0.9868  loss_cls: 0.5077  loss_box_reg: 0.4  loss_rpn_cls: 0.03429  loss_rpn_loc: 0.03402  time: 1.9158  data_time: 0.2297  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:12:26 d2.utils.events]: \u001b[0m eta: 7:16:19  iter: 1299  total_loss: 0.9683  loss_cls: 0.4996  loss_box_reg: 0.3826  loss_rpn_cls: 0.04044  loss_rpn_loc: 0.03661  time: 1.9157  data_time: 0.2294  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:13:04 d2.utils.events]: \u001b[0m eta: 7:15:39  iter: 1319  total_loss: 0.9591  loss_cls: 0.4887  loss_box_reg: 0.3972  loss_rpn_cls: 0.03479  loss_rpn_loc: 0.02732  time: 1.9156  data_time: 0.2274  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:13:43 d2.utils.events]: \u001b[0m eta: 7:14:59  iter: 1339  total_loss: 0.9488  loss_cls: 0.4977  loss_box_reg: 0.3831  loss_rpn_cls: 0.03025  loss_rpn_loc: 0.02909  time: 1.9156  data_time: 0.2282  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:14:21 d2.utils.events]: \u001b[0m eta: 7:14:24  iter: 1359  total_loss: 1.01  loss_cls: 0.5139  loss_box_reg: 0.4244  loss_rpn_cls: 0.04227  loss_rpn_loc: 0.04013  time: 1.9156  data_time: 0.2306  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:14:59 d2.utils.events]: \u001b[0m eta: 7:13:47  iter: 1379  total_loss: 0.9717  loss_cls: 0.4975  loss_box_reg: 0.3751  loss_rpn_cls: 0.03528  loss_rpn_loc: 0.04332  time: 1.9156  data_time: 0.2303  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:15:38 d2.utils.events]: \u001b[0m eta: 7:13:08  iter: 1399  total_loss: 0.9783  loss_cls: 0.5015  loss_box_reg: 0.4075  loss_rpn_cls: 0.03597  loss_rpn_loc: 0.03236  time: 1.9155  data_time: 0.2263  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:16:16 d2.utils.events]: \u001b[0m eta: 7:12:29  iter: 1419  total_loss: 0.8865  loss_cls: 0.4728  loss_box_reg: 0.3721  loss_rpn_cls: 0.03492  loss_rpn_loc: 0.03937  time: 1.9155  data_time: 0.2261  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:16:54 d2.utils.events]: \u001b[0m eta: 7:11:49  iter: 1439  total_loss: 0.9645  loss_cls: 0.4967  loss_box_reg: 0.3887  loss_rpn_cls: 0.03438  loss_rpn_loc: 0.03566  time: 1.9154  data_time: 0.2264  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:17:32 d2.utils.events]: \u001b[0m eta: 7:11:11  iter: 1459  total_loss: 0.986  loss_cls: 0.5256  loss_box_reg: 0.3807  loss_rpn_cls: 0.02897  loss_rpn_loc: 0.04332  time: 1.9155  data_time: 0.2305  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:18:11 d2.utils.events]: \u001b[0m eta: 7:10:34  iter: 1479  total_loss: 0.9077  loss_cls: 0.4973  loss_box_reg: 0.3716  loss_rpn_cls: 0.02798  loss_rpn_loc: 0.02823  time: 1.9155  data_time: 0.2328  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:18:49 d2.utils.events]: \u001b[0m eta: 7:09:57  iter: 1499  total_loss: 0.983  loss_cls: 0.5076  loss_box_reg: 0.3816  loss_rpn_cls: 0.04129  loss_rpn_loc: 0.0548  time: 1.9156  data_time: 0.2334  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:19:28 d2.utils.events]: \u001b[0m eta: 7:09:19  iter: 1519  total_loss: 0.9747  loss_cls: 0.5109  loss_box_reg: 0.3831  loss_rpn_cls: 0.03476  loss_rpn_loc: 0.04111  time: 1.9157  data_time: 0.2346  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:20:06 d2.utils.events]: \u001b[0m eta: 7:08:38  iter: 1539  total_loss: 0.8799  loss_cls: 0.4611  loss_box_reg: 0.3389  loss_rpn_cls: 0.03637  loss_rpn_loc: 0.02938  time: 1.9156  data_time: 0.2250  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:20:44 d2.utils.events]: \u001b[0m eta: 7:08:01  iter: 1559  total_loss: 0.9102  loss_cls: 0.4844  loss_box_reg: 0.3441  loss_rpn_cls: 0.03818  loss_rpn_loc: 0.03558  time: 1.9156  data_time: 0.2286  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:21:23 d2.utils.events]: \u001b[0m eta: 7:07:24  iter: 1579  total_loss: 0.9539  loss_cls: 0.5117  loss_box_reg: 0.3908  loss_rpn_cls: 0.04727  loss_rpn_loc: 0.05094  time: 1.9157  data_time: 0.2398  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:22:01 d2.utils.events]: \u001b[0m eta: 7:06:45  iter: 1599  total_loss: 0.9564  loss_cls: 0.4874  loss_box_reg: 0.3704  loss_rpn_cls: 0.02987  loss_rpn_loc: 0.03822  time: 1.9157  data_time: 0.2304  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:22:39 d2.utils.events]: \u001b[0m eta: 7:06:08  iter: 1619  total_loss: 0.8777  loss_cls: 0.4661  loss_box_reg: 0.3356  loss_rpn_cls: 0.0293  loss_rpn_loc: 0.02751  time: 1.9158  data_time: 0.2342  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:23:18 d2.utils.events]: \u001b[0m eta: 7:05:31  iter: 1639  total_loss: 0.8548  loss_cls: 0.4452  loss_box_reg: 0.3337  loss_rpn_cls: 0.03942  loss_rpn_loc: 0.04353  time: 1.9158  data_time: 0.2346  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:23:56 d2.utils.events]: \u001b[0m eta: 7:04:51  iter: 1659  total_loss: 0.9154  loss_cls: 0.4917  loss_box_reg: 0.3497  loss_rpn_cls: 0.03565  loss_rpn_loc: 0.03289  time: 1.9158  data_time: 0.2316  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:24:35 d2.utils.events]: \u001b[0m eta: 7:04:13  iter: 1679  total_loss: 0.9113  loss_cls: 0.4781  loss_box_reg: 0.3434  loss_rpn_cls: 0.03422  loss_rpn_loc: 0.04115  time: 1.9158  data_time: 0.2285  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:25:13 d2.utils.events]: \u001b[0m eta: 7:03:35  iter: 1699  total_loss: 0.9009  loss_cls: 0.4728  loss_box_reg: 0.3522  loss_rpn_cls: 0.03025  loss_rpn_loc: 0.04057  time: 1.9159  data_time: 0.2361  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:25:52 d2.utils.events]: \u001b[0m eta: 7:02:59  iter: 1719  total_loss: 0.918  loss_cls: 0.4953  loss_box_reg: 0.3607  loss_rpn_cls: 0.03277  loss_rpn_loc: 0.03184  time: 1.9160  data_time: 0.2331  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:26:30 d2.utils.events]: \u001b[0m eta: 7:02:23  iter: 1739  total_loss: 0.9177  loss_cls: 0.4862  loss_box_reg: 0.3473  loss_rpn_cls: 0.02957  loss_rpn_loc: 0.03586  time: 1.9160  data_time: 0.2313  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:27:08 d2.utils.events]: \u001b[0m eta: 7:01:44  iter: 1759  total_loss: 0.8968  loss_cls: 0.4926  loss_box_reg: 0.3498  loss_rpn_cls: 0.03467  loss_rpn_loc: 0.03478  time: 1.9159  data_time: 0.2254  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:27:47 d2.utils.events]: \u001b[0m eta: 7:01:09  iter: 1779  total_loss: 0.8815  loss_cls: 0.4717  loss_box_reg: 0.3369  loss_rpn_cls: 0.03119  loss_rpn_loc: 0.03694  time: 1.9162  data_time: 0.2401  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:28:25 d2.utils.events]: \u001b[0m eta: 7:00:30  iter: 1799  total_loss: 0.8525  loss_cls: 0.4743  loss_box_reg: 0.3128  loss_rpn_cls: 0.03371  loss_rpn_loc: 0.03466  time: 1.9161  data_time: 0.2256  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:29:04 d2.utils.events]: \u001b[0m eta: 6:59:54  iter: 1819  total_loss: 0.9364  loss_cls: 0.4924  loss_box_reg: 0.3398  loss_rpn_cls: 0.03366  loss_rpn_loc: 0.04144  time: 1.9162  data_time: 0.2341  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:29:42 d2.utils.events]: \u001b[0m eta: 6:59:15  iter: 1839  total_loss: 0.8202  loss_cls: 0.4507  loss_box_reg: 0.3267  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.0312  time: 1.9162  data_time: 0.2285  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:30:20 d2.utils.events]: \u001b[0m eta: 6:58:38  iter: 1859  total_loss: 0.9156  loss_cls: 0.4873  loss_box_reg: 0.3497  loss_rpn_cls: 0.02784  loss_rpn_loc: 0.03231  time: 1.9162  data_time: 0.2334  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:30:59 d2.utils.events]: \u001b[0m eta: 6:58:01  iter: 1879  total_loss: 0.9546  loss_cls: 0.4976  loss_box_reg: 0.3475  loss_rpn_cls: 0.03455  loss_rpn_loc: 0.03589  time: 1.9162  data_time: 0.2312  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:31:37 d2.utils.events]: \u001b[0m eta: 6:57:23  iter: 1899  total_loss: 0.8871  loss_cls: 0.4593  loss_box_reg: 0.3425  loss_rpn_cls: 0.03145  loss_rpn_loc: 0.04151  time: 1.9163  data_time: 0.2310  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:32:15 d2.utils.events]: \u001b[0m eta: 6:56:44  iter: 1919  total_loss: 0.8494  loss_cls: 0.4587  loss_box_reg: 0.3353  loss_rpn_cls: 0.03244  loss_rpn_loc: 0.03539  time: 1.9162  data_time: 0.2273  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:32:54 d2.utils.events]: \u001b[0m eta: 6:56:05  iter: 1939  total_loss: 0.9005  loss_cls: 0.4803  loss_box_reg: 0.3605  loss_rpn_cls: 0.02909  loss_rpn_loc: 0.03942  time: 1.9162  data_time: 0.2272  lr: 0.0001  max_mem: 24885M\n",
      "\u001b[32m[01/05 17:33:32 d2.utils.events]: \u001b[0m eta: 6:55:26  iter: 1959  total_loss: 0.8609  loss_cls: 0.4491  loss_box_reg: 0.322  loss_rpn_cls: 0.03163  loss_rpn_loc: 0.03884  time: 1.9161  data_time: 0.2258  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:34:10 d2.utils.events]: \u001b[0m eta: 6:54:49  iter: 1979  total_loss: 0.8766  loss_cls: 0.4864  loss_box_reg: 0.31  loss_rpn_cls: 0.03187  loss_rpn_loc: 0.05007  time: 1.9161  data_time: 0.2306  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:34:49 d2.utils.events]: \u001b[0m eta: 6:54:11  iter: 1999  total_loss: 0.85  loss_cls: 0.4618  loss_box_reg: 0.3087  loss_rpn_cls: 0.0313  loss_rpn_loc: 0.03497  time: 1.9162  data_time: 0.2348  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:35:27 d2.utils.events]: \u001b[0m eta: 6:53:31  iter: 2019  total_loss: 0.8724  loss_cls: 0.4867  loss_box_reg: 0.3254  loss_rpn_cls: 0.03528  loss_rpn_loc: 0.03093  time: 1.9161  data_time: 0.2247  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:36:05 d2.utils.events]: \u001b[0m eta: 6:52:56  iter: 2039  total_loss: 0.8791  loss_cls: 0.4638  loss_box_reg: 0.3534  loss_rpn_cls: 0.03945  loss_rpn_loc: 0.03963  time: 1.9161  data_time: 0.2341  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:36:44 d2.utils.events]: \u001b[0m eta: 6:52:18  iter: 2059  total_loss: 0.8338  loss_cls: 0.4465  loss_box_reg: 0.3347  loss_rpn_cls: 0.03549  loss_rpn_loc: 0.0353  time: 1.9161  data_time: 0.2288  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:37:22 d2.utils.events]: \u001b[0m eta: 6:51:39  iter: 2079  total_loss: 0.8247  loss_cls: 0.4552  loss_box_reg: 0.3001  loss_rpn_cls: 0.02924  loss_rpn_loc: 0.02949  time: 1.9161  data_time: 0.2319  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:38:00 d2.utils.events]: \u001b[0m eta: 6:51:01  iter: 2099  total_loss: 0.8263  loss_cls: 0.4394  loss_box_reg: 0.3234  loss_rpn_cls: 0.02967  loss_rpn_loc: 0.03052  time: 1.9161  data_time: 0.2285  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:38:39 d2.utils.events]: \u001b[0m eta: 6:50:23  iter: 2119  total_loss: 0.8475  loss_cls: 0.4548  loss_box_reg: 0.3252  loss_rpn_cls: 0.02726  loss_rpn_loc: 0.03445  time: 1.9161  data_time: 0.2314  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:39:17 d2.utils.events]: \u001b[0m eta: 6:49:45  iter: 2139  total_loss: 0.8964  loss_cls: 0.49  loss_box_reg: 0.3465  loss_rpn_cls: 0.0293  loss_rpn_loc: 0.03304  time: 1.9162  data_time: 0.2310  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:39:55 d2.utils.events]: \u001b[0m eta: 6:49:06  iter: 2159  total_loss: 0.8528  loss_cls: 0.4527  loss_box_reg: 0.3222  loss_rpn_cls: 0.0349  loss_rpn_loc: 0.04056  time: 1.9162  data_time: 0.2284  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:40:34 d2.utils.events]: \u001b[0m eta: 6:48:29  iter: 2179  total_loss: 0.9097  loss_cls: 0.4938  loss_box_reg: 0.3401  loss_rpn_cls: 0.03663  loss_rpn_loc: 0.04152  time: 1.9162  data_time: 0.2331  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:41:12 d2.utils.events]: \u001b[0m eta: 6:47:49  iter: 2199  total_loss: 0.8629  loss_cls: 0.4609  loss_box_reg: 0.3364  loss_rpn_cls: 0.02568  loss_rpn_loc: 0.03335  time: 1.9162  data_time: 0.2269  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:41:50 d2.utils.events]: \u001b[0m eta: 6:47:11  iter: 2219  total_loss: 0.885  loss_cls: 0.4741  loss_box_reg: 0.3167  loss_rpn_cls: 0.03502  loss_rpn_loc: 0.04456  time: 1.9161  data_time: 0.2327  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:42:29 d2.utils.events]: \u001b[0m eta: 6:46:35  iter: 2239  total_loss: 0.8799  loss_cls: 0.4492  loss_box_reg: 0.3363  loss_rpn_cls: 0.03401  loss_rpn_loc: 0.03725  time: 1.9162  data_time: 0.2285  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:43:07 d2.utils.events]: \u001b[0m eta: 6:45:55  iter: 2259  total_loss: 0.7975  loss_cls: 0.4404  loss_box_reg: 0.3046  loss_rpn_cls: 0.02664  loss_rpn_loc: 0.03504  time: 1.9161  data_time: 0.2304  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:43:45 d2.utils.events]: \u001b[0m eta: 6:45:19  iter: 2279  total_loss: 0.8301  loss_cls: 0.4732  loss_box_reg: 0.2903  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.03702  time: 1.9161  data_time: 0.2271  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:44:24 d2.utils.events]: \u001b[0m eta: 6:44:46  iter: 2299  total_loss: 0.8373  loss_cls: 0.4749  loss_box_reg: 0.2977  loss_rpn_cls: 0.03557  loss_rpn_loc: 0.03653  time: 1.9161  data_time: 0.2326  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:45:02 d2.utils.events]: \u001b[0m eta: 6:44:08  iter: 2319  total_loss: 0.8746  loss_cls: 0.4911  loss_box_reg: 0.326  loss_rpn_cls: 0.02883  loss_rpn_loc: 0.03183  time: 1.9162  data_time: 0.2341  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:45:41 d2.utils.events]: \u001b[0m eta: 6:43:31  iter: 2339  total_loss: 0.8362  loss_cls: 0.4293  loss_box_reg: 0.321  loss_rpn_cls: 0.02637  loss_rpn_loc: 0.0346  time: 1.9163  data_time: 0.2358  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:46:19 d2.utils.events]: \u001b[0m eta: 6:42:52  iter: 2359  total_loss: 0.8131  loss_cls: 0.4286  loss_box_reg: 0.3031  loss_rpn_cls: 0.03021  loss_rpn_loc: 0.03764  time: 1.9163  data_time: 0.2305  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:46:57 d2.utils.events]: \u001b[0m eta: 6:42:13  iter: 2379  total_loss: 0.814  loss_cls: 0.4472  loss_box_reg: 0.3276  loss_rpn_cls: 0.02849  loss_rpn_loc: 0.02952  time: 1.9162  data_time: 0.2259  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:47:36 d2.utils.events]: \u001b[0m eta: 6:41:35  iter: 2399  total_loss: 0.7872  loss_cls: 0.4483  loss_box_reg: 0.3106  loss_rpn_cls: 0.03108  loss_rpn_loc: 0.03631  time: 1.9162  data_time: 0.2257  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:48:14 d2.utils.events]: \u001b[0m eta: 6:40:57  iter: 2419  total_loss: 0.8328  loss_cls: 0.4586  loss_box_reg: 0.3085  loss_rpn_cls: 0.02583  loss_rpn_loc: 0.03752  time: 1.9162  data_time: 0.2288  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:48:52 d2.utils.events]: \u001b[0m eta: 6:40:20  iter: 2439  total_loss: 0.8456  loss_cls: 0.4339  loss_box_reg: 0.3065  loss_rpn_cls: 0.02796  loss_rpn_loc: 0.03537  time: 1.9162  data_time: 0.2325  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:49:31 d2.utils.events]: \u001b[0m eta: 6:39:41  iter: 2459  total_loss: 0.8211  loss_cls: 0.4442  loss_box_reg: 0.3171  loss_rpn_cls: 0.0341  loss_rpn_loc: 0.03998  time: 1.9162  data_time: 0.2298  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:50:09 d2.utils.events]: \u001b[0m eta: 6:39:04  iter: 2479  total_loss: 0.8354  loss_cls: 0.4371  loss_box_reg: 0.3207  loss_rpn_cls: 0.03229  loss_rpn_loc: 0.03681  time: 1.9163  data_time: 0.2362  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:50:47 d2.utils.events]: \u001b[0m eta: 6:38:24  iter: 2499  total_loss: 0.8085  loss_cls: 0.4521  loss_box_reg: 0.3073  loss_rpn_cls: 0.03143  loss_rpn_loc: 0.03351  time: 1.9163  data_time: 0.2277  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:51:26 d2.utils.events]: \u001b[0m eta: 6:37:46  iter: 2519  total_loss: 0.8437  loss_cls: 0.4676  loss_box_reg: 0.3113  loss_rpn_cls: 0.03457  loss_rpn_loc: 0.03821  time: 1.9163  data_time: 0.2309  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:52:04 d2.utils.events]: \u001b[0m eta: 6:37:10  iter: 2539  total_loss: 0.8008  loss_cls: 0.4322  loss_box_reg: 0.2937  loss_rpn_cls: 0.03138  loss_rpn_loc: 0.03678  time: 1.9163  data_time: 0.2320  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:52:43 d2.utils.events]: \u001b[0m eta: 6:36:33  iter: 2559  total_loss: 0.8489  loss_cls: 0.4739  loss_box_reg: 0.3127  loss_rpn_cls: 0.03318  loss_rpn_loc: 0.03735  time: 1.9163  data_time: 0.2310  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:53:21 d2.utils.events]: \u001b[0m eta: 6:35:52  iter: 2579  total_loss: 0.8164  loss_cls: 0.4529  loss_box_reg: 0.3136  loss_rpn_cls: 0.02835  loss_rpn_loc: 0.03678  time: 1.9163  data_time: 0.2272  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:53:59 d2.utils.events]: \u001b[0m eta: 6:35:15  iter: 2599  total_loss: 0.8342  loss_cls: 0.4462  loss_box_reg: 0.2985  loss_rpn_cls: 0.03174  loss_rpn_loc: 0.04041  time: 1.9163  data_time: 0.2282  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:54:38 d2.utils.events]: \u001b[0m eta: 6:34:35  iter: 2619  total_loss: 0.8118  loss_cls: 0.4264  loss_box_reg: 0.2791  loss_rpn_cls: 0.03045  loss_rpn_loc: 0.03528  time: 1.9163  data_time: 0.2354  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:55:16 d2.utils.events]: \u001b[0m eta: 6:33:57  iter: 2639  total_loss: 0.7998  loss_cls: 0.4305  loss_box_reg: 0.3008  loss_rpn_cls: 0.02937  loss_rpn_loc: 0.03525  time: 1.9163  data_time: 0.2281  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:55:54 d2.utils.events]: \u001b[0m eta: 6:33:19  iter: 2659  total_loss: 0.7987  loss_cls: 0.4485  loss_box_reg: 0.3118  loss_rpn_cls: 0.02786  loss_rpn_loc: 0.03062  time: 1.9163  data_time: 0.2282  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:56:32 d2.utils.events]: \u001b[0m eta: 6:32:40  iter: 2679  total_loss: 0.8208  loss_cls: 0.4451  loss_box_reg: 0.3014  loss_rpn_cls: 0.02668  loss_rpn_loc: 0.02708  time: 1.9163  data_time: 0.2276  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:57:11 d2.utils.events]: \u001b[0m eta: 6:32:02  iter: 2699  total_loss: 0.8014  loss_cls: 0.4575  loss_box_reg: 0.2954  loss_rpn_cls: 0.03004  loss_rpn_loc: 0.03709  time: 1.9163  data_time: 0.2318  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:57:49 d2.utils.events]: \u001b[0m eta: 6:31:23  iter: 2719  total_loss: 0.8505  loss_cls: 0.4501  loss_box_reg: 0.3054  loss_rpn_cls: 0.02801  loss_rpn_loc: 0.03321  time: 1.9164  data_time: 0.2343  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:58:28 d2.utils.events]: \u001b[0m eta: 6:30:45  iter: 2739  total_loss: 0.8154  loss_cls: 0.466  loss_box_reg: 0.3201  loss_rpn_cls: 0.02379  loss_rpn_loc: 0.03071  time: 1.9164  data_time: 0.2290  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:59:06 d2.utils.events]: \u001b[0m eta: 6:30:07  iter: 2759  total_loss: 0.8596  loss_cls: 0.4527  loss_box_reg: 0.3155  loss_rpn_cls: 0.02993  loss_rpn_loc: 0.03891  time: 1.9164  data_time: 0.2309  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 17:59:45 d2.utils.events]: \u001b[0m eta: 6:29:28  iter: 2779  total_loss: 0.8113  loss_cls: 0.4292  loss_box_reg: 0.3021  loss_rpn_cls: 0.03618  loss_rpn_loc: 0.03761  time: 1.9164  data_time: 0.2272  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:00:23 d2.utils.events]: \u001b[0m eta: 6:28:51  iter: 2799  total_loss: 0.799  loss_cls: 0.4272  loss_box_reg: 0.3033  loss_rpn_cls: 0.0323  loss_rpn_loc: 0.03778  time: 1.9164  data_time: 0.2382  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:01:01 d2.utils.events]: \u001b[0m eta: 6:28:12  iter: 2819  total_loss: 0.8106  loss_cls: 0.4305  loss_box_reg: 0.3182  loss_rpn_cls: 0.03165  loss_rpn_loc: 0.03172  time: 1.9164  data_time: 0.2307  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:01:40 d2.utils.events]: \u001b[0m eta: 6:27:34  iter: 2839  total_loss: 0.8109  loss_cls: 0.4241  loss_box_reg: 0.301  loss_rpn_cls: 0.02578  loss_rpn_loc: 0.03306  time: 1.9164  data_time: 0.2283  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:02:18 d2.utils.events]: \u001b[0m eta: 6:26:55  iter: 2859  total_loss: 0.7521  loss_cls: 0.4214  loss_box_reg: 0.2945  loss_rpn_cls: 0.02776  loss_rpn_loc: 0.0315  time: 1.9165  data_time: 0.2393  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:02:57 d2.utils.events]: \u001b[0m eta: 6:26:17  iter: 2879  total_loss: 0.8059  loss_cls: 0.4286  loss_box_reg: 0.3043  loss_rpn_cls: 0.02424  loss_rpn_loc: 0.03243  time: 1.9165  data_time: 0.2308  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:03:35 d2.utils.events]: \u001b[0m eta: 6:25:39  iter: 2899  total_loss: 0.8121  loss_cls: 0.4529  loss_box_reg: 0.3176  loss_rpn_cls: 0.03301  loss_rpn_loc: 0.04277  time: 1.9165  data_time: 0.2288  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:04:13 d2.utils.events]: \u001b[0m eta: 6:25:01  iter: 2919  total_loss: 0.8566  loss_cls: 0.4475  loss_box_reg: 0.2906  loss_rpn_cls: 0.03641  loss_rpn_loc: 0.03506  time: 1.9165  data_time: 0.2295  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:04:52 d2.utils.events]: \u001b[0m eta: 6:24:26  iter: 2939  total_loss: 0.8095  loss_cls: 0.4355  loss_box_reg: 0.311  loss_rpn_cls: 0.03577  loss_rpn_loc: 0.04252  time: 1.9165  data_time: 0.2300  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:05:30 d2.utils.events]: \u001b[0m eta: 6:23:48  iter: 2959  total_loss: 0.8141  loss_cls: 0.4531  loss_box_reg: 0.3042  loss_rpn_cls: 0.02733  loss_rpn_loc: 0.03491  time: 1.9165  data_time: 0.2308  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:06:08 d2.utils.events]: \u001b[0m eta: 6:23:09  iter: 2979  total_loss: 0.8006  loss_cls: 0.4263  loss_box_reg: 0.3033  loss_rpn_cls: 0.03033  loss_rpn_loc: 0.0326  time: 1.9165  data_time: 0.2307  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:06:47 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../../../dataset/test.json\n",
      "\u001b[32m[01/05 18:06:47 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 0            |    Paper    | 0            | Paper pack | 0            |\n",
      "|     Metal     | 0            |    Glass    | 0            |  Plastic   | 0            |\n",
      "|   Styrofoam   | 0            | Plastic bag | 0            |  Battery   | 0            |\n",
      "|   Clothing    | 0            |             |              |            |              |\n",
      "|     total     | 0            |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[01/05 18:06:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/05 18:06:47 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/05 18:06:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.53 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/05 18:06:48 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/05 18:06:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[01/05 18:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0011 s/iter. Inference: 0.0467 s/iter. Eval: 0.0004 s/iter. Total: 0.0482 s/iter. ETA=0:03:54\n",
      "\u001b[32m[01/05 18:06:53 d2.evaluation.evaluator]: \u001b[0mInference done 118/4871. Dataloading: 0.0015 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:03:43\n",
      "\u001b[32m[01/05 18:06:58 d2.evaluation.evaluator]: \u001b[0mInference done 221/4871. Dataloading: 0.0015 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:03:43\n",
      "\u001b[32m[01/05 18:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 328/4871. Dataloading: 0.0016 s/iter. Inference: 0.0457 s/iter. Eval: 0.0003 s/iter. Total: 0.0477 s/iter. ETA=0:03:36\n",
      "\u001b[32m[01/05 18:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 436/4871. Dataloading: 0.0016 s/iter. Inference: 0.0455 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:03:30\n",
      "\u001b[32m[01/05 18:07:14 d2.evaluation.evaluator]: \u001b[0mInference done 543/4871. Dataloading: 0.0016 s/iter. Inference: 0.0455 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:03:25\n",
      "\u001b[32m[01/05 18:07:19 d2.evaluation.evaluator]: \u001b[0mInference done 652/4871. Dataloading: 0.0016 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:03:18\n",
      "\u001b[32m[01/05 18:07:24 d2.evaluation.evaluator]: \u001b[0mInference done 756/4871. Dataloading: 0.0016 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:03:14\n",
      "\u001b[32m[01/05 18:07:29 d2.evaluation.evaluator]: \u001b[0mInference done 865/4871. Dataloading: 0.0015 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:03:08\n",
      "\u001b[32m[01/05 18:07:34 d2.evaluation.evaluator]: \u001b[0mInference done 976/4871. Dataloading: 0.0015 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:03:02\n",
      "\u001b[32m[01/05 18:07:39 d2.evaluation.evaluator]: \u001b[0mInference done 1085/4871. Dataloading: 0.0015 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:02:57\n",
      "\u001b[32m[01/05 18:07:44 d2.evaluation.evaluator]: \u001b[0mInference done 1196/4871. Dataloading: 0.0015 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0467 s/iter. ETA=0:02:51\n",
      "\u001b[32m[01/05 18:07:49 d2.evaluation.evaluator]: \u001b[0mInference done 1307/4871. Dataloading: 0.0015 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:02:46\n",
      "\u001b[32m[01/05 18:07:54 d2.evaluation.evaluator]: \u001b[0mInference done 1414/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:02:41\n",
      "\u001b[32m[01/05 18:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 1523/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:02:36\n",
      "\u001b[32m[01/05 18:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 1630/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:02:31\n",
      "\u001b[32m[01/05 18:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 1737/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:02:26\n",
      "\u001b[32m[01/05 18:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 1840/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0004 s/iter. Total: 0.0468 s/iter. ETA=0:02:21\n",
      "\u001b[32m[01/05 18:08:19 d2.evaluation.evaluator]: \u001b[0mInference done 1948/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0004 s/iter. Total: 0.0468 s/iter. ETA=0:02:16\n",
      "\u001b[32m[01/05 18:08:24 d2.evaluation.evaluator]: \u001b[0mInference done 2055/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0004 s/iter. Total: 0.0468 s/iter. ETA=0:02:11\n",
      "\u001b[32m[01/05 18:08:29 d2.evaluation.evaluator]: \u001b[0mInference done 2160/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0004 s/iter. Total: 0.0468 s/iter. ETA=0:02:06\n",
      "\u001b[32m[01/05 18:08:34 d2.evaluation.evaluator]: \u001b[0mInference done 2265/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0004 s/iter. Total: 0.0469 s/iter. ETA=0:02:02\n",
      "\u001b[32m[01/05 18:08:39 d2.evaluation.evaluator]: \u001b[0mInference done 2373/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:01:57\n",
      "\u001b[32m[01/05 18:08:44 d2.evaluation.evaluator]: \u001b[0mInference done 2482/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:01:51\n",
      "\u001b[32m[01/05 18:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 2586/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:01:47\n",
      "\u001b[32m[01/05 18:08:54 d2.evaluation.evaluator]: \u001b[0mInference done 2693/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:01:42\n",
      "\u001b[32m[01/05 18:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 2799/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:01:37\n",
      "\u001b[32m[01/05 18:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 2905/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:01:32\n",
      "\u001b[32m[01/05 18:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 3008/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:01:27\n",
      "\u001b[32m[01/05 18:09:14 d2.evaluation.evaluator]: \u001b[0mInference done 3113/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:01:22\n",
      "\u001b[32m[01/05 18:09:19 d2.evaluation.evaluator]: \u001b[0mInference done 3218/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:01:17\n",
      "\u001b[32m[01/05 18:09:24 d2.evaluation.evaluator]: \u001b[0mInference done 3327/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:01:12\n",
      "\u001b[32m[01/05 18:09:29 d2.evaluation.evaluator]: \u001b[0mInference done 3429/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:01:07\n",
      "\u001b[32m[01/05 18:09:34 d2.evaluation.evaluator]: \u001b[0mInference done 3537/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:01:02\n",
      "\u001b[32m[01/05 18:09:39 d2.evaluation.evaluator]: \u001b[0mInference done 3646/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:57\n",
      "\u001b[32m[01/05 18:09:44 d2.evaluation.evaluator]: \u001b[0mInference done 3755/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:52\n",
      "\u001b[32m[01/05 18:09:49 d2.evaluation.evaluator]: \u001b[0mInference done 3864/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:47\n",
      "\u001b[32m[01/05 18:09:54 d2.evaluation.evaluator]: \u001b[0mInference done 3970/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:42\n",
      "\u001b[32m[01/05 18:09:59 d2.evaluation.evaluator]: \u001b[0mInference done 4077/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:37\n",
      "\u001b[32m[01/05 18:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 4183/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:32\n",
      "\u001b[32m[01/05 18:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 4285/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:27\n",
      "\u001b[32m[01/05 18:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 4392/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:22\n",
      "\u001b[32m[01/05 18:10:19 d2.evaluation.evaluator]: \u001b[0mInference done 4502/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:17\n",
      "\u001b[32m[01/05 18:10:24 d2.evaluation.evaluator]: \u001b[0mInference done 4610/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:12\n",
      "\u001b[32m[01/05 18:10:29 d2.evaluation.evaluator]: \u001b[0mInference done 4718/4871. Dataloading: 0.0017 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:07\n",
      "\u001b[32m[01/05 18:10:34 d2.evaluation.evaluator]: \u001b[0mInference done 4823/4871. Dataloading: 0.0017 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:00:02\n",
      "\u001b[32m[01/05 18:10:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:48.772999 (0.047015 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/05 18:10:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:38 (0.044958 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/05 18:10:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/05 18:10:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[01/05 18:10:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.83s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/05 18:10:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/05 18:10:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.61 seconds.\n",
      "\u001b[32m[01/05 18:10:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/05 18:10:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.33 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/05 18:10:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[01/05 18:10:43 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/05 18:10:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[01/05 18:10:43 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[01/05 18:10:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/05 18:10:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/05 18:10:43 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[01/05 18:10:43 d2.utils.events]: \u001b[0m eta: 6:22:31  iter: 2999  total_loss: 0.8338  loss_cls: 0.4329  loss_box_reg: 0.3072  loss_rpn_cls: 0.02805  loss_rpn_loc: 0.03499  time: 1.9166  data_time: 0.2373  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:11:22 d2.utils.events]: \u001b[0m eta: 6:21:54  iter: 3019  total_loss: 0.7958  loss_cls: 0.4442  loss_box_reg: 0.3045  loss_rpn_cls: 0.02707  loss_rpn_loc: 0.03023  time: 1.9165  data_time: 0.2309  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:12:00 d2.utils.events]: \u001b[0m eta: 6:21:14  iter: 3039  total_loss: 0.8195  loss_cls: 0.4506  loss_box_reg: 0.2892  loss_rpn_cls: 0.02293  loss_rpn_loc: 0.03587  time: 1.9165  data_time: 0.2262  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:12:38 d2.utils.events]: \u001b[0m eta: 6:20:37  iter: 3059  total_loss: 0.7604  loss_cls: 0.432  loss_box_reg: 0.2861  loss_rpn_cls: 0.02539  loss_rpn_loc: 0.02736  time: 1.9165  data_time: 0.2338  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:13:17 d2.utils.events]: \u001b[0m eta: 6:20:00  iter: 3079  total_loss: 0.8119  loss_cls: 0.4394  loss_box_reg: 0.3027  loss_rpn_cls: 0.03025  loss_rpn_loc: 0.03768  time: 1.9166  data_time: 0.2391  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:13:55 d2.utils.events]: \u001b[0m eta: 6:19:23  iter: 3099  total_loss: 0.7899  loss_cls: 0.4195  loss_box_reg: 0.2874  loss_rpn_cls: 0.02724  loss_rpn_loc: 0.02886  time: 1.9167  data_time: 0.2307  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:14:34 d2.utils.events]: \u001b[0m eta: 6:18:45  iter: 3119  total_loss: 0.7786  loss_cls: 0.4306  loss_box_reg: 0.2702  loss_rpn_cls: 0.02994  loss_rpn_loc: 0.03931  time: 1.9166  data_time: 0.2299  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:15:12 d2.utils.events]: \u001b[0m eta: 6:18:07  iter: 3139  total_loss: 0.8533  loss_cls: 0.4469  loss_box_reg: 0.2986  loss_rpn_cls: 0.03027  loss_rpn_loc: 0.03612  time: 1.9167  data_time: 0.2315  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:15:50 d2.utils.events]: \u001b[0m eta: 6:17:29  iter: 3159  total_loss: 0.7957  loss_cls: 0.4305  loss_box_reg: 0.2788  loss_rpn_cls: 0.03107  loss_rpn_loc: 0.04111  time: 1.9167  data_time: 0.2314  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:16:29 d2.utils.events]: \u001b[0m eta: 6:16:50  iter: 3179  total_loss: 0.7738  loss_cls: 0.4217  loss_box_reg: 0.3006  loss_rpn_cls: 0.02739  loss_rpn_loc: 0.02947  time: 1.9167  data_time: 0.2305  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:17:07 d2.utils.events]: \u001b[0m eta: 6:16:12  iter: 3199  total_loss: 0.8406  loss_cls: 0.4493  loss_box_reg: 0.305  loss_rpn_cls: 0.02745  loss_rpn_loc: 0.03453  time: 1.9166  data_time: 0.2274  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:17:45 d2.utils.events]: \u001b[0m eta: 6:15:35  iter: 3219  total_loss: 0.7749  loss_cls: 0.4115  loss_box_reg: 0.2988  loss_rpn_cls: 0.02948  loss_rpn_loc: 0.03005  time: 1.9166  data_time: 0.2302  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:18:24 d2.utils.events]: \u001b[0m eta: 6:14:57  iter: 3239  total_loss: 0.7537  loss_cls: 0.4092  loss_box_reg: 0.28  loss_rpn_cls: 0.02848  loss_rpn_loc: 0.03167  time: 1.9166  data_time: 0.2327  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:19:02 d2.utils.events]: \u001b[0m eta: 6:14:19  iter: 3259  total_loss: 0.8453  loss_cls: 0.4439  loss_box_reg: 0.3133  loss_rpn_cls: 0.03806  loss_rpn_loc: 0.03994  time: 1.9166  data_time: 0.2270  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:19:40 d2.utils.events]: \u001b[0m eta: 6:13:40  iter: 3279  total_loss: 0.8114  loss_cls: 0.4416  loss_box_reg: 0.3018  loss_rpn_cls: 0.02663  loss_rpn_loc: 0.03175  time: 1.9166  data_time: 0.2264  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:20:19 d2.utils.events]: \u001b[0m eta: 6:13:00  iter: 3299  total_loss: 0.8145  loss_cls: 0.4262  loss_box_reg: 0.2879  loss_rpn_cls: 0.02641  loss_rpn_loc: 0.04122  time: 1.9166  data_time: 0.2311  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:20:57 d2.utils.events]: \u001b[0m eta: 6:12:22  iter: 3319  total_loss: 0.838  loss_cls: 0.4598  loss_box_reg: 0.3096  loss_rpn_cls: 0.03006  loss_rpn_loc: 0.03847  time: 1.9166  data_time: 0.2305  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:21:35 d2.utils.events]: \u001b[0m eta: 6:11:42  iter: 3339  total_loss: 0.8374  loss_cls: 0.4299  loss_box_reg: 0.3133  loss_rpn_cls: 0.0301  loss_rpn_loc: 0.04112  time: 1.9166  data_time: 0.2305  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:22:14 d2.utils.events]: \u001b[0m eta: 6:11:04  iter: 3359  total_loss: 0.7624  loss_cls: 0.4367  loss_box_reg: 0.2665  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.03744  time: 1.9166  data_time: 0.2285  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:22:52 d2.utils.events]: \u001b[0m eta: 6:10:27  iter: 3379  total_loss: 0.8479  loss_cls: 0.4598  loss_box_reg: 0.3225  loss_rpn_cls: 0.0293  loss_rpn_loc: 0.03831  time: 1.9166  data_time: 0.2313  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:23:30 d2.utils.events]: \u001b[0m eta: 6:09:49  iter: 3399  total_loss: 0.7713  loss_cls: 0.4192  loss_box_reg: 0.2858  loss_rpn_cls: 0.02201  loss_rpn_loc: 0.0359  time: 1.9166  data_time: 0.2326  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:24:09 d2.utils.events]: \u001b[0m eta: 6:09:12  iter: 3419  total_loss: 0.7972  loss_cls: 0.4296  loss_box_reg: 0.2919  loss_rpn_cls: 0.02855  loss_rpn_loc: 0.03934  time: 1.9166  data_time: 0.2295  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:24:47 d2.utils.events]: \u001b[0m eta: 6:08:35  iter: 3439  total_loss: 0.8249  loss_cls: 0.4486  loss_box_reg: 0.304  loss_rpn_cls: 0.03289  loss_rpn_loc: 0.03502  time: 1.9167  data_time: 0.2372  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:25:26 d2.utils.events]: \u001b[0m eta: 6:07:57  iter: 3459  total_loss: 0.7998  loss_cls: 0.4374  loss_box_reg: 0.301  loss_rpn_cls: 0.02791  loss_rpn_loc: 0.0344  time: 1.9167  data_time: 0.2280  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:26:04 d2.utils.events]: \u001b[0m eta: 6:07:18  iter: 3479  total_loss: 0.7791  loss_cls: 0.4252  loss_box_reg: 0.3023  loss_rpn_cls: 0.03152  loss_rpn_loc: 0.03296  time: 1.9167  data_time: 0.2293  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:26:42 d2.utils.events]: \u001b[0m eta: 6:06:40  iter: 3499  total_loss: 0.8088  loss_cls: 0.4326  loss_box_reg: 0.3018  loss_rpn_cls: 0.0283  loss_rpn_loc: 0.02885  time: 1.9167  data_time: 0.2327  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:27:21 d2.utils.events]: \u001b[0m eta: 6:06:00  iter: 3519  total_loss: 0.7296  loss_cls: 0.4006  loss_box_reg: 0.2529  loss_rpn_cls: 0.02914  loss_rpn_loc: 0.03435  time: 1.9166  data_time: 0.2238  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:27:59 d2.utils.events]: \u001b[0m eta: 6:05:23  iter: 3539  total_loss: 0.7903  loss_cls: 0.4138  loss_box_reg: 0.2874  loss_rpn_cls: 0.02721  loss_rpn_loc: 0.03399  time: 1.9167  data_time: 0.2356  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:28:37 d2.utils.events]: \u001b[0m eta: 6:04:43  iter: 3559  total_loss: 0.7611  loss_cls: 0.4184  loss_box_reg: 0.2722  loss_rpn_cls: 0.02722  loss_rpn_loc: 0.03145  time: 1.9167  data_time: 0.2279  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:29:16 d2.utils.events]: \u001b[0m eta: 6:04:06  iter: 3579  total_loss: 0.7374  loss_cls: 0.4108  loss_box_reg: 0.2601  loss_rpn_cls: 0.02502  loss_rpn_loc: 0.0403  time: 1.9166  data_time: 0.2263  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:29:54 d2.utils.events]: \u001b[0m eta: 6:03:28  iter: 3599  total_loss: 0.7638  loss_cls: 0.4114  loss_box_reg: 0.3047  loss_rpn_cls: 0.02364  loss_rpn_loc: 0.03031  time: 1.9166  data_time: 0.2325  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:30:32 d2.utils.events]: \u001b[0m eta: 6:02:49  iter: 3619  total_loss: 0.7821  loss_cls: 0.4213  loss_box_reg: 0.2854  loss_rpn_cls: 0.02907  loss_rpn_loc: 0.0291  time: 1.9167  data_time: 0.2327  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:31:11 d2.utils.events]: \u001b[0m eta: 6:02:10  iter: 3639  total_loss: 0.8013  loss_cls: 0.4333  loss_box_reg: 0.2944  loss_rpn_cls: 0.02909  loss_rpn_loc: 0.03178  time: 1.9167  data_time: 0.2306  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:31:49 d2.utils.events]: \u001b[0m eta: 6:01:33  iter: 3659  total_loss: 0.7806  loss_cls: 0.4245  loss_box_reg: 0.282  loss_rpn_cls: 0.02502  loss_rpn_loc: 0.03611  time: 1.9167  data_time: 0.2337  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:32:27 d2.utils.events]: \u001b[0m eta: 6:00:54  iter: 3679  total_loss: 0.8282  loss_cls: 0.4655  loss_box_reg: 0.2956  loss_rpn_cls: 0.03021  loss_rpn_loc: 0.03566  time: 1.9167  data_time: 0.2252  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:33:06 d2.utils.events]: \u001b[0m eta: 6:00:14  iter: 3699  total_loss: 0.7933  loss_cls: 0.4269  loss_box_reg: 0.3023  loss_rpn_cls: 0.02761  loss_rpn_loc: 0.03815  time: 1.9166  data_time: 0.2280  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:33:44 d2.utils.events]: \u001b[0m eta: 5:59:36  iter: 3719  total_loss: 0.7295  loss_cls: 0.4003  loss_box_reg: 0.2671  loss_rpn_cls: 0.02998  loss_rpn_loc: 0.03539  time: 1.9167  data_time: 0.2348  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:34:22 d2.utils.events]: \u001b[0m eta: 5:58:57  iter: 3739  total_loss: 0.7773  loss_cls: 0.4286  loss_box_reg: 0.2924  loss_rpn_cls: 0.03052  loss_rpn_loc: 0.03764  time: 1.9166  data_time: 0.2267  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:35:01 d2.utils.events]: \u001b[0m eta: 5:58:18  iter: 3759  total_loss: 0.7645  loss_cls: 0.4282  loss_box_reg: 0.2741  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.03844  time: 1.9166  data_time: 0.2286  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:35:39 d2.utils.events]: \u001b[0m eta: 5:57:40  iter: 3779  total_loss: 0.7455  loss_cls: 0.4095  loss_box_reg: 0.2839  loss_rpn_cls: 0.02246  loss_rpn_loc: 0.03051  time: 1.9167  data_time: 0.2371  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:36:18 d2.utils.events]: \u001b[0m eta: 5:57:01  iter: 3799  total_loss: 0.7286  loss_cls: 0.4016  loss_box_reg: 0.2709  loss_rpn_cls: 0.02203  loss_rpn_loc: 0.02914  time: 1.9167  data_time: 0.2304  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:36:56 d2.utils.events]: \u001b[0m eta: 5:56:23  iter: 3819  total_loss: 0.7899  loss_cls: 0.4271  loss_box_reg: 0.2918  loss_rpn_cls: 0.03142  loss_rpn_loc: 0.03704  time: 1.9167  data_time: 0.2324  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:37:35 d2.utils.events]: \u001b[0m eta: 5:55:44  iter: 3839  total_loss: 0.8217  loss_cls: 0.4415  loss_box_reg: 0.3005  loss_rpn_cls: 0.02788  loss_rpn_loc: 0.02944  time: 1.9167  data_time: 0.2338  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:38:13 d2.utils.events]: \u001b[0m eta: 5:55:05  iter: 3859  total_loss: 0.7766  loss_cls: 0.4244  loss_box_reg: 0.3002  loss_rpn_cls: 0.03287  loss_rpn_loc: 0.03587  time: 1.9167  data_time: 0.2296  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:38:51 d2.utils.events]: \u001b[0m eta: 5:54:28  iter: 3879  total_loss: 0.772  loss_cls: 0.4266  loss_box_reg: 0.2822  loss_rpn_cls: 0.02782  loss_rpn_loc: 0.03539  time: 1.9167  data_time: 0.2262  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:39:29 d2.utils.events]: \u001b[0m eta: 5:53:46  iter: 3899  total_loss: 0.7505  loss_cls: 0.4121  loss_box_reg: 0.2829  loss_rpn_cls: 0.03108  loss_rpn_loc: 0.03663  time: 1.9167  data_time: 0.2284  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:40:08 d2.utils.events]: \u001b[0m eta: 5:53:08  iter: 3919  total_loss: 0.7952  loss_cls: 0.4281  loss_box_reg: 0.286  loss_rpn_cls: 0.03062  loss_rpn_loc: 0.03241  time: 1.9167  data_time: 0.2305  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:40:46 d2.utils.events]: \u001b[0m eta: 5:52:30  iter: 3939  total_loss: 0.7396  loss_cls: 0.4132  loss_box_reg: 0.2615  loss_rpn_cls: 0.0224  loss_rpn_loc: 0.03207  time: 1.9167  data_time: 0.2329  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:41:25 d2.utils.events]: \u001b[0m eta: 5:51:51  iter: 3959  total_loss: 0.7811  loss_cls: 0.4076  loss_box_reg: 0.2924  loss_rpn_cls: 0.02955  loss_rpn_loc: 0.03995  time: 1.9168  data_time: 0.2349  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:42:03 d2.utils.events]: \u001b[0m eta: 5:51:15  iter: 3979  total_loss: 0.7483  loss_cls: 0.432  loss_box_reg: 0.2864  loss_rpn_cls: 0.0228  loss_rpn_loc: 0.02504  time: 1.9168  data_time: 0.2305  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:42:42 d2.utils.events]: \u001b[0m eta: 5:50:37  iter: 3999  total_loss: 0.7625  loss_cls: 0.4173  loss_box_reg: 0.2916  loss_rpn_cls: 0.02345  loss_rpn_loc: 0.02745  time: 1.9168  data_time: 0.2321  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:43:20 d2.utils.events]: \u001b[0m eta: 5:49:59  iter: 4019  total_loss: 0.7851  loss_cls: 0.4306  loss_box_reg: 0.3007  loss_rpn_cls: 0.02589  loss_rpn_loc: 0.03465  time: 1.9168  data_time: 0.2276  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:43:58 d2.utils.events]: \u001b[0m eta: 5:49:22  iter: 4039  total_loss: 0.7881  loss_cls: 0.4284  loss_box_reg: 0.2783  loss_rpn_cls: 0.02614  loss_rpn_loc: 0.04227  time: 1.9168  data_time: 0.2294  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:44:37 d2.utils.events]: \u001b[0m eta: 5:48:44  iter: 4059  total_loss: 0.7843  loss_cls: 0.4268  loss_box_reg: 0.2886  loss_rpn_cls: 0.02923  loss_rpn_loc: 0.03784  time: 1.9168  data_time: 0.2299  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:45:15 d2.utils.events]: \u001b[0m eta: 5:48:05  iter: 4079  total_loss: 0.7895  loss_cls: 0.434  loss_box_reg: 0.3004  loss_rpn_cls: 0.03108  loss_rpn_loc: 0.0361  time: 1.9168  data_time: 0.2282  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:45:53 d2.utils.events]: \u001b[0m eta: 5:47:28  iter: 4099  total_loss: 0.8053  loss_cls: 0.4335  loss_box_reg: 0.3001  loss_rpn_cls: 0.02798  loss_rpn_loc: 0.03999  time: 1.9168  data_time: 0.2313  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:46:32 d2.utils.events]: \u001b[0m eta: 5:46:49  iter: 4119  total_loss: 0.7641  loss_cls: 0.4034  loss_box_reg: 0.2844  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.03368  time: 1.9168  data_time: 0.2279  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:47:10 d2.utils.events]: \u001b[0m eta: 5:46:10  iter: 4139  total_loss: 0.7888  loss_cls: 0.4058  loss_box_reg: 0.2931  loss_rpn_cls: 0.02272  loss_rpn_loc: 0.03962  time: 1.9168  data_time: 0.2374  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:47:49 d2.utils.events]: \u001b[0m eta: 5:45:32  iter: 4159  total_loss: 0.7505  loss_cls: 0.4098  loss_box_reg: 0.2743  loss_rpn_cls: 0.02763  loss_rpn_loc: 0.03782  time: 1.9168  data_time: 0.2286  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:48:27 d2.utils.events]: \u001b[0m eta: 5:44:55  iter: 4179  total_loss: 0.7221  loss_cls: 0.4067  loss_box_reg: 0.2531  loss_rpn_cls: 0.0287  loss_rpn_loc: 0.02462  time: 1.9169  data_time: 0.2374  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:49:05 d2.utils.events]: \u001b[0m eta: 5:44:16  iter: 4199  total_loss: 0.7393  loss_cls: 0.4043  loss_box_reg: 0.2609  loss_rpn_cls: 0.02847  loss_rpn_loc: 0.03261  time: 1.9169  data_time: 0.2288  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:49:44 d2.utils.events]: \u001b[0m eta: 5:43:37  iter: 4219  total_loss: 0.733  loss_cls: 0.3871  loss_box_reg: 0.2678  loss_rpn_cls: 0.0301  loss_rpn_loc: 0.03778  time: 1.9169  data_time: 0.2284  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:50:22 d2.utils.events]: \u001b[0m eta: 5:42:56  iter: 4239  total_loss: 0.8241  loss_cls: 0.4308  loss_box_reg: 0.2856  loss_rpn_cls: 0.02846  loss_rpn_loc: 0.03326  time: 1.9168  data_time: 0.2258  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:51:00 d2.utils.events]: \u001b[0m eta: 5:42:20  iter: 4259  total_loss: 0.7547  loss_cls: 0.4223  loss_box_reg: 0.2849  loss_rpn_cls: 0.02397  loss_rpn_loc: 0.03655  time: 1.9169  data_time: 0.2358  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:51:39 d2.utils.events]: \u001b[0m eta: 5:41:43  iter: 4279  total_loss: 0.7695  loss_cls: 0.4303  loss_box_reg: 0.2865  loss_rpn_cls: 0.02386  loss_rpn_loc: 0.03839  time: 1.9168  data_time: 0.2249  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:52:17 d2.utils.events]: \u001b[0m eta: 5:41:05  iter: 4299  total_loss: 0.7756  loss_cls: 0.4251  loss_box_reg: 0.2752  loss_rpn_cls: 0.02349  loss_rpn_loc: 0.03062  time: 1.9168  data_time: 0.2334  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:52:56 d2.utils.events]: \u001b[0m eta: 5:40:28  iter: 4319  total_loss: 0.7399  loss_cls: 0.3948  loss_box_reg: 0.2718  loss_rpn_cls: 0.02765  loss_rpn_loc: 0.03367  time: 1.9169  data_time: 0.2351  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:53:34 d2.utils.events]: \u001b[0m eta: 5:39:50  iter: 4339  total_loss: 0.7  loss_cls: 0.406  loss_box_reg: 0.2644  loss_rpn_cls: 0.02265  loss_rpn_loc: 0.03537  time: 1.9169  data_time: 0.2297  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:54:12 d2.utils.events]: \u001b[0m eta: 5:39:13  iter: 4359  total_loss: 0.7393  loss_cls: 0.418  loss_box_reg: 0.2622  loss_rpn_cls: 0.03104  loss_rpn_loc: 0.03568  time: 1.9169  data_time: 0.2280  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:54:50 d2.utils.events]: \u001b[0m eta: 5:38:34  iter: 4379  total_loss: 0.764  loss_cls: 0.4113  loss_box_reg: 0.2819  loss_rpn_cls: 0.02934  loss_rpn_loc: 0.03483  time: 1.9168  data_time: 0.2294  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:55:29 d2.utils.events]: \u001b[0m eta: 5:37:54  iter: 4399  total_loss: 0.7263  loss_cls: 0.3951  loss_box_reg: 0.2761  loss_rpn_cls: 0.02201  loss_rpn_loc: 0.02515  time: 1.9168  data_time: 0.2308  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:56:07 d2.utils.events]: \u001b[0m eta: 5:37:15  iter: 4419  total_loss: 0.7582  loss_cls: 0.4086  loss_box_reg: 0.2831  loss_rpn_cls: 0.02748  loss_rpn_loc: 0.04531  time: 1.9168  data_time: 0.2321  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:56:46 d2.utils.events]: \u001b[0m eta: 5:36:35  iter: 4439  total_loss: 0.7129  loss_cls: 0.3996  loss_box_reg: 0.2698  loss_rpn_cls: 0.0249  loss_rpn_loc: 0.02688  time: 1.9168  data_time: 0.2312  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:57:24 d2.utils.events]: \u001b[0m eta: 5:35:56  iter: 4459  total_loss: 0.7776  loss_cls: 0.4156  loss_box_reg: 0.2872  loss_rpn_cls: 0.02845  loss_rpn_loc: 0.03774  time: 1.9168  data_time: 0.2282  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:58:02 d2.utils.events]: \u001b[0m eta: 5:35:16  iter: 4479  total_loss: 0.7403  loss_cls: 0.4008  loss_box_reg: 0.2899  loss_rpn_cls: 0.02281  loss_rpn_loc: 0.02372  time: 1.9168  data_time: 0.2232  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:58:40 d2.utils.events]: \u001b[0m eta: 5:34:39  iter: 4499  total_loss: 0.789  loss_cls: 0.4291  loss_box_reg: 0.2806  loss_rpn_cls: 0.03231  loss_rpn_loc: 0.04241  time: 1.9168  data_time: 0.2283  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:59:19 d2.utils.events]: \u001b[0m eta: 5:34:01  iter: 4519  total_loss: 0.7375  loss_cls: 0.3971  loss_box_reg: 0.2837  loss_rpn_cls: 0.02978  loss_rpn_loc: 0.03431  time: 1.9168  data_time: 0.2289  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 18:59:57 d2.utils.events]: \u001b[0m eta: 5:33:23  iter: 4539  total_loss: 0.7552  loss_cls: 0.408  loss_box_reg: 0.2727  loss_rpn_cls: 0.03108  loss_rpn_loc: 0.03725  time: 1.9168  data_time: 0.2356  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:00:36 d2.utils.events]: \u001b[0m eta: 5:32:45  iter: 4559  total_loss: 0.6927  loss_cls: 0.3462  loss_box_reg: 0.2546  loss_rpn_cls: 0.02499  loss_rpn_loc: 0.02776  time: 1.9168  data_time: 0.2295  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:01:14 d2.utils.events]: \u001b[0m eta: 5:32:06  iter: 4579  total_loss: 0.8167  loss_cls: 0.442  loss_box_reg: 0.2988  loss_rpn_cls: 0.02616  loss_rpn_loc: 0.03559  time: 1.9168  data_time: 0.2258  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:01:52 d2.utils.events]: \u001b[0m eta: 5:31:28  iter: 4599  total_loss: 0.668  loss_cls: 0.3712  loss_box_reg: 0.2538  loss_rpn_cls: 0.01991  loss_rpn_loc: 0.02634  time: 1.9168  data_time: 0.2272  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:02:31 d2.utils.events]: \u001b[0m eta: 5:30:49  iter: 4619  total_loss: 0.7676  loss_cls: 0.3947  loss_box_reg: 0.2831  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.04045  time: 1.9168  data_time: 0.2298  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:03:09 d2.utils.events]: \u001b[0m eta: 5:30:11  iter: 4639  total_loss: 0.7678  loss_cls: 0.398  loss_box_reg: 0.283  loss_rpn_cls: 0.02658  loss_rpn_loc: 0.03489  time: 1.9169  data_time: 0.2338  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:03:47 d2.utils.events]: \u001b[0m eta: 5:29:32  iter: 4659  total_loss: 0.7961  loss_cls: 0.4351  loss_box_reg: 0.2898  loss_rpn_cls: 0.03177  loss_rpn_loc: 0.03953  time: 1.9168  data_time: 0.2279  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:04:26 d2.utils.events]: \u001b[0m eta: 5:28:55  iter: 4679  total_loss: 0.7269  loss_cls: 0.4111  loss_box_reg: 0.25  loss_rpn_cls: 0.02801  loss_rpn_loc: 0.02937  time: 1.9169  data_time: 0.2367  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:05:04 d2.utils.events]: \u001b[0m eta: 5:28:18  iter: 4699  total_loss: 0.7547  loss_cls: 0.4197  loss_box_reg: 0.2998  loss_rpn_cls: 0.02332  loss_rpn_loc: 0.02701  time: 1.9169  data_time: 0.2257  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:05:43 d2.utils.events]: \u001b[0m eta: 5:27:40  iter: 4719  total_loss: 0.7486  loss_cls: 0.4029  loss_box_reg: 0.2795  loss_rpn_cls: 0.02598  loss_rpn_loc: 0.03069  time: 1.9169  data_time: 0.2323  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:06:21 d2.utils.events]: \u001b[0m eta: 5:27:04  iter: 4739  total_loss: 0.8018  loss_cls: 0.4221  loss_box_reg: 0.2997  loss_rpn_cls: 0.02637  loss_rpn_loc: 0.04015  time: 1.9169  data_time: 0.2296  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:07:00 d2.utils.events]: \u001b[0m eta: 5:26:26  iter: 4759  total_loss: 0.8484  loss_cls: 0.4528  loss_box_reg: 0.31  loss_rpn_cls: 0.03074  loss_rpn_loc: 0.05273  time: 1.9169  data_time: 0.2300  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:07:38 d2.utils.events]: \u001b[0m eta: 5:25:47  iter: 4779  total_loss: 0.7281  loss_cls: 0.4139  loss_box_reg: 0.2673  loss_rpn_cls: 0.02142  loss_rpn_loc: 0.03042  time: 1.9169  data_time: 0.2282  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:08:16 d2.utils.events]: \u001b[0m eta: 5:25:09  iter: 4799  total_loss: 0.7021  loss_cls: 0.4022  loss_box_reg: 0.2753  loss_rpn_cls: 0.0234  loss_rpn_loc: 0.02469  time: 1.9169  data_time: 0.2271  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:08:55 d2.utils.events]: \u001b[0m eta: 5:24:33  iter: 4819  total_loss: 0.7404  loss_cls: 0.3859  loss_box_reg: 0.2718  loss_rpn_cls: 0.03103  loss_rpn_loc: 0.03393  time: 1.9169  data_time: 0.2304  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:09:33 d2.utils.events]: \u001b[0m eta: 5:23:53  iter: 4839  total_loss: 0.7976  loss_cls: 0.4086  loss_box_reg: 0.2817  loss_rpn_cls: 0.03144  loss_rpn_loc: 0.03354  time: 1.9169  data_time: 0.2302  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:10:11 d2.utils.events]: \u001b[0m eta: 5:23:15  iter: 4859  total_loss: 0.7681  loss_cls: 0.419  loss_box_reg: 0.2894  loss_rpn_cls: 0.02944  loss_rpn_loc: 0.03433  time: 1.9169  data_time: 0.2274  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:10:50 d2.utils.events]: \u001b[0m eta: 5:22:36  iter: 4879  total_loss: 0.709  loss_cls: 0.3823  loss_box_reg: 0.2741  loss_rpn_cls: 0.02175  loss_rpn_loc: 0.03362  time: 1.9169  data_time: 0.2288  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:11:28 d2.utils.events]: \u001b[0m eta: 5:22:00  iter: 4899  total_loss: 0.7649  loss_cls: 0.4129  loss_box_reg: 0.2757  loss_rpn_cls: 0.02445  loss_rpn_loc: 0.04236  time: 1.9169  data_time: 0.2272  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:12:06 d2.utils.events]: \u001b[0m eta: 5:21:19  iter: 4919  total_loss: 0.7556  loss_cls: 0.3818  loss_box_reg: 0.2726  loss_rpn_cls: 0.02555  loss_rpn_loc: 0.03427  time: 1.9168  data_time: 0.2263  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:12:44 d2.utils.events]: \u001b[0m eta: 5:20:41  iter: 4939  total_loss: 0.7815  loss_cls: 0.4075  loss_box_reg: 0.2945  loss_rpn_cls: 0.02887  loss_rpn_loc: 0.04074  time: 1.9169  data_time: 0.2301  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:13:23 d2.utils.events]: \u001b[0m eta: 5:20:05  iter: 4959  total_loss: 0.7519  loss_cls: 0.4108  loss_box_reg: 0.2725  loss_rpn_cls: 0.02843  loss_rpn_loc: 0.03635  time: 1.9169  data_time: 0.2313  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:14:01 d2.utils.events]: \u001b[0m eta: 5:19:23  iter: 4979  total_loss: 0.7329  loss_cls: 0.3877  loss_box_reg: 0.2659  loss_rpn_cls: 0.02631  loss_rpn_loc: 0.0357  time: 1.9168  data_time: 0.2288  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:14:39 d2.utils.events]: \u001b[0m eta: 5:18:44  iter: 4999  total_loss: 0.7482  loss_cls: 0.4075  loss_box_reg: 0.2704  loss_rpn_cls: 0.02699  loss_rpn_loc: 0.03104  time: 1.9168  data_time: 0.2311  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:15:18 d2.utils.events]: \u001b[0m eta: 5:18:06  iter: 5019  total_loss: 0.7863  loss_cls: 0.4317  loss_box_reg: 0.2861  loss_rpn_cls: 0.02665  loss_rpn_loc: 0.03967  time: 1.9169  data_time: 0.2316  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:15:56 d2.utils.events]: \u001b[0m eta: 5:17:28  iter: 5039  total_loss: 0.7389  loss_cls: 0.4031  loss_box_reg: 0.2749  loss_rpn_cls: 0.03073  loss_rpn_loc: 0.03335  time: 1.9169  data_time: 0.2288  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:16:35 d2.utils.events]: \u001b[0m eta: 5:16:50  iter: 5059  total_loss: 0.647  loss_cls: 0.3554  loss_box_reg: 0.2415  loss_rpn_cls: 0.02211  loss_rpn_loc: 0.02985  time: 1.9168  data_time: 0.2297  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:17:13 d2.utils.events]: \u001b[0m eta: 5:16:12  iter: 5079  total_loss: 0.7517  loss_cls: 0.4154  loss_box_reg: 0.276  loss_rpn_cls: 0.02751  loss_rpn_loc: 0.02923  time: 1.9168  data_time: 0.2289  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:17:51 d2.utils.events]: \u001b[0m eta: 5:15:33  iter: 5099  total_loss: 0.7924  loss_cls: 0.4244  loss_box_reg: 0.2992  loss_rpn_cls: 0.03068  loss_rpn_loc: 0.03922  time: 1.9168  data_time: 0.2295  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:18:30 d2.utils.events]: \u001b[0m eta: 5:14:54  iter: 5119  total_loss: 0.7359  loss_cls: 0.3888  loss_box_reg: 0.2823  loss_rpn_cls: 0.02216  loss_rpn_loc: 0.03253  time: 1.9168  data_time: 0.2271  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:19:08 d2.utils.events]: \u001b[0m eta: 5:14:16  iter: 5139  total_loss: 0.6844  loss_cls: 0.3884  loss_box_reg: 0.2498  loss_rpn_cls: 0.02047  loss_rpn_loc: 0.02446  time: 1.9168  data_time: 0.2298  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:19:46 d2.utils.events]: \u001b[0m eta: 5:13:38  iter: 5159  total_loss: 0.758  loss_cls: 0.4207  loss_box_reg: 0.2838  loss_rpn_cls: 0.02756  loss_rpn_loc: 0.03224  time: 1.9168  data_time: 0.2284  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:20:25 d2.utils.events]: \u001b[0m eta: 5:13:00  iter: 5179  total_loss: 0.7066  loss_cls: 0.3968  loss_box_reg: 0.2676  loss_rpn_cls: 0.02422  loss_rpn_loc: 0.02994  time: 1.9168  data_time: 0.2302  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:21:03 d2.utils.events]: \u001b[0m eta: 5:12:22  iter: 5199  total_loss: 0.7624  loss_cls: 0.4033  loss_box_reg: 0.293  loss_rpn_cls: 0.02293  loss_rpn_loc: 0.0314  time: 1.9168  data_time: 0.2343  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:21:41 d2.utils.events]: \u001b[0m eta: 5:11:44  iter: 5219  total_loss: 0.7055  loss_cls: 0.3795  loss_box_reg: 0.2746  loss_rpn_cls: 0.02347  loss_rpn_loc: 0.03012  time: 1.9168  data_time: 0.2303  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:22:20 d2.utils.events]: \u001b[0m eta: 5:11:07  iter: 5239  total_loss: 0.7153  loss_cls: 0.4027  loss_box_reg: 0.2668  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.02845  time: 1.9168  data_time: 0.2278  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:22:58 d2.utils.events]: \u001b[0m eta: 5:10:27  iter: 5259  total_loss: 0.7038  loss_cls: 0.4022  loss_box_reg: 0.2659  loss_rpn_cls: 0.02275  loss_rpn_loc: 0.03681  time: 1.9168  data_time: 0.2325  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:23:37 d2.utils.events]: \u001b[0m eta: 5:09:50  iter: 5279  total_loss: 0.7514  loss_cls: 0.4167  loss_box_reg: 0.2719  loss_rpn_cls: 0.02514  loss_rpn_loc: 0.04009  time: 1.9169  data_time: 0.2338  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:24:15 d2.utils.events]: \u001b[0m eta: 5:09:11  iter: 5299  total_loss: 0.7276  loss_cls: 0.3956  loss_box_reg: 0.2529  loss_rpn_cls: 0.03198  loss_rpn_loc: 0.0433  time: 1.9169  data_time: 0.2289  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:24:53 d2.utils.events]: \u001b[0m eta: 5:08:32  iter: 5319  total_loss: 0.7743  loss_cls: 0.4133  loss_box_reg: 0.3033  loss_rpn_cls: 0.02581  loss_rpn_loc: 0.04333  time: 1.9169  data_time: 0.2315  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:25:32 d2.utils.events]: \u001b[0m eta: 5:07:54  iter: 5339  total_loss: 0.7349  loss_cls: 0.3992  loss_box_reg: 0.2747  loss_rpn_cls: 0.0289  loss_rpn_loc: 0.03541  time: 1.9169  data_time: 0.2306  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:26:10 d2.utils.events]: \u001b[0m eta: 5:07:15  iter: 5359  total_loss: 0.7411  loss_cls: 0.4  loss_box_reg: 0.2691  loss_rpn_cls: 0.02576  loss_rpn_loc: 0.02928  time: 1.9169  data_time: 0.2281  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:26:48 d2.utils.events]: \u001b[0m eta: 5:06:37  iter: 5379  total_loss: 0.7142  loss_cls: 0.3809  loss_box_reg: 0.2546  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.03002  time: 1.9169  data_time: 0.2331  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:27:27 d2.utils.events]: \u001b[0m eta: 5:05:59  iter: 5399  total_loss: 0.7057  loss_cls: 0.3919  loss_box_reg: 0.2658  loss_rpn_cls: 0.02287  loss_rpn_loc: 0.03054  time: 1.9169  data_time: 0.2346  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:28:05 d2.utils.events]: \u001b[0m eta: 5:05:20  iter: 5419  total_loss: 0.7249  loss_cls: 0.4136  loss_box_reg: 0.2626  loss_rpn_cls: 0.02418  loss_rpn_loc: 0.02823  time: 1.9169  data_time: 0.2292  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:28:43 d2.utils.events]: \u001b[0m eta: 5:04:42  iter: 5439  total_loss: 0.7432  loss_cls: 0.393  loss_box_reg: 0.2774  loss_rpn_cls: 0.02026  loss_rpn_loc: 0.03289  time: 1.9169  data_time: 0.2324  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:29:22 d2.utils.events]: \u001b[0m eta: 5:04:04  iter: 5459  total_loss: 0.7146  loss_cls: 0.3928  loss_box_reg: 0.2593  loss_rpn_cls: 0.02306  loss_rpn_loc: 0.03638  time: 1.9169  data_time: 0.2302  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:30:00 d2.utils.events]: \u001b[0m eta: 5:03:27  iter: 5479  total_loss: 0.7542  loss_cls: 0.3999  loss_box_reg: 0.2886  loss_rpn_cls: 0.02938  loss_rpn_loc: 0.04408  time: 1.9169  data_time: 0.2359  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:30:39 d2.utils.events]: \u001b[0m eta: 5:02:49  iter: 5499  total_loss: 0.6852  loss_cls: 0.3911  loss_box_reg: 0.2636  loss_rpn_cls: 0.02294  loss_rpn_loc: 0.03595  time: 1.9169  data_time: 0.2351  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:31:17 d2.utils.events]: \u001b[0m eta: 5:02:11  iter: 5519  total_loss: 0.7565  loss_cls: 0.4188  loss_box_reg: 0.2668  loss_rpn_cls: 0.02533  loss_rpn_loc: 0.03074  time: 1.9169  data_time: 0.2281  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:31:56 d2.utils.events]: \u001b[0m eta: 5:01:32  iter: 5539  total_loss: 0.6967  loss_cls: 0.3741  loss_box_reg: 0.2633  loss_rpn_cls: 0.02268  loss_rpn_loc: 0.02651  time: 1.9169  data_time: 0.2318  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:32:34 d2.utils.events]: \u001b[0m eta: 5:00:53  iter: 5559  total_loss: 0.7366  loss_cls: 0.3878  loss_box_reg: 0.2745  loss_rpn_cls: 0.02427  loss_rpn_loc: 0.03602  time: 1.9169  data_time: 0.2284  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:33:12 d2.utils.events]: \u001b[0m eta: 5:00:16  iter: 5579  total_loss: 0.7658  loss_cls: 0.394  loss_box_reg: 0.2552  loss_rpn_cls: 0.0259  loss_rpn_loc: 0.04083  time: 1.9169  data_time: 0.2296  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:33:51 d2.utils.events]: \u001b[0m eta: 4:59:38  iter: 5599  total_loss: 0.7301  loss_cls: 0.393  loss_box_reg: 0.2675  loss_rpn_cls: 0.02799  loss_rpn_loc: 0.03219  time: 1.9169  data_time: 0.2289  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:34:29 d2.utils.events]: \u001b[0m eta: 4:58:59  iter: 5619  total_loss: 0.6953  loss_cls: 0.3896  loss_box_reg: 0.2656  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.02841  time: 1.9169  data_time: 0.2317  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:35:07 d2.utils.events]: \u001b[0m eta: 4:58:21  iter: 5639  total_loss: 0.7167  loss_cls: 0.3992  loss_box_reg: 0.2751  loss_rpn_cls: 0.02698  loss_rpn_loc: 0.03576  time: 1.9169  data_time: 0.2313  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:35:46 d2.utils.events]: \u001b[0m eta: 4:57:44  iter: 5659  total_loss: 0.7507  loss_cls: 0.4034  loss_box_reg: 0.293  loss_rpn_cls: 0.02989  loss_rpn_loc: 0.03939  time: 1.9169  data_time: 0.2323  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:36:24 d2.utils.events]: \u001b[0m eta: 4:57:05  iter: 5679  total_loss: 0.7226  loss_cls: 0.3887  loss_box_reg: 0.2637  loss_rpn_cls: 0.02501  loss_rpn_loc: 0.02904  time: 1.9169  data_time: 0.2301  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:37:02 d2.utils.events]: \u001b[0m eta: 4:56:26  iter: 5699  total_loss: 0.7935  loss_cls: 0.4041  loss_box_reg: 0.2959  loss_rpn_cls: 0.02899  loss_rpn_loc: 0.03886  time: 1.9169  data_time: 0.2314  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:37:41 d2.utils.events]: \u001b[0m eta: 4:55:47  iter: 5719  total_loss: 0.71  loss_cls: 0.3822  loss_box_reg: 0.258  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.03283  time: 1.9169  data_time: 0.2335  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:38:19 d2.utils.events]: \u001b[0m eta: 4:55:09  iter: 5739  total_loss: 0.6947  loss_cls: 0.3909  loss_box_reg: 0.2405  loss_rpn_cls: 0.02192  loss_rpn_loc: 0.03954  time: 1.9169  data_time: 0.2261  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:38:57 d2.utils.events]: \u001b[0m eta: 4:54:31  iter: 5759  total_loss: 0.6843  loss_cls: 0.37  loss_box_reg: 0.2487  loss_rpn_cls: 0.02575  loss_rpn_loc: 0.03968  time: 1.9169  data_time: 0.2376  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:39:36 d2.utils.events]: \u001b[0m eta: 4:53:52  iter: 5779  total_loss: 0.7379  loss_cls: 0.4058  loss_box_reg: 0.2767  loss_rpn_cls: 0.02759  loss_rpn_loc: 0.03726  time: 1.9169  data_time: 0.2275  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:40:14 d2.utils.events]: \u001b[0m eta: 4:53:15  iter: 5799  total_loss: 0.7426  loss_cls: 0.4101  loss_box_reg: 0.2755  loss_rpn_cls: 0.02455  loss_rpn_loc: 0.03011  time: 1.9170  data_time: 0.2364  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:40:53 d2.utils.events]: \u001b[0m eta: 4:52:37  iter: 5819  total_loss: 0.6982  loss_cls: 0.3861  loss_box_reg: 0.2702  loss_rpn_cls: 0.02796  loss_rpn_loc: 0.03189  time: 1.9170  data_time: 0.2306  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:41:31 d2.utils.events]: \u001b[0m eta: 4:51:59  iter: 5839  total_loss: 0.6994  loss_cls: 0.3762  loss_box_reg: 0.2713  loss_rpn_cls: 0.02302  loss_rpn_loc: 0.03019  time: 1.9170  data_time: 0.2311  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:42:10 d2.utils.events]: \u001b[0m eta: 4:51:21  iter: 5859  total_loss: 0.7339  loss_cls: 0.3594  loss_box_reg: 0.2821  loss_rpn_cls: 0.02708  loss_rpn_loc: 0.04894  time: 1.9170  data_time: 0.2402  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:42:48 d2.utils.events]: \u001b[0m eta: 4:50:43  iter: 5879  total_loss: 0.6983  loss_cls: 0.3953  loss_box_reg: 0.2646  loss_rpn_cls: 0.02219  loss_rpn_loc: 0.03  time: 1.9170  data_time: 0.2325  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:43:27 d2.utils.events]: \u001b[0m eta: 4:50:05  iter: 5899  total_loss: 0.7287  loss_cls: 0.3986  loss_box_reg: 0.2738  loss_rpn_cls: 0.02909  loss_rpn_loc: 0.0319  time: 1.9170  data_time: 0.2286  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:44:05 d2.utils.events]: \u001b[0m eta: 4:49:27  iter: 5919  total_loss: 0.6997  loss_cls: 0.3741  loss_box_reg: 0.2566  loss_rpn_cls: 0.02878  loss_rpn_loc: 0.03019  time: 1.9170  data_time: 0.2301  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:44:43 d2.utils.events]: \u001b[0m eta: 4:48:51  iter: 5939  total_loss: 0.7314  loss_cls: 0.4037  loss_box_reg: 0.2705  loss_rpn_cls: 0.02556  loss_rpn_loc: 0.03308  time: 1.9171  data_time: 0.2330  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:45:22 d2.utils.events]: \u001b[0m eta: 4:48:12  iter: 5959  total_loss: 0.6833  loss_cls: 0.3748  loss_box_reg: 0.2614  loss_rpn_cls: 0.02023  loss_rpn_loc: 0.02851  time: 1.9170  data_time: 0.2292  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:46:00 d2.utils.events]: \u001b[0m eta: 4:47:34  iter: 5979  total_loss: 0.7434  loss_cls: 0.4127  loss_box_reg: 0.2711  loss_rpn_cls: 0.02468  loss_rpn_loc: 0.03456  time: 1.9171  data_time: 0.2331  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:46:39 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../../../dataset/test.json\n",
      "\u001b[32m[01/05 19:46:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/05 19:46:39 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/05 19:46:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.53 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/05 19:46:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/05 19:46:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[01/05 19:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0013 s/iter. Inference: 0.0466 s/iter. Eval: 0.0003 s/iter. Total: 0.0483 s/iter. ETA=0:03:54\n",
      "\u001b[32m[01/05 19:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 115/4871. Dataloading: 0.0016 s/iter. Inference: 0.0464 s/iter. Eval: 0.0003 s/iter. Total: 0.0484 s/iter. ETA=0:03:50\n",
      "\u001b[32m[01/05 19:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 224/4871. Dataloading: 0.0016 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:03:39\n",
      "\u001b[32m[01/05 19:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 324/4871. Dataloading: 0.0017 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0481 s/iter. ETA=0:03:38\n",
      "\u001b[32m[01/05 19:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 434/4871. Dataloading: 0.0017 s/iter. Inference: 0.0454 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:03:30\n",
      "\u001b[32m[01/05 19:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 539/4871. Dataloading: 0.0017 s/iter. Inference: 0.0455 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:03:25\n",
      "\u001b[32m[01/05 19:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 646/4871. Dataloading: 0.0016 s/iter. Inference: 0.0455 s/iter. Eval: 0.0003 s/iter. Total: 0.0475 s/iter. ETA=0:03:20\n",
      "\u001b[32m[01/05 19:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 757/4871. Dataloading: 0.0016 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:03:13\n",
      "\u001b[32m[01/05 19:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 862/4871. Dataloading: 0.0016 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:03:09\n",
      "\u001b[32m[01/05 19:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 975/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:03:02\n",
      "\u001b[32m[01/05 19:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 1084/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:02:57\n",
      "\u001b[32m[01/05 19:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 1190/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:02:52\n",
      "\u001b[32m[01/05 19:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 1295/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:02:47\n",
      "\u001b[32m[01/05 19:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 1404/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:02:42\n",
      "\u001b[32m[01/05 19:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 1511/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:02:37\n",
      "\u001b[32m[01/05 19:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 1613/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:02:33\n",
      "\u001b[32m[01/05 19:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 1721/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:02:27\n",
      "\u001b[32m[01/05 19:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 1827/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:02:23\n",
      "\u001b[32m[01/05 19:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 1928/4871. Dataloading: 0.0016 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0471 s/iter. ETA=0:02:18\n",
      "\u001b[32m[01/05 19:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 2033/4871. Dataloading: 0.0016 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:02:13\n",
      "\u001b[32m[01/05 19:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 2140/4871. Dataloading: 0.0016 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:02:08\n",
      "\u001b[32m[01/05 19:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 2246/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:02:03\n",
      "\u001b[32m[01/05 19:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 2352/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:01:58\n",
      "\u001b[32m[01/05 19:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 2458/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:01:53\n",
      "\u001b[32m[01/05 19:48:40 d2.evaluation.evaluator]: \u001b[0mInference done 2564/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:01:48\n",
      "\u001b[32m[01/05 19:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 2670/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:01:43\n",
      "\u001b[32m[01/05 19:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 2774/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:01:39\n",
      "\u001b[32m[01/05 19:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 2877/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:34\n",
      "\u001b[32m[01/05 19:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 2985/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:29\n",
      "\u001b[32m[01/05 19:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 3091/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:24\n",
      "\u001b[32m[01/05 19:49:11 d2.evaluation.evaluator]: \u001b[0mInference done 3197/4871. Dataloading: 0.0017 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:19\n",
      "\u001b[32m[01/05 19:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 3305/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:14\n",
      "\u001b[32m[01/05 19:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 3413/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:08\n",
      "\u001b[32m[01/05 19:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 3519/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:01:03\n",
      "\u001b[32m[01/05 19:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 3625/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:00:58\n",
      "\u001b[32m[01/05 19:49:36 d2.evaluation.evaluator]: \u001b[0mInference done 3736/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:53\n",
      "\u001b[32m[01/05 19:49:41 d2.evaluation.evaluator]: \u001b[0mInference done 3843/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:48\n",
      "\u001b[32m[01/05 19:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 3949/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:43\n",
      "\u001b[32m[01/05 19:49:51 d2.evaluation.evaluator]: \u001b[0mInference done 4056/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:38\n",
      "\u001b[32m[01/05 19:49:56 d2.evaluation.evaluator]: \u001b[0mInference done 4162/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:33\n",
      "\u001b[32m[01/05 19:50:01 d2.evaluation.evaluator]: \u001b[0mInference done 4270/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:28\n",
      "\u001b[32m[01/05 19:50:06 d2.evaluation.evaluator]: \u001b[0mInference done 4375/4871. Dataloading: 0.0017 s/iter. Inference: 0.0451 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:23\n",
      "\u001b[32m[01/05 19:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 4479/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:00:18\n",
      "\u001b[32m[01/05 19:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 4581/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:00:13\n",
      "\u001b[32m[01/05 19:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 4685/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/05 19:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 4792/4871. Dataloading: 0.0017 s/iter. Inference: 0.0452 s/iter. Eval: 0.0003 s/iter. Total: 0.0473 s/iter. ETA=0:00:03\n",
      "\u001b[32m[01/05 19:50:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:50.069901 (0.047281 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/05 19:50:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:39 (0.045211 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/05 19:50:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/05 19:50:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[01/05 19:50:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.84s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/05 19:50:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/05 19:50:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.31 seconds.\n",
      "\u001b[32m[01/05 19:50:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/05 19:50:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.31 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/05 19:50:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[01/05 19:50:36 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/05 19:50:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[01/05 19:50:36 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[01/05 19:50:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/05 19:50:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/05 19:50:36 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[01/05 19:50:36 d2.utils.events]: \u001b[0m eta: 4:46:54  iter: 5999  total_loss: 0.7058  loss_cls: 0.3847  loss_box_reg: 0.2659  loss_rpn_cls: 0.02577  loss_rpn_loc: 0.02835  time: 1.9170  data_time: 0.2270  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:51:14 d2.utils.events]: \u001b[0m eta: 4:46:16  iter: 6019  total_loss: 0.7347  loss_cls: 0.3892  loss_box_reg: 0.271  loss_rpn_cls: 0.02624  loss_rpn_loc: 0.03627  time: 1.9170  data_time: 0.2320  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:51:53 d2.utils.events]: \u001b[0m eta: 4:45:36  iter: 6039  total_loss: 0.7394  loss_cls: 0.4136  loss_box_reg: 0.2518  loss_rpn_cls: 0.02306  loss_rpn_loc: 0.0314  time: 1.9170  data_time: 0.2275  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:52:31 d2.utils.events]: \u001b[0m eta: 4:44:58  iter: 6059  total_loss: 0.7672  loss_cls: 0.4087  loss_box_reg: 0.2874  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.0343  time: 1.9170  data_time: 0.2311  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:53:09 d2.utils.events]: \u001b[0m eta: 4:44:19  iter: 6079  total_loss: 0.7522  loss_cls: 0.405  loss_box_reg: 0.2703  loss_rpn_cls: 0.0269  loss_rpn_loc: 0.02505  time: 1.9170  data_time: 0.2316  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:53:48 d2.utils.events]: \u001b[0m eta: 4:43:40  iter: 6099  total_loss: 0.6946  loss_cls: 0.4083  loss_box_reg: 0.2466  loss_rpn_cls: 0.02242  loss_rpn_loc: 0.03094  time: 1.9170  data_time: 0.2227  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:54:26 d2.utils.events]: \u001b[0m eta: 4:43:03  iter: 6119  total_loss: 0.767  loss_cls: 0.4051  loss_box_reg: 0.2874  loss_rpn_cls: 0.03002  loss_rpn_loc: 0.04669  time: 1.9170  data_time: 0.2296  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:55:04 d2.utils.events]: \u001b[0m eta: 4:42:25  iter: 6139  total_loss: 0.7607  loss_cls: 0.4234  loss_box_reg: 0.2745  loss_rpn_cls: 0.02753  loss_rpn_loc: 0.02864  time: 1.9170  data_time: 0.2280  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:55:43 d2.utils.events]: \u001b[0m eta: 4:41:46  iter: 6159  total_loss: 0.6743  loss_cls: 0.3697  loss_box_reg: 0.2332  loss_rpn_cls: 0.02251  loss_rpn_loc: 0.03278  time: 1.9170  data_time: 0.2325  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:56:21 d2.utils.events]: \u001b[0m eta: 4:41:07  iter: 6179  total_loss: 0.7191  loss_cls: 0.3929  loss_box_reg: 0.2635  loss_rpn_cls: 0.02346  loss_rpn_loc: 0.03011  time: 1.9170  data_time: 0.2314  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:57:00 d2.utils.events]: \u001b[0m eta: 4:40:30  iter: 6199  total_loss: 0.6929  loss_cls: 0.4047  loss_box_reg: 0.2557  loss_rpn_cls: 0.02487  loss_rpn_loc: 0.03511  time: 1.9170  data_time: 0.2318  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:57:38 d2.utils.events]: \u001b[0m eta: 4:39:51  iter: 6219  total_loss: 0.7743  loss_cls: 0.383  loss_box_reg: 0.3059  loss_rpn_cls: 0.02866  loss_rpn_loc: 0.03826  time: 1.9170  data_time: 0.2267  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:58:16 d2.utils.events]: \u001b[0m eta: 4:39:11  iter: 6239  total_loss: 0.6802  loss_cls: 0.3706  loss_box_reg: 0.2554  loss_rpn_cls: 0.02883  loss_rpn_loc: 0.03432  time: 1.9170  data_time: 0.2289  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:58:54 d2.utils.events]: \u001b[0m eta: 4:38:34  iter: 6259  total_loss: 0.6975  loss_cls: 0.3789  loss_box_reg: 0.2765  loss_rpn_cls: 0.02388  loss_rpn_loc: 0.04096  time: 1.9170  data_time: 0.2323  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 19:59:33 d2.utils.events]: \u001b[0m eta: 4:37:55  iter: 6279  total_loss: 0.7155  loss_cls: 0.3741  loss_box_reg: 0.259  loss_rpn_cls: 0.02862  loss_rpn_loc: 0.03148  time: 1.9170  data_time: 0.2294  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:00:11 d2.utils.events]: \u001b[0m eta: 4:37:18  iter: 6299  total_loss: 0.7302  loss_cls: 0.3994  loss_box_reg: 0.2677  loss_rpn_cls: 0.02606  loss_rpn_loc: 0.03371  time: 1.9170  data_time: 0.2346  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:00:50 d2.utils.events]: \u001b[0m eta: 4:36:42  iter: 6319  total_loss: 0.7634  loss_cls: 0.4054  loss_box_reg: 0.2839  loss_rpn_cls: 0.02266  loss_rpn_loc: 0.03135  time: 1.9170  data_time: 0.2329  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:01:28 d2.utils.events]: \u001b[0m eta: 4:36:07  iter: 6339  total_loss: 0.7269  loss_cls: 0.3852  loss_box_reg: 0.2752  loss_rpn_cls: 0.02301  loss_rpn_loc: 0.03194  time: 1.9171  data_time: 0.2338  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:02:07 d2.utils.events]: \u001b[0m eta: 4:35:29  iter: 6359  total_loss: 0.6819  loss_cls: 0.3757  loss_box_reg: 0.2516  loss_rpn_cls: 0.02134  loss_rpn_loc: 0.02654  time: 1.9171  data_time: 0.2314  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:02:45 d2.utils.events]: \u001b[0m eta: 4:34:52  iter: 6379  total_loss: 0.7176  loss_cls: 0.3838  loss_box_reg: 0.2616  loss_rpn_cls: 0.02624  loss_rpn_loc: 0.0345  time: 1.9171  data_time: 0.2360  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:03:23 d2.utils.events]: \u001b[0m eta: 4:34:11  iter: 6399  total_loss: 0.7393  loss_cls: 0.3932  loss_box_reg: 0.2631  loss_rpn_cls: 0.03123  loss_rpn_loc: 0.03718  time: 1.9171  data_time: 0.2266  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:04:02 d2.utils.events]: \u001b[0m eta: 4:33:34  iter: 6419  total_loss: 0.6948  loss_cls: 0.3735  loss_box_reg: 0.2651  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.03211  time: 1.9171  data_time: 0.2311  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:04:40 d2.utils.events]: \u001b[0m eta: 4:32:55  iter: 6439  total_loss: 0.6804  loss_cls: 0.3814  loss_box_reg: 0.251  loss_rpn_cls: 0.02173  loss_rpn_loc: 0.03101  time: 1.9170  data_time: 0.2243  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:05:18 d2.utils.events]: \u001b[0m eta: 4:32:17  iter: 6459  total_loss: 0.7395  loss_cls: 0.3942  loss_box_reg: 0.2837  loss_rpn_cls: 0.02606  loss_rpn_loc: 0.04323  time: 1.9170  data_time: 0.2357  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:05:57 d2.utils.events]: \u001b[0m eta: 4:31:36  iter: 6479  total_loss: 0.7379  loss_cls: 0.4141  loss_box_reg: 0.2687  loss_rpn_cls: 0.02465  loss_rpn_loc: 0.03752  time: 1.9170  data_time: 0.2300  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:06:35 d2.utils.events]: \u001b[0m eta: 4:30:57  iter: 6499  total_loss: 0.7639  loss_cls: 0.3988  loss_box_reg: 0.2844  loss_rpn_cls: 0.0324  loss_rpn_loc: 0.0369  time: 1.9170  data_time: 0.2317  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:07:13 d2.utils.events]: \u001b[0m eta: 4:30:20  iter: 6519  total_loss: 0.6957  loss_cls: 0.3821  loss_box_reg: 0.264  loss_rpn_cls: 0.02397  loss_rpn_loc: 0.03308  time: 1.9170  data_time: 0.2324  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:07:52 d2.utils.events]: \u001b[0m eta: 4:29:41  iter: 6539  total_loss: 0.7263  loss_cls: 0.3955  loss_box_reg: 0.262  loss_rpn_cls: 0.02168  loss_rpn_loc: 0.02875  time: 1.9170  data_time: 0.2306  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:08:30 d2.utils.events]: \u001b[0m eta: 4:29:04  iter: 6559  total_loss: 0.6703  loss_cls: 0.3569  loss_box_reg: 0.2498  loss_rpn_cls: 0.02287  loss_rpn_loc: 0.03476  time: 1.9170  data_time: 0.2278  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:09:08 d2.utils.events]: \u001b[0m eta: 4:28:25  iter: 6579  total_loss: 0.7223  loss_cls: 0.3743  loss_box_reg: 0.2764  loss_rpn_cls: 0.02758  loss_rpn_loc: 0.02845  time: 1.9170  data_time: 0.2284  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:09:47 d2.utils.events]: \u001b[0m eta: 4:27:47  iter: 6599  total_loss: 0.6763  loss_cls: 0.3781  loss_box_reg: 0.2468  loss_rpn_cls: 0.02706  loss_rpn_loc: 0.03186  time: 1.9170  data_time: 0.2283  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:10:25 d2.utils.events]: \u001b[0m eta: 4:27:09  iter: 6619  total_loss: 0.7332  loss_cls: 0.3807  loss_box_reg: 0.2558  loss_rpn_cls: 0.02275  loss_rpn_loc: 0.03613  time: 1.9170  data_time: 0.2344  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:11:03 d2.utils.events]: \u001b[0m eta: 4:26:30  iter: 6639  total_loss: 0.7704  loss_cls: 0.3903  loss_box_reg: 0.2912  loss_rpn_cls: 0.02753  loss_rpn_loc: 0.03632  time: 1.9170  data_time: 0.2271  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:11:42 d2.utils.events]: \u001b[0m eta: 4:25:51  iter: 6659  total_loss: 0.7324  loss_cls: 0.366  loss_box_reg: 0.2859  loss_rpn_cls: 0.03114  loss_rpn_loc: 0.03418  time: 1.9170  data_time: 0.2302  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:12:20 d2.utils.events]: \u001b[0m eta: 4:25:14  iter: 6679  total_loss: 0.7043  loss_cls: 0.3873  loss_box_reg: 0.2592  loss_rpn_cls: 0.02954  loss_rpn_loc: 0.03052  time: 1.9170  data_time: 0.2378  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:12:59 d2.utils.events]: \u001b[0m eta: 4:24:38  iter: 6699  total_loss: 0.6922  loss_cls: 0.3804  loss_box_reg: 0.2459  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.03156  time: 1.9171  data_time: 0.2391  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:13:37 d2.utils.events]: \u001b[0m eta: 4:23:59  iter: 6719  total_loss: 0.731  loss_cls: 0.3829  loss_box_reg: 0.2534  loss_rpn_cls: 0.02089  loss_rpn_loc: 0.03286  time: 1.9171  data_time: 0.2292  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:14:15 d2.utils.events]: \u001b[0m eta: 4:23:21  iter: 6739  total_loss: 0.666  loss_cls: 0.3778  loss_box_reg: 0.2498  loss_rpn_cls: 0.01925  loss_rpn_loc: 0.02491  time: 1.9171  data_time: 0.2315  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:14:54 d2.utils.events]: \u001b[0m eta: 4:22:41  iter: 6759  total_loss: 0.6939  loss_cls: 0.3703  loss_box_reg: 0.2613  loss_rpn_cls: 0.02689  loss_rpn_loc: 0.03615  time: 1.9171  data_time: 0.2296  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:15:32 d2.utils.events]: \u001b[0m eta: 4:22:06  iter: 6779  total_loss: 0.686  loss_cls: 0.3729  loss_box_reg: 0.257  loss_rpn_cls: 0.02155  loss_rpn_loc: 0.03106  time: 1.9171  data_time: 0.2359  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:16:11 d2.utils.events]: \u001b[0m eta: 4:21:25  iter: 6799  total_loss: 0.6656  loss_cls: 0.3608  loss_box_reg: 0.2641  loss_rpn_cls: 0.02323  loss_rpn_loc: 0.02818  time: 1.9171  data_time: 0.2312  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:16:49 d2.utils.events]: \u001b[0m eta: 4:20:47  iter: 6819  total_loss: 0.6847  loss_cls: 0.373  loss_box_reg: 0.2564  loss_rpn_cls: 0.02259  loss_rpn_loc: 0.02984  time: 1.9171  data_time: 0.2279  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:17:27 d2.utils.events]: \u001b[0m eta: 4:20:08  iter: 6839  total_loss: 0.6903  loss_cls: 0.3696  loss_box_reg: 0.2653  loss_rpn_cls: 0.02166  loss_rpn_loc: 0.03235  time: 1.9171  data_time: 0.2273  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:18:06 d2.utils.events]: \u001b[0m eta: 4:19:29  iter: 6859  total_loss: 0.698  loss_cls: 0.3699  loss_box_reg: 0.2515  loss_rpn_cls: 0.02252  loss_rpn_loc: 0.0275  time: 1.9171  data_time: 0.2306  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:18:44 d2.utils.events]: \u001b[0m eta: 4:18:51  iter: 6879  total_loss: 0.6917  loss_cls: 0.3752  loss_box_reg: 0.269  loss_rpn_cls: 0.02468  loss_rpn_loc: 0.03568  time: 1.9171  data_time: 0.2281  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:19:22 d2.utils.events]: \u001b[0m eta: 4:18:13  iter: 6899  total_loss: 0.692  loss_cls: 0.3885  loss_box_reg: 0.2555  loss_rpn_cls: 0.02523  loss_rpn_loc: 0.02884  time: 1.9171  data_time: 0.2270  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:20:01 d2.utils.events]: \u001b[0m eta: 4:17:34  iter: 6919  total_loss: 0.7579  loss_cls: 0.3979  loss_box_reg: 0.2681  loss_rpn_cls: 0.02996  loss_rpn_loc: 0.04306  time: 1.9171  data_time: 0.2318  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:20:39 d2.utils.events]: \u001b[0m eta: 4:16:56  iter: 6939  total_loss: 0.7497  loss_cls: 0.4047  loss_box_reg: 0.2724  loss_rpn_cls: 0.02085  loss_rpn_loc: 0.03264  time: 1.9171  data_time: 0.2307  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:21:17 d2.utils.events]: \u001b[0m eta: 4:16:18  iter: 6959  total_loss: 0.6725  loss_cls: 0.3709  loss_box_reg: 0.2713  loss_rpn_cls: 0.02461  loss_rpn_loc: 0.03715  time: 1.9171  data_time: 0.2307  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:21:56 d2.utils.events]: \u001b[0m eta: 4:15:40  iter: 6979  total_loss: 0.7317  loss_cls: 0.3884  loss_box_reg: 0.2868  loss_rpn_cls: 0.02548  loss_rpn_loc: 0.03845  time: 1.9171  data_time: 0.2299  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:22:34 d2.utils.events]: \u001b[0m eta: 4:15:04  iter: 6999  total_loss: 0.7087  loss_cls: 0.3852  loss_box_reg: 0.2641  loss_rpn_cls: 0.02658  loss_rpn_loc: 0.03534  time: 1.9171  data_time: 0.2296  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:23:12 d2.utils.events]: \u001b[0m eta: 4:14:24  iter: 7019  total_loss: 0.69  loss_cls: 0.3646  loss_box_reg: 0.255  loss_rpn_cls: 0.02442  loss_rpn_loc: 0.03301  time: 1.9171  data_time: 0.2291  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:23:51 d2.utils.events]: \u001b[0m eta: 4:13:47  iter: 7039  total_loss: 0.7147  loss_cls: 0.3943  loss_box_reg: 0.2713  loss_rpn_cls: 0.0268  loss_rpn_loc: 0.03808  time: 1.9171  data_time: 0.2318  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:24:29 d2.utils.events]: \u001b[0m eta: 4:13:09  iter: 7059  total_loss: 0.6923  loss_cls: 0.3744  loss_box_reg: 0.2703  loss_rpn_cls: 0.02719  loss_rpn_loc: 0.04227  time: 1.9171  data_time: 0.2329  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:25:08 d2.utils.events]: \u001b[0m eta: 4:12:32  iter: 7079  total_loss: 0.6687  loss_cls: 0.3575  loss_box_reg: 0.2371  loss_rpn_cls: 0.02469  loss_rpn_loc: 0.03829  time: 1.9171  data_time: 0.2327  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:25:46 d2.utils.events]: \u001b[0m eta: 4:11:54  iter: 7099  total_loss: 0.6865  loss_cls: 0.3723  loss_box_reg: 0.2622  loss_rpn_cls: 0.02465  loss_rpn_loc: 0.02774  time: 1.9171  data_time: 0.2337  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:26:25 d2.utils.events]: \u001b[0m eta: 4:11:16  iter: 7119  total_loss: 0.6761  loss_cls: 0.3622  loss_box_reg: 0.2407  loss_rpn_cls: 0.02322  loss_rpn_loc: 0.03032  time: 1.9171  data_time: 0.2309  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:27:03 d2.utils.events]: \u001b[0m eta: 4:10:38  iter: 7139  total_loss: 0.6813  loss_cls: 0.3547  loss_box_reg: 0.2673  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.02843  time: 1.9171  data_time: 0.2319  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:27:41 d2.utils.events]: \u001b[0m eta: 4:10:01  iter: 7159  total_loss: 0.7259  loss_cls: 0.3941  loss_box_reg: 0.2755  loss_rpn_cls: 0.02332  loss_rpn_loc: 0.02829  time: 1.9171  data_time: 0.2300  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:28:20 d2.utils.events]: \u001b[0m eta: 4:09:23  iter: 7179  total_loss: 0.7028  loss_cls: 0.3469  loss_box_reg: 0.2676  loss_rpn_cls: 0.02773  loss_rpn_loc: 0.03315  time: 1.9171  data_time: 0.2356  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:28:58 d2.utils.events]: \u001b[0m eta: 4:08:43  iter: 7199  total_loss: 0.742  loss_cls: 0.3695  loss_box_reg: 0.2713  loss_rpn_cls: 0.01929  loss_rpn_loc: 0.03199  time: 1.9171  data_time: 0.2277  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:29:36 d2.utils.events]: \u001b[0m eta: 4:08:06  iter: 7219  total_loss: 0.7173  loss_cls: 0.4039  loss_box_reg: 0.2674  loss_rpn_cls: 0.02351  loss_rpn_loc: 0.03399  time: 1.9171  data_time: 0.2242  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:30:15 d2.utils.events]: \u001b[0m eta: 4:07:30  iter: 7239  total_loss: 0.6733  loss_cls: 0.3461  loss_box_reg: 0.2466  loss_rpn_cls: 0.02599  loss_rpn_loc: 0.03  time: 1.9171  data_time: 0.2370  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:30:53 d2.utils.events]: \u001b[0m eta: 4:06:52  iter: 7259  total_loss: 0.7342  loss_cls: 0.4026  loss_box_reg: 0.2627  loss_rpn_cls: 0.02454  loss_rpn_loc: 0.04159  time: 1.9171  data_time: 0.2268  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:31:32 d2.utils.events]: \u001b[0m eta: 4:06:13  iter: 7279  total_loss: 0.7089  loss_cls: 0.3779  loss_box_reg: 0.263  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.02995  time: 1.9171  data_time: 0.2271  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:32:10 d2.utils.events]: \u001b[0m eta: 4:05:35  iter: 7299  total_loss: 0.73  loss_cls: 0.4023  loss_box_reg: 0.2659  loss_rpn_cls: 0.02474  loss_rpn_loc: 0.03534  time: 1.9172  data_time: 0.2316  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:32:48 d2.utils.events]: \u001b[0m eta: 4:04:53  iter: 7319  total_loss: 0.6635  loss_cls: 0.3535  loss_box_reg: 0.2682  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.03284  time: 1.9171  data_time: 0.2257  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:33:27 d2.utils.events]: \u001b[0m eta: 4:04:14  iter: 7339  total_loss: 0.711  loss_cls: 0.3884  loss_box_reg: 0.2729  loss_rpn_cls: 0.02316  loss_rpn_loc: 0.03009  time: 1.9171  data_time: 0.2314  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:34:05 d2.utils.events]: \u001b[0m eta: 4:03:36  iter: 7359  total_loss: 0.643  loss_cls: 0.3564  loss_box_reg: 0.2526  loss_rpn_cls: 0.02028  loss_rpn_loc: 0.02662  time: 1.9171  data_time: 0.2306  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:34:44 d2.utils.events]: \u001b[0m eta: 4:02:58  iter: 7379  total_loss: 0.6905  loss_cls: 0.3804  loss_box_reg: 0.2515  loss_rpn_cls: 0.01866  loss_rpn_loc: 0.03104  time: 1.9172  data_time: 0.2368  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:35:22 d2.utils.events]: \u001b[0m eta: 4:02:20  iter: 7399  total_loss: 0.6616  loss_cls: 0.3505  loss_box_reg: 0.2562  loss_rpn_cls: 0.01961  loss_rpn_loc: 0.02875  time: 1.9171  data_time: 0.2267  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:36:00 d2.utils.events]: \u001b[0m eta: 4:01:42  iter: 7419  total_loss: 0.7218  loss_cls: 0.3918  loss_box_reg: 0.2802  loss_rpn_cls: 0.02451  loss_rpn_loc: 0.03711  time: 1.9171  data_time: 0.2288  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:36:39 d2.utils.events]: \u001b[0m eta: 4:01:06  iter: 7439  total_loss: 0.7374  loss_cls: 0.3881  loss_box_reg: 0.2911  loss_rpn_cls: 0.02149  loss_rpn_loc: 0.03612  time: 1.9172  data_time: 0.2346  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:37:17 d2.utils.events]: \u001b[0m eta: 4:00:25  iter: 7459  total_loss: 0.7022  loss_cls: 0.3612  loss_box_reg: 0.27  loss_rpn_cls: 0.0254  loss_rpn_loc: 0.03597  time: 1.9171  data_time: 0.2265  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:37:55 d2.utils.events]: \u001b[0m eta: 3:59:49  iter: 7479  total_loss: 0.7125  loss_cls: 0.3774  loss_box_reg: 0.2609  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.03533  time: 1.9172  data_time: 0.2337  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:38:34 d2.utils.events]: \u001b[0m eta: 3:59:11  iter: 7499  total_loss: 0.7473  loss_cls: 0.3806  loss_box_reg: 0.2767  loss_rpn_cls: 0.02528  loss_rpn_loc: 0.03562  time: 1.9171  data_time: 0.2280  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:39:12 d2.utils.events]: \u001b[0m eta: 3:58:31  iter: 7519  total_loss: 0.7587  loss_cls: 0.3844  loss_box_reg: 0.2767  loss_rpn_cls: 0.02435  loss_rpn_loc: 0.03578  time: 1.9172  data_time: 0.2350  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:39:50 d2.utils.events]: \u001b[0m eta: 3:57:52  iter: 7539  total_loss: 0.6872  loss_cls: 0.3657  loss_box_reg: 0.2526  loss_rpn_cls: 0.02289  loss_rpn_loc: 0.03365  time: 1.9172  data_time: 0.2282  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:40:29 d2.utils.events]: \u001b[0m eta: 3:57:14  iter: 7559  total_loss: 0.677  loss_cls: 0.3589  loss_box_reg: 0.2454  loss_rpn_cls: 0.02378  loss_rpn_loc: 0.03282  time: 1.9171  data_time: 0.2254  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:41:07 d2.utils.events]: \u001b[0m eta: 3:56:38  iter: 7579  total_loss: 0.6877  loss_cls: 0.3534  loss_box_reg: 0.2528  loss_rpn_cls: 0.02477  loss_rpn_loc: 0.03273  time: 1.9171  data_time: 0.2323  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:41:45 d2.utils.events]: \u001b[0m eta: 3:56:00  iter: 7599  total_loss: 0.7023  loss_cls: 0.3664  loss_box_reg: 0.2771  loss_rpn_cls: 0.02687  loss_rpn_loc: 0.0407  time: 1.9171  data_time: 0.2279  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:42:24 d2.utils.events]: \u001b[0m eta: 3:55:21  iter: 7619  total_loss: 0.6354  loss_cls: 0.3582  loss_box_reg: 0.2293  loss_rpn_cls: 0.02468  loss_rpn_loc: 0.03331  time: 1.9171  data_time: 0.2297  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:43:02 d2.utils.events]: \u001b[0m eta: 3:54:44  iter: 7639  total_loss: 0.7078  loss_cls: 0.3598  loss_box_reg: 0.2602  loss_rpn_cls: 0.02613  loss_rpn_loc: 0.04033  time: 1.9171  data_time: 0.2338  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:43:40 d2.utils.events]: \u001b[0m eta: 3:54:06  iter: 7659  total_loss: 0.681  loss_cls: 0.3554  loss_box_reg: 0.2558  loss_rpn_cls: 0.02266  loss_rpn_loc: 0.03446  time: 1.9171  data_time: 0.2248  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:44:19 d2.utils.events]: \u001b[0m eta: 3:53:26  iter: 7679  total_loss: 0.697  loss_cls: 0.3639  loss_box_reg: 0.2715  loss_rpn_cls: 0.02164  loss_rpn_loc: 0.03239  time: 1.9171  data_time: 0.2284  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:44:57 d2.utils.events]: \u001b[0m eta: 3:52:46  iter: 7699  total_loss: 0.704  loss_cls: 0.3714  loss_box_reg: 0.259  loss_rpn_cls: 0.02319  loss_rpn_loc: 0.02514  time: 1.9171  data_time: 0.2292  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:45:35 d2.utils.events]: \u001b[0m eta: 3:52:08  iter: 7719  total_loss: 0.7033  loss_cls: 0.3695  loss_box_reg: 0.2531  loss_rpn_cls: 0.02411  loss_rpn_loc: 0.04454  time: 1.9171  data_time: 0.2263  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:46:14 d2.utils.events]: \u001b[0m eta: 3:51:29  iter: 7739  total_loss: 0.6753  loss_cls: 0.368  loss_box_reg: 0.2542  loss_rpn_cls: 0.02529  loss_rpn_loc: 0.03259  time: 1.9171  data_time: 0.2265  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:46:52 d2.utils.events]: \u001b[0m eta: 3:50:51  iter: 7759  total_loss: 0.6584  loss_cls: 0.3692  loss_box_reg: 0.26  loss_rpn_cls: 0.02321  loss_rpn_loc: 0.02902  time: 1.9171  data_time: 0.2399  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:47:31 d2.utils.events]: \u001b[0m eta: 3:50:13  iter: 7779  total_loss: 0.6884  loss_cls: 0.3526  loss_box_reg: 0.2696  loss_rpn_cls: 0.02028  loss_rpn_loc: 0.03229  time: 1.9172  data_time: 0.2352  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:48:09 d2.utils.events]: \u001b[0m eta: 3:49:36  iter: 7799  total_loss: 0.6982  loss_cls: 0.3635  loss_box_reg: 0.2504  loss_rpn_cls: 0.02426  loss_rpn_loc: 0.0328  time: 1.9172  data_time: 0.2354  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:48:48 d2.utils.events]: \u001b[0m eta: 3:48:58  iter: 7819  total_loss: 0.7331  loss_cls: 0.3932  loss_box_reg: 0.2759  loss_rpn_cls: 0.02287  loss_rpn_loc: 0.03917  time: 1.9172  data_time: 0.2289  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:49:26 d2.utils.events]: \u001b[0m eta: 3:48:20  iter: 7839  total_loss: 0.6912  loss_cls: 0.3577  loss_box_reg: 0.2611  loss_rpn_cls: 0.03043  loss_rpn_loc: 0.03455  time: 1.9172  data_time: 0.2333  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:50:04 d2.utils.events]: \u001b[0m eta: 3:47:41  iter: 7859  total_loss: 0.7418  loss_cls: 0.4089  loss_box_reg: 0.2509  loss_rpn_cls: 0.02597  loss_rpn_loc: 0.0324  time: 1.9172  data_time: 0.2260  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:50:43 d2.utils.events]: \u001b[0m eta: 3:47:02  iter: 7879  total_loss: 0.6428  loss_cls: 0.345  loss_box_reg: 0.2489  loss_rpn_cls: 0.01876  loss_rpn_loc: 0.02896  time: 1.9172  data_time: 0.2300  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:51:21 d2.utils.events]: \u001b[0m eta: 3:46:25  iter: 7899  total_loss: 0.7284  loss_cls: 0.3782  loss_box_reg: 0.289  loss_rpn_cls: 0.02487  loss_rpn_loc: 0.03673  time: 1.9172  data_time: 0.2339  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:52:00 d2.utils.events]: \u001b[0m eta: 3:45:47  iter: 7919  total_loss: 0.7434  loss_cls: 0.4127  loss_box_reg: 0.2599  loss_rpn_cls: 0.02316  loss_rpn_loc: 0.03083  time: 1.9172  data_time: 0.2312  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:52:38 d2.utils.events]: \u001b[0m eta: 3:45:07  iter: 7939  total_loss: 0.6237  loss_cls: 0.3382  loss_box_reg: 0.2457  loss_rpn_cls: 0.0217  loss_rpn_loc: 0.03254  time: 1.9172  data_time: 0.2264  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:53:16 d2.utils.events]: \u001b[0m eta: 3:44:29  iter: 7959  total_loss: 0.6764  loss_cls: 0.3616  loss_box_reg: 0.2504  loss_rpn_cls: 0.02148  loss_rpn_loc: 0.03321  time: 1.9172  data_time: 0.2380  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:53:55 d2.utils.events]: \u001b[0m eta: 3:43:50  iter: 7979  total_loss: 0.7271  loss_cls: 0.4093  loss_box_reg: 0.2674  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.03605  time: 1.9172  data_time: 0.2262  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:54:33 d2.utils.events]: \u001b[0m eta: 3:43:12  iter: 7999  total_loss: 0.6787  loss_cls: 0.3583  loss_box_reg: 0.2678  loss_rpn_cls: 0.02  loss_rpn_loc: 0.03167  time: 1.9172  data_time: 0.2344  lr: 0.0001  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:55:11 d2.utils.events]: \u001b[0m eta: 3:42:34  iter: 8019  total_loss: 0.704  loss_cls: 0.3803  loss_box_reg: 0.2567  loss_rpn_cls: 0.0267  loss_rpn_loc: 0.03302  time: 1.9172  data_time: 0.2247  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:55:50 d2.utils.events]: \u001b[0m eta: 3:41:55  iter: 8039  total_loss: 0.6393  loss_cls: 0.3519  loss_box_reg: 0.2442  loss_rpn_cls: 0.02142  loss_rpn_loc: 0.02609  time: 1.9172  data_time: 0.2248  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:56:28 d2.utils.events]: \u001b[0m eta: 3:41:16  iter: 8059  total_loss: 0.7186  loss_cls: 0.3747  loss_box_reg: 0.2853  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.03524  time: 1.9172  data_time: 0.2306  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:57:06 d2.utils.events]: \u001b[0m eta: 3:40:35  iter: 8079  total_loss: 0.6455  loss_cls: 0.333  loss_box_reg: 0.2549  loss_rpn_cls: 0.01991  loss_rpn_loc: 0.02933  time: 1.9172  data_time: 0.2309  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:57:45 d2.utils.events]: \u001b[0m eta: 3:39:57  iter: 8099  total_loss: 0.7382  loss_cls: 0.3867  loss_box_reg: 0.2775  loss_rpn_cls: 0.02956  loss_rpn_loc: 0.04295  time: 1.9172  data_time: 0.2311  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:58:23 d2.utils.events]: \u001b[0m eta: 3:39:19  iter: 8119  total_loss: 0.6744  loss_cls: 0.3671  loss_box_reg: 0.2458  loss_rpn_cls: 0.02322  loss_rpn_loc: 0.03277  time: 1.9172  data_time: 0.2311  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:59:02 d2.utils.events]: \u001b[0m eta: 3:38:41  iter: 8139  total_loss: 0.6403  loss_cls: 0.3515  loss_box_reg: 0.2428  loss_rpn_cls: 0.02376  loss_rpn_loc: 0.02861  time: 1.9172  data_time: 0.2330  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 20:59:40 d2.utils.events]: \u001b[0m eta: 3:38:02  iter: 8159  total_loss: 0.6499  loss_cls: 0.3509  loss_box_reg: 0.2502  loss_rpn_cls: 0.02003  loss_rpn_loc: 0.03348  time: 1.9172  data_time: 0.2257  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:00:18 d2.utils.events]: \u001b[0m eta: 3:37:23  iter: 8179  total_loss: 0.6523  loss_cls: 0.3491  loss_box_reg: 0.245  loss_rpn_cls: 0.02328  loss_rpn_loc: 0.02883  time: 1.9172  data_time: 0.2288  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:00:57 d2.utils.events]: \u001b[0m eta: 3:36:45  iter: 8199  total_loss: 0.6802  loss_cls: 0.3663  loss_box_reg: 0.2588  loss_rpn_cls: 0.02401  loss_rpn_loc: 0.03611  time: 1.9172  data_time: 0.2312  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:01:35 d2.utils.events]: \u001b[0m eta: 3:36:06  iter: 8219  total_loss: 0.7076  loss_cls: 0.3827  loss_box_reg: 0.2629  loss_rpn_cls: 0.02065  loss_rpn_loc: 0.03579  time: 1.9172  data_time: 0.2260  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:02:13 d2.utils.events]: \u001b[0m eta: 3:35:28  iter: 8239  total_loss: 0.6547  loss_cls: 0.3361  loss_box_reg: 0.2501  loss_rpn_cls: 0.02038  loss_rpn_loc: 0.03347  time: 1.9172  data_time: 0.2307  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:02:52 d2.utils.events]: \u001b[0m eta: 3:34:50  iter: 8259  total_loss: 0.738  loss_cls: 0.3877  loss_box_reg: 0.2627  loss_rpn_cls: 0.02773  loss_rpn_loc: 0.03766  time: 1.9172  data_time: 0.2323  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:03:30 d2.utils.events]: \u001b[0m eta: 3:34:12  iter: 8279  total_loss: 0.7148  loss_cls: 0.3598  loss_box_reg: 0.2622  loss_rpn_cls: 0.02533  loss_rpn_loc: 0.03419  time: 1.9172  data_time: 0.2369  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:04:08 d2.utils.events]: \u001b[0m eta: 3:33:34  iter: 8299  total_loss: 0.6896  loss_cls: 0.3624  loss_box_reg: 0.2604  loss_rpn_cls: 0.02375  loss_rpn_loc: 0.03313  time: 1.9172  data_time: 0.2295  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:04:47 d2.utils.events]: \u001b[0m eta: 3:32:56  iter: 8319  total_loss: 0.6468  loss_cls: 0.3504  loss_box_reg: 0.2305  loss_rpn_cls: 0.02568  loss_rpn_loc: 0.02875  time: 1.9172  data_time: 0.2305  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:05:25 d2.utils.events]: \u001b[0m eta: 3:32:18  iter: 8339  total_loss: 0.6983  loss_cls: 0.3877  loss_box_reg: 0.2398  loss_rpn_cls: 0.02562  loss_rpn_loc: 0.02894  time: 1.9172  data_time: 0.2368  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:06:04 d2.utils.events]: \u001b[0m eta: 3:31:40  iter: 8359  total_loss: 0.6887  loss_cls: 0.3554  loss_box_reg: 0.2672  loss_rpn_cls: 0.02316  loss_rpn_loc: 0.0296  time: 1.9172  data_time: 0.2380  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:06:42 d2.utils.events]: \u001b[0m eta: 3:31:02  iter: 8379  total_loss: 0.7098  loss_cls: 0.3783  loss_box_reg: 0.2857  loss_rpn_cls: 0.02462  loss_rpn_loc: 0.03709  time: 1.9172  data_time: 0.2323  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:07:21 d2.utils.events]: \u001b[0m eta: 3:30:24  iter: 8399  total_loss: 0.6937  loss_cls: 0.3762  loss_box_reg: 0.2564  loss_rpn_cls: 0.02328  loss_rpn_loc: 0.03384  time: 1.9172  data_time: 0.2308  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:07:59 d2.utils.events]: \u001b[0m eta: 3:29:45  iter: 8419  total_loss: 0.6512  loss_cls: 0.3531  loss_box_reg: 0.248  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.02588  time: 1.9172  data_time: 0.2278  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:08:37 d2.utils.events]: \u001b[0m eta: 3:29:06  iter: 8439  total_loss: 0.6558  loss_cls: 0.3599  loss_box_reg: 0.2562  loss_rpn_cls: 0.02082  loss_rpn_loc: 0.02936  time: 1.9172  data_time: 0.2294  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:09:15 d2.utils.events]: \u001b[0m eta: 3:28:28  iter: 8459  total_loss: 0.67  loss_cls: 0.3542  loss_box_reg: 0.2538  loss_rpn_cls: 0.01988  loss_rpn_loc: 0.03547  time: 1.9172  data_time: 0.2269  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:09:54 d2.utils.events]: \u001b[0m eta: 3:27:48  iter: 8479  total_loss: 0.6589  loss_cls: 0.3704  loss_box_reg: 0.2497  loss_rpn_cls: 0.02313  loss_rpn_loc: 0.03175  time: 1.9172  data_time: 0.2323  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:10:32 d2.utils.events]: \u001b[0m eta: 3:27:10  iter: 8499  total_loss: 0.6439  loss_cls: 0.342  loss_box_reg: 0.2558  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.03159  time: 1.9172  data_time: 0.2287  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:11:11 d2.utils.events]: \u001b[0m eta: 3:26:33  iter: 8519  total_loss: 0.6881  loss_cls: 0.3643  loss_box_reg: 0.243  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.03325  time: 1.9172  data_time: 0.2377  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:11:49 d2.utils.events]: \u001b[0m eta: 3:25:56  iter: 8539  total_loss: 0.6994  loss_cls: 0.3733  loss_box_reg: 0.2726  loss_rpn_cls: 0.02658  loss_rpn_loc: 0.03617  time: 1.9173  data_time: 0.2341  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:12:28 d2.utils.events]: \u001b[0m eta: 3:25:18  iter: 8559  total_loss: 0.6612  loss_cls: 0.3583  loss_box_reg: 0.2577  loss_rpn_cls: 0.02024  loss_rpn_loc: 0.02744  time: 1.9173  data_time: 0.2306  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:13:06 d2.utils.events]: \u001b[0m eta: 3:24:40  iter: 8579  total_loss: 0.6816  loss_cls: 0.3588  loss_box_reg: 0.2515  loss_rpn_cls: 0.02155  loss_rpn_loc: 0.03291  time: 1.9173  data_time: 0.2326  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:13:44 d2.utils.events]: \u001b[0m eta: 3:24:02  iter: 8599  total_loss: 0.6591  loss_cls: 0.3558  loss_box_reg: 0.2574  loss_rpn_cls: 0.01971  loss_rpn_loc: 0.02367  time: 1.9173  data_time: 0.2274  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:14:23 d2.utils.events]: \u001b[0m eta: 3:23:23  iter: 8619  total_loss: 0.7296  loss_cls: 0.3786  loss_box_reg: 0.2757  loss_rpn_cls: 0.02811  loss_rpn_loc: 0.03834  time: 1.9173  data_time: 0.2307  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:15:01 d2.utils.events]: \u001b[0m eta: 3:22:44  iter: 8639  total_loss: 0.7365  loss_cls: 0.3579  loss_box_reg: 0.2929  loss_rpn_cls: 0.02177  loss_rpn_loc: 0.03019  time: 1.9173  data_time: 0.2350  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:15:40 d2.utils.events]: \u001b[0m eta: 3:22:06  iter: 8659  total_loss: 0.6768  loss_cls: 0.3629  loss_box_reg: 0.2486  loss_rpn_cls: 0.02151  loss_rpn_loc: 0.02707  time: 1.9173  data_time: 0.2337  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:16:18 d2.utils.events]: \u001b[0m eta: 3:21:28  iter: 8679  total_loss: 0.6519  loss_cls: 0.3443  loss_box_reg: 0.2529  loss_rpn_cls: 0.01929  loss_rpn_loc: 0.02941  time: 1.9173  data_time: 0.2282  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:16:56 d2.utils.events]: \u001b[0m eta: 3:20:50  iter: 8699  total_loss: 0.6435  loss_cls: 0.3466  loss_box_reg: 0.2348  loss_rpn_cls: 0.02037  loss_rpn_loc: 0.02489  time: 1.9173  data_time: 0.2253  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:17:34 d2.utils.events]: \u001b[0m eta: 3:20:12  iter: 8719  total_loss: 0.7091  loss_cls: 0.382  loss_box_reg: 0.2635  loss_rpn_cls: 0.02202  loss_rpn_loc: 0.03679  time: 1.9173  data_time: 0.2303  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:18:13 d2.utils.events]: \u001b[0m eta: 3:19:36  iter: 8739  total_loss: 0.6491  loss_cls: 0.3587  loss_box_reg: 0.2561  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.03676  time: 1.9173  data_time: 0.2306  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:18:51 d2.utils.events]: \u001b[0m eta: 3:18:55  iter: 8759  total_loss: 0.644  loss_cls: 0.371  loss_box_reg: 0.2354  loss_rpn_cls: 0.02397  loss_rpn_loc: 0.02933  time: 1.9172  data_time: 0.2269  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:19:30 d2.utils.events]: \u001b[0m eta: 3:18:17  iter: 8779  total_loss: 0.6655  loss_cls: 0.373  loss_box_reg: 0.2657  loss_rpn_cls: 0.02616  loss_rpn_loc: 0.03401  time: 1.9172  data_time: 0.2290  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:20:08 d2.utils.events]: \u001b[0m eta: 3:17:38  iter: 8799  total_loss: 0.6342  loss_cls: 0.34  loss_box_reg: 0.2512  loss_rpn_cls: 0.02239  loss_rpn_loc: 0.03743  time: 1.9172  data_time: 0.2282  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:20:46 d2.utils.events]: \u001b[0m eta: 3:16:58  iter: 8819  total_loss: 0.66  loss_cls: 0.3621  loss_box_reg: 0.2605  loss_rpn_cls: 0.02182  loss_rpn_loc: 0.03582  time: 1.9172  data_time: 0.2242  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:21:24 d2.utils.events]: \u001b[0m eta: 3:16:19  iter: 8839  total_loss: 0.7237  loss_cls: 0.3859  loss_box_reg: 0.2695  loss_rpn_cls: 0.02371  loss_rpn_loc: 0.03273  time: 1.9172  data_time: 0.2286  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:22:03 d2.utils.events]: \u001b[0m eta: 3:15:40  iter: 8859  total_loss: 0.7107  loss_cls: 0.3703  loss_box_reg: 0.2741  loss_rpn_cls: 0.01845  loss_rpn_loc: 0.02709  time: 1.9172  data_time: 0.2259  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:22:41 d2.utils.events]: \u001b[0m eta: 3:15:02  iter: 8879  total_loss: 0.6728  loss_cls: 0.3591  loss_box_reg: 0.2518  loss_rpn_cls: 0.02193  loss_rpn_loc: 0.03878  time: 1.9172  data_time: 0.2295  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:23:19 d2.utils.events]: \u001b[0m eta: 3:14:24  iter: 8899  total_loss: 0.6417  loss_cls: 0.3616  loss_box_reg: 0.2402  loss_rpn_cls: 0.01917  loss_rpn_loc: 0.03675  time: 1.9172  data_time: 0.2269  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:23:58 d2.utils.events]: \u001b[0m eta: 3:13:45  iter: 8919  total_loss: 0.6846  loss_cls: 0.3614  loss_box_reg: 0.2485  loss_rpn_cls: 0.02606  loss_rpn_loc: 0.0332  time: 1.9172  data_time: 0.2294  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:24:36 d2.utils.events]: \u001b[0m eta: 3:13:08  iter: 8939  total_loss: 0.6826  loss_cls: 0.3733  loss_box_reg: 0.249  loss_rpn_cls: 0.02371  loss_rpn_loc: 0.02601  time: 1.9172  data_time: 0.2342  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:25:14 d2.utils.events]: \u001b[0m eta: 3:12:30  iter: 8959  total_loss: 0.6812  loss_cls: 0.3562  loss_box_reg: 0.258  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.02937  time: 1.9172  data_time: 0.2331  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:25:53 d2.utils.events]: \u001b[0m eta: 3:11:51  iter: 8979  total_loss: 0.665  loss_cls: 0.3814  loss_box_reg: 0.2416  loss_rpn_cls: 0.02857  loss_rpn_loc: 0.03353  time: 1.9172  data_time: 0.2320  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:26:32 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../../../dataset/test.json\n",
      "\u001b[32m[01/05 21:26:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/05 21:26:32 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/05 21:26:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.53 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/05 21:26:32 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/05 21:26:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[01/05 21:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0016 s/iter. Inference: 0.0467 s/iter. Eval: 0.0003 s/iter. Total: 0.0486 s/iter. ETA=0:03:56\n",
      "\u001b[32m[01/05 21:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 113/4871. Dataloading: 0.0016 s/iter. Inference: 0.0473 s/iter. Eval: 0.0003 s/iter. Total: 0.0493 s/iter. ETA=0:03:54\n",
      "\u001b[32m[01/05 21:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 221/4871. Dataloading: 0.0015 s/iter. Inference: 0.0461 s/iter. Eval: 0.0003 s/iter. Total: 0.0480 s/iter. ETA=0:03:43\n",
      "\u001b[32m[01/05 21:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 331/4871. Dataloading: 0.0016 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0472 s/iter. ETA=0:03:34\n",
      "\u001b[32m[01/05 21:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 439/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0470 s/iter. ETA=0:03:28\n",
      "\u001b[32m[01/05 21:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 550/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0467 s/iter. ETA=0:03:21\n",
      "\u001b[32m[01/05 21:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 658/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0467 s/iter. ETA=0:03:16\n",
      "\u001b[32m[01/05 21:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 764/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:03:12\n",
      "\u001b[32m[01/05 21:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 871/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:03:07\n",
      "\u001b[32m[01/05 21:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 980/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0467 s/iter. ETA=0:03:01\n",
      "\u001b[32m[01/05 21:27:24 d2.evaluation.evaluator]: \u001b[0mInference done 1083/4871. Dataloading: 0.0016 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:02:57\n",
      "\u001b[32m[01/05 21:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 1193/4871. Dataloading: 0.0016 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:02:52\n",
      "\u001b[32m[01/05 21:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 1302/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:02:46\n",
      "\u001b[32m[01/05 21:27:39 d2.evaluation.evaluator]: \u001b[0mInference done 1412/4871. Dataloading: 0.0016 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0467 s/iter. ETA=0:02:41\n",
      "\u001b[32m[01/05 21:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 1526/4871. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:02:35\n",
      "\u001b[32m[01/05 21:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 1636/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:02:30\n",
      "\u001b[32m[01/05 21:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 1747/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:02:24\n",
      "\u001b[32m[01/05 21:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 1856/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:02:19\n",
      "\u001b[32m[01/05 21:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 1968/4871. Dataloading: 0.0015 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:02:14\n",
      "\u001b[32m[01/05 21:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 2078/4871. Dataloading: 0.0016 s/iter. Inference: 0.0443 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:02:09\n",
      "\u001b[32m[01/05 21:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 2185/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:02:04\n",
      "\u001b[32m[01/05 21:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 2291/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:01:59\n",
      "\u001b[32m[01/05 21:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 2403/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:01:54\n",
      "\u001b[32m[01/05 21:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 2509/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:01:49\n",
      "\u001b[32m[01/05 21:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 2611/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:44\n",
      "\u001b[32m[01/05 21:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 2716/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:01:40\n",
      "\u001b[32m[01/05 21:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 2828/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:34\n",
      "\u001b[32m[01/05 21:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 2937/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:29\n",
      "\u001b[32m[01/05 21:28:54 d2.evaluation.evaluator]: \u001b[0mInference done 3045/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:24\n",
      "\u001b[32m[01/05 21:28:59 d2.evaluation.evaluator]: \u001b[0mInference done 3152/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:19\n",
      "\u001b[32m[01/05 21:29:04 d2.evaluation.evaluator]: \u001b[0mInference done 3261/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:14\n",
      "\u001b[32m[01/05 21:29:09 d2.evaluation.evaluator]: \u001b[0mInference done 3371/4871. Dataloading: 0.0016 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:09\n",
      "\u001b[32m[01/05 21:29:14 d2.evaluation.evaluator]: \u001b[0mInference done 3476/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:04\n",
      "\u001b[32m[01/05 21:29:19 d2.evaluation.evaluator]: \u001b[0mInference done 3582/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:00:59\n",
      "\u001b[32m[01/05 21:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 3688/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:00:54\n",
      "\u001b[32m[01/05 21:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 3795/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:00:50\n",
      "\u001b[32m[01/05 21:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 3903/4871. Dataloading: 0.0016 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:00:44\n",
      "\u001b[32m[01/05 21:29:39 d2.evaluation.evaluator]: \u001b[0mInference done 4008/4871. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:00:40\n",
      "\u001b[32m[01/05 21:29:44 d2.evaluation.evaluator]: \u001b[0mInference done 4114/4871. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:00:35\n",
      "\u001b[32m[01/05 21:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 4221/4871. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:00:30\n",
      "\u001b[32m[01/05 21:29:54 d2.evaluation.evaluator]: \u001b[0mInference done 4328/4871. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:00:25\n",
      "\u001b[32m[01/05 21:29:59 d2.evaluation.evaluator]: \u001b[0mInference done 4435/4871. Dataloading: 0.0016 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:00:20\n",
      "\u001b[32m[01/05 21:30:04 d2.evaluation.evaluator]: \u001b[0mInference done 4539/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:00:15\n",
      "\u001b[32m[01/05 21:30:09 d2.evaluation.evaluator]: \u001b[0mInference done 4647/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/05 21:30:14 d2.evaluation.evaluator]: \u001b[0mInference done 4754/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/05 21:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 4862/4871. Dataloading: 0.0016 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/05 21:30:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:46.919995 (0.046634 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/05 21:30:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:37 (0.044654 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/05 21:30:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/05 21:30:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[01/05 21:30:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/05 21:30:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/05 21:30:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.17 seconds.\n",
      "\u001b[32m[01/05 21:30:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/05 21:30:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.28 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[01/05 21:30:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[01/05 21:30:25 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/05 21:30:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[01/05 21:30:25 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[01/05 21:30:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/05 21:30:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/05 21:30:25 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[01/05 21:30:25 d2.utils.events]: \u001b[0m eta: 3:11:14  iter: 8999  total_loss: 0.69  loss_cls: 0.3678  loss_box_reg: 0.2633  loss_rpn_cls: 0.02077  loss_rpn_loc: 0.04298  time: 1.9173  data_time: 0.2356  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:31:04 d2.utils.events]: \u001b[0m eta: 3:10:37  iter: 9019  total_loss: 0.7081  loss_cls: 0.3855  loss_box_reg: 0.264  loss_rpn_cls: 0.02984  loss_rpn_loc: 0.03588  time: 1.9173  data_time: 0.2370  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:31:42 d2.utils.events]: \u001b[0m eta: 3:09:59  iter: 9039  total_loss: 0.7309  loss_cls: 0.3829  loss_box_reg: 0.2693  loss_rpn_cls: 0.0285  loss_rpn_loc: 0.03429  time: 1.9173  data_time: 0.2318  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:32:21 d2.utils.events]: \u001b[0m eta: 3:09:21  iter: 9059  total_loss: 0.6468  loss_cls: 0.374  loss_box_reg: 0.2453  loss_rpn_cls: 0.02264  loss_rpn_loc: 0.03427  time: 1.9173  data_time: 0.2372  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:32:59 d2.utils.events]: \u001b[0m eta: 3:08:44  iter: 9079  total_loss: 0.6768  loss_cls: 0.3463  loss_box_reg: 0.2643  loss_rpn_cls: 0.02382  loss_rpn_loc: 0.03467  time: 1.9173  data_time: 0.2281  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:33:37 d2.utils.events]: \u001b[0m eta: 3:08:05  iter: 9099  total_loss: 0.6893  loss_cls: 0.3537  loss_box_reg: 0.2836  loss_rpn_cls: 0.02451  loss_rpn_loc: 0.03577  time: 1.9173  data_time: 0.2257  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:34:16 d2.utils.events]: \u001b[0m eta: 3:07:27  iter: 9119  total_loss: 0.7172  loss_cls: 0.3795  loss_box_reg: 0.2606  loss_rpn_cls: 0.02623  loss_rpn_loc: 0.03287  time: 1.9173  data_time: 0.2295  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:34:54 d2.utils.events]: \u001b[0m eta: 3:06:49  iter: 9139  total_loss: 0.6419  loss_cls: 0.338  loss_box_reg: 0.2635  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.03056  time: 1.9173  data_time: 0.2284  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:35:32 d2.utils.events]: \u001b[0m eta: 3:06:11  iter: 9159  total_loss: 0.6609  loss_cls: 0.3529  loss_box_reg: 0.2392  loss_rpn_cls: 0.01962  loss_rpn_loc: 0.02891  time: 1.9173  data_time: 0.2300  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:36:11 d2.utils.events]: \u001b[0m eta: 3:05:35  iter: 9179  total_loss: 0.6514  loss_cls: 0.3563  loss_box_reg: 0.236  loss_rpn_cls: 0.02252  loss_rpn_loc: 0.02372  time: 1.9173  data_time: 0.2303  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:36:49 d2.utils.events]: \u001b[0m eta: 3:04:56  iter: 9199  total_loss: 0.6951  loss_cls: 0.384  loss_box_reg: 0.2535  loss_rpn_cls: 0.02695  loss_rpn_loc: 0.03156  time: 1.9173  data_time: 0.2306  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:37:27 d2.utils.events]: \u001b[0m eta: 3:04:19  iter: 9219  total_loss: 0.7171  loss_cls: 0.3782  loss_box_reg: 0.2748  loss_rpn_cls: 0.02607  loss_rpn_loc: 0.0349  time: 1.9173  data_time: 0.2313  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:38:06 d2.utils.events]: \u001b[0m eta: 3:03:41  iter: 9239  total_loss: 0.7352  loss_cls: 0.3796  loss_box_reg: 0.2661  loss_rpn_cls: 0.02477  loss_rpn_loc: 0.03261  time: 1.9173  data_time: 0.2340  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:38:44 d2.utils.events]: \u001b[0m eta: 3:03:02  iter: 9259  total_loss: 0.6766  loss_cls: 0.367  loss_box_reg: 0.2503  loss_rpn_cls: 0.02543  loss_rpn_loc: 0.03658  time: 1.9173  data_time: 0.2273  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:39:23 d2.utils.events]: \u001b[0m eta: 3:02:23  iter: 9279  total_loss: 0.7297  loss_cls: 0.3601  loss_box_reg: 0.2728  loss_rpn_cls: 0.0263  loss_rpn_loc: 0.04663  time: 1.9173  data_time: 0.2250  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:40:01 d2.utils.events]: \u001b[0m eta: 3:01:45  iter: 9299  total_loss: 0.7067  loss_cls: 0.388  loss_box_reg: 0.256  loss_rpn_cls: 0.02172  loss_rpn_loc: 0.03003  time: 1.9173  data_time: 0.2259  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:40:39 d2.utils.events]: \u001b[0m eta: 3:01:08  iter: 9319  total_loss: 0.6168  loss_cls: 0.3602  loss_box_reg: 0.2397  loss_rpn_cls: 0.01715  loss_rpn_loc: 0.02488  time: 1.9173  data_time: 0.2275  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:41:18 d2.utils.events]: \u001b[0m eta: 3:00:29  iter: 9339  total_loss: 0.6869  loss_cls: 0.363  loss_box_reg: 0.2478  loss_rpn_cls: 0.02303  loss_rpn_loc: 0.03693  time: 1.9173  data_time: 0.2278  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:41:56 d2.utils.events]: \u001b[0m eta: 2:59:52  iter: 9359  total_loss: 0.6596  loss_cls: 0.3484  loss_box_reg: 0.2434  loss_rpn_cls: 0.01973  loss_rpn_loc: 0.02711  time: 1.9173  data_time: 0.2352  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:42:34 d2.utils.events]: \u001b[0m eta: 2:59:12  iter: 9379  total_loss: 0.6882  loss_cls: 0.373  loss_box_reg: 0.2704  loss_rpn_cls: 0.02482  loss_rpn_loc: 0.03833  time: 1.9173  data_time: 0.2287  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:43:13 d2.utils.events]: \u001b[0m eta: 2:58:33  iter: 9399  total_loss: 0.6952  loss_cls: 0.3561  loss_box_reg: 0.2763  loss_rpn_cls: 0.0213  loss_rpn_loc: 0.0308  time: 1.9173  data_time: 0.2257  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:43:51 d2.utils.events]: \u001b[0m eta: 2:57:56  iter: 9419  total_loss: 0.7133  loss_cls: 0.3772  loss_box_reg: 0.2827  loss_rpn_cls: 0.02171  loss_rpn_loc: 0.02466  time: 1.9173  data_time: 0.2379  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:44:29 d2.utils.events]: \u001b[0m eta: 2:57:17  iter: 9439  total_loss: 0.7079  loss_cls: 0.3585  loss_box_reg: 0.266  loss_rpn_cls: 0.02521  loss_rpn_loc: 0.03351  time: 1.9173  data_time: 0.2308  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:45:08 d2.utils.events]: \u001b[0m eta: 2:56:40  iter: 9459  total_loss: 0.6452  loss_cls: 0.3644  loss_box_reg: 0.2402  loss_rpn_cls: 0.01757  loss_rpn_loc: 0.02523  time: 1.9173  data_time: 0.2295  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:45:46 d2.utils.events]: \u001b[0m eta: 2:56:02  iter: 9479  total_loss: 0.645  loss_cls: 0.3623  loss_box_reg: 0.2305  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.02135  time: 1.9173  data_time: 0.2303  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:46:24 d2.utils.events]: \u001b[0m eta: 2:55:24  iter: 9499  total_loss: 0.6897  loss_cls: 0.3714  loss_box_reg: 0.2527  loss_rpn_cls: 0.02089  loss_rpn_loc: 0.03568  time: 1.9173  data_time: 0.2278  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:47:03 d2.utils.events]: \u001b[0m eta: 2:54:44  iter: 9519  total_loss: 0.6934  loss_cls: 0.3617  loss_box_reg: 0.2799  loss_rpn_cls: 0.02728  loss_rpn_loc: 0.04896  time: 1.9173  data_time: 0.2309  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:47:41 d2.utils.events]: \u001b[0m eta: 2:54:06  iter: 9539  total_loss: 0.6459  loss_cls: 0.3472  loss_box_reg: 0.251  loss_rpn_cls: 0.02487  loss_rpn_loc: 0.02729  time: 1.9173  data_time: 0.2405  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:48:20 d2.utils.events]: \u001b[0m eta: 2:53:27  iter: 9559  total_loss: 0.699  loss_cls: 0.3628  loss_box_reg: 0.2783  loss_rpn_cls: 0.0215  loss_rpn_loc: 0.04136  time: 1.9173  data_time: 0.2279  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:48:58 d2.utils.events]: \u001b[0m eta: 2:52:47  iter: 9579  total_loss: 0.6511  loss_cls: 0.348  loss_box_reg: 0.2475  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.03252  time: 1.9173  data_time: 0.2313  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:49:37 d2.utils.events]: \u001b[0m eta: 2:52:10  iter: 9599  total_loss: 0.7169  loss_cls: 0.3754  loss_box_reg: 0.258  loss_rpn_cls: 0.02263  loss_rpn_loc: 0.03374  time: 1.9173  data_time: 0.2327  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:50:15 d2.utils.events]: \u001b[0m eta: 2:51:32  iter: 9619  total_loss: 0.6631  loss_cls: 0.3716  loss_box_reg: 0.2442  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.02547  time: 1.9173  data_time: 0.2334  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:50:53 d2.utils.events]: \u001b[0m eta: 2:50:53  iter: 9639  total_loss: 0.6611  loss_cls: 0.3559  loss_box_reg: 0.2423  loss_rpn_cls: 0.02435  loss_rpn_loc: 0.04077  time: 1.9173  data_time: 0.2264  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:51:32 d2.utils.events]: \u001b[0m eta: 2:50:15  iter: 9659  total_loss: 0.6778  loss_cls: 0.3742  loss_box_reg: 0.2458  loss_rpn_cls: 0.02641  loss_rpn_loc: 0.03606  time: 1.9173  data_time: 0.2295  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:52:10 d2.utils.events]: \u001b[0m eta: 2:49:37  iter: 9679  total_loss: 0.698  loss_cls: 0.3653  loss_box_reg: 0.2686  loss_rpn_cls: 0.02388  loss_rpn_loc: 0.02784  time: 1.9173  data_time: 0.2306  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:52:48 d2.utils.events]: \u001b[0m eta: 2:48:59  iter: 9699  total_loss: 0.6855  loss_cls: 0.3738  loss_box_reg: 0.2623  loss_rpn_cls: 0.02402  loss_rpn_loc: 0.03436  time: 1.9173  data_time: 0.2274  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:53:27 d2.utils.events]: \u001b[0m eta: 2:48:20  iter: 9719  total_loss: 0.6658  loss_cls: 0.3672  loss_box_reg: 0.2668  loss_rpn_cls: 0.02196  loss_rpn_loc: 0.03234  time: 1.9173  data_time: 0.2281  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:54:05 d2.utils.events]: \u001b[0m eta: 2:47:41  iter: 9739  total_loss: 0.6848  loss_cls: 0.3794  loss_box_reg: 0.263  loss_rpn_cls: 0.02132  loss_rpn_loc: 0.02858  time: 1.9173  data_time: 0.2262  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:54:43 d2.utils.events]: \u001b[0m eta: 2:47:02  iter: 9759  total_loss: 0.6779  loss_cls: 0.3694  loss_box_reg: 0.2661  loss_rpn_cls: 0.02136  loss_rpn_loc: 0.03427  time: 1.9173  data_time: 0.2256  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:55:21 d2.utils.events]: \u001b[0m eta: 2:46:23  iter: 9779  total_loss: 0.6915  loss_cls: 0.3618  loss_box_reg: 0.2779  loss_rpn_cls: 0.02213  loss_rpn_loc: 0.03625  time: 1.9173  data_time: 0.2285  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:56:00 d2.utils.events]: \u001b[0m eta: 2:45:45  iter: 9799  total_loss: 0.6897  loss_cls: 0.369  loss_box_reg: 0.2609  loss_rpn_cls: 0.02579  loss_rpn_loc: 0.03449  time: 1.9173  data_time: 0.2313  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:56:38 d2.utils.events]: \u001b[0m eta: 2:45:09  iter: 9819  total_loss: 0.6563  loss_cls: 0.3662  loss_box_reg: 0.2467  loss_rpn_cls: 0.02183  loss_rpn_loc: 0.03378  time: 1.9173  data_time: 0.2290  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:57:17 d2.utils.events]: \u001b[0m eta: 2:44:31  iter: 9839  total_loss: 0.682  loss_cls: 0.3621  loss_box_reg: 0.2589  loss_rpn_cls: 0.02677  loss_rpn_loc: 0.03418  time: 1.9173  data_time: 0.2286  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:57:55 d2.utils.events]: \u001b[0m eta: 2:43:53  iter: 9859  total_loss: 0.6692  loss_cls: 0.3483  loss_box_reg: 0.2625  loss_rpn_cls: 0.0209  loss_rpn_loc: 0.02742  time: 1.9173  data_time: 0.2295  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:58:33 d2.utils.events]: \u001b[0m eta: 2:43:15  iter: 9879  total_loss: 0.6907  loss_cls: 0.3802  loss_box_reg: 0.265  loss_rpn_cls: 0.0235  loss_rpn_loc: 0.03367  time: 1.9173  data_time: 0.2259  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:59:12 d2.utils.events]: \u001b[0m eta: 2:42:37  iter: 9899  total_loss: 0.6636  loss_cls: 0.372  loss_box_reg: 0.2358  loss_rpn_cls: 0.02537  loss_rpn_loc: 0.03502  time: 1.9173  data_time: 0.2302  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 21:59:50 d2.utils.events]: \u001b[0m eta: 2:41:59  iter: 9919  total_loss: 0.6816  loss_cls: 0.3485  loss_box_reg: 0.2542  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.03916  time: 1.9173  data_time: 0.2305  lr: 5e-07  max_mem: 24886M\n",
      "\u001b[32m[01/05 22:00:28 d2.utils.events]: \u001b[0m eta: 2:41:20  iter: 9939  total_loss: 0.5749  loss_cls: 0.3275  loss_box_reg: 0.2215  loss_rpn_cls: 0.01785  loss_rpn_loc: 0.01885  time: 1.9173  data_time: 0.2271  lr: 5e-07  max_mem: 24886M\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'../../../dataset'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
