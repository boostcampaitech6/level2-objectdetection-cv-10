{"cells":[{"cell_type":"markdown","metadata":{"id":"4t8WN3ydCHIO"},"source":["# Object Detection - Mission 7\n","#### Ensemble\n","앙상블은 최종 아웃풋의 품질과 가장 직점적으로 연관이 있고, 시간 대비 좋은 결과를 낼 수 있는 방법입니다!\n","지금까지 학습시킨 모델들을 혹은 Sample Submission을 이용해 앙상블 코드를 작성해봅시다.\n","<br>Ensemble의 자세한 내용은 09강: Ready for Competition 강의를 참고합니다."]},{"cell_type":"markdown","metadata":{"id":"e0NRKyCRCjZs"},"source":["## 대회 데이터셋 구성\n","Custom 데이터를 구현하여 대회 데이터셋에 Ensemble 방법을 적용해봅니다. <br>\n","데이터셋의 자세한 개요는 [대회 플랫폼](https://next.stages.ai/competitions/)의 데이터 설명을 참고합니다.\n","> Copyright: CC BY 2.0\n","\n","### dataset\n","    ├── train.json\n","    ├── test.json\n","    ├── train\n","    └── test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TL_fCsQ_CFbw"},"outputs":[],"source":["!pip install ensemble_boxes"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"9gQvhOSxCFb1"},"outputs":[],"source":["import pandas as pd\n","from ensemble_boxes import *\n","import numpy as np\n","from pycocotools.coco import COCO"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"opgAs-9GCFb2"},"outputs":[],"source":["# ensemble csv files\n","submission_files = ['/data/ephemeral/home/level2-objectdetection-cv-10/develop/yumin/assignments/cascade_4995.csv',\n","                   '/data/ephemeral/home/level2-objectdetection-cv-10/develop/yumin/assignments/swin_5708.csv',\n","                   '/data/ephemeral/home/level2-objectdetection-cv-10/develop/yumin/assignments/yolo_5507.csv',\n","                   '/data/ephemeral/home/level2-objectdetection-cv-10/develop/yumin/assignments/yolo_5515.csv']\n","submission_df = [pd.read_csv(file) for file in submission_files]"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"GEH0AK1yCFb3"},"outputs":[],"source":["image_ids = submission_df[0]['image_id'].tolist()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"CrnHsBkGCFb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n"]}],"source":["# ensemble 할 file의 image 정보를 불러오기 위한 json\n","annotation = '../../../dataset/test.json'\n","coco = COCO(annotation)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"bxNjAo3hCFb4"},"outputs":[],"source":["prediction_strings = []\n","file_names = []\n","# ensemble 시 설정할 iou threshold 이 부분을 바꿔가며 대회 metric에 알맞게 적용해봐요!\n","iou_thr = 0.55\n","skip_box_thr = 0.0001\n","\n","\n","# 각 image id 별로 submission file에서 box좌표 추출\n","for i, image_id in enumerate(image_ids):\n","    prediction_string = ''\n","    boxes_list = []\n","    scores_list = []\n","    labels_list = []\n","    image_info = coco.loadImgs(i)[0]\n","#     각 submission file 별로 prediction box좌표 불러오기\n","    for df in submission_df:\n","        predict_string = df[df['image_id'] == image_id]['PredictionString'].tolist()[0]\n","        predict_list = str(predict_string).split()\n","\n","        if len(predict_list)==0 or len(predict_list)==1:\n","            continue\n","\n","        predict_list = np.reshape(predict_list, (-1, 6))\n","        box_list = []\n","\n","        for box in predict_list[:, 2:6].tolist():\n","            box[0] = float(box[0]) / image_info['width']\n","            box[1] = float(box[1]) / image_info['height']\n","            box[2] = float(box[2]) / image_info['width']\n","            box[3] = float(box[3]) / image_info['height']\n","            box_list.append(box)\n","\n","        boxes_list.append(box_list)\n","        scores_list.append(list(map(float, predict_list[:, 1].tolist())))\n","        labels_list.append(list(map(int, predict_list[:, 0].tolist())))\n","\n","#     예측 box가 있다면 이를 ensemble 수행\n","    if len(boxes_list):\n","        #boxes, scores, labels = nms(boxes_list, scores_list, labels_list, iou_thr=iou_thr)\n","        boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, iou_thr=iou_thr, skip_box_thr = skip_box_thr)\n","        for box, score, label in zip(boxes, scores, labels):\n","            prediction_string += str(label) + ' ' + str(score) + ' ' + str(box[0] * image_info['width']) + ' ' + str(box[1] * image_info['height']) + ' ' + str(box[2] * image_info['width']) + ' ' + str(box[3] * image_info['height']) + ' '\n","\n","    prediction_strings.append(prediction_string)\n","    file_names.append(image_id)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"K1QwofbNCFb5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PredictionString</th>\n","      <th>image_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.0 0.8170978426933289 603.2189331054688 512.6...</td>\n","      <td>test/0000.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0 0.7966922521591187 346.088134765625 251.31...</td>\n","      <td>test/0001.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0 0.7640089392662048 425.6733093261719 268.0...</td>\n","      <td>test/0002.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9.0 0.6503177285194397 153.63706970214844 253....</td>\n","      <td>test/0003.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0 0.48002156615257263 188.58729553222656 270...</td>\n","      <td>test/0004.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    PredictionString       image_id\n","0  7.0 0.8170978426933289 603.2189331054688 512.6...  test/0000.jpg\n","1  5.0 0.7966922521591187 346.088134765625 251.31...  test/0001.jpg\n","2  1.0 0.7640089392662048 425.6733093261719 268.0...  test/0002.jpg\n","3  9.0 0.6503177285194397 153.63706970214844 253....  test/0003.jpg\n","4  1.0 0.48002156615257263 188.58729553222656 270...  test/0004.jpg"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["submission = pd.DataFrame()\n","submission['PredictionString'] = prediction_strings\n","submission['image_id'] = file_names\n","submission.to_csv('../../../ensemble_wbf_2.csv', index=False)\n","\n","submission.head()"]},{"cell_type":"markdown","metadata":{"id":"pj76TIByCsPr"},"source":["### Reference\n","https://github.com/ZFTurbo/Weighted-Boxes-Fusion"]},{"cell_type":"markdown","metadata":{"id":"VFJDriTsCFb6"},"source":["###**콘텐츠 라이선스**\n","\n","<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
